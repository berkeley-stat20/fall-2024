[
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Documentation",
    "section": "",
    "text": "Welcome to the technical documentation of the Stat 20 curriculum and website."
  },
  {
    "objectID": "docs/slides.html",
    "href": "docs/slides.html",
    "title": "Slides",
    "section": "",
    "text": "Be sure your personal fork of the course-materials is up to date by syncing it to the one on github.com/stat20.\nPull the most recent changes from your fork to your local machine.\nMake changes to slides.qmd and save.\n\n\n\n\nQuarto Pub is a free service for publishing quarto documents, including slides, online. Start by setting up an account at https://quartopub.com/.\n\nOnce you are set up with an account, in the terminal, navigate to the directory that contains your slides, for example: cd summarizing-numerical-data.\nOpen slides.qmd and, ensure that under revealjs: that you add the option self-contained: true. (read more here)\nIn that directory run:\n\n\n\nTerminal\n\nquarto publish quarto-pub slides.qmd\n\n\nYou may be prompted to answer a few questions at the terminal. If it successfully published, it will provide a link to your published document\nAt this point, you’re all set!\n\nIf you’d like to learn more about publishing with Quarto Pub, see the official documentation.\n\n\n\nTest it out by working in a much simpler directory than course-materials, one called practice-repo. Since you won’t be pushing any commits back up to GitHub, you don’t need a create your own fork.\n\nCreate a new project in Rstudio from a version control repository and paste in https://github.com/stat20/practice-repo for the url.\nModify slides.qmd in the summarizing-numerical-data directory by, say, replacing \"Instructor\" with your name in the header.\nIn the terminal, navigate into the sub-directory with the slides: cd summarizing-numerical-data\nStill at the terminal, publish your slides:\n\n\nTerminal\n\nquarto publish quarto-pub slides.qmd\n\nClick through any prompts you might see at the terminal.\nIf it publishes successfully, the terminal will print a link to your published document. Visit that site and check the link at the top that it says that it has been “Published at …”. It should appear as &lt;user_name&gt;.quarto.pub/summarizing-categorical-data/."
  },
  {
    "objectID": "docs/slides.html#modifying-your-own-slides",
    "href": "docs/slides.html#modifying-your-own-slides",
    "title": "Slides",
    "section": "",
    "text": "Be sure your personal fork of the course-materials is up to date by syncing it to the one on github.com/stat20.\nPull the most recent changes from your fork to your local machine.\nMake changes to slides.qmd and save."
  },
  {
    "objectID": "docs/slides.html#publishing-your-own-slides",
    "href": "docs/slides.html#publishing-your-own-slides",
    "title": "Slides",
    "section": "",
    "text": "Quarto Pub is a free service for publishing quarto documents, including slides, online. Start by setting up an account at https://quartopub.com/.\n\nOnce you are set up with an account, in the terminal, navigate to the directory that contains your slides, for example: cd summarizing-numerical-data.\nOpen slides.qmd and, ensure that under revealjs: that you add the option self-contained: true. (read more here)\nIn that directory run:\n\n\n\nTerminal\n\nquarto publish quarto-pub slides.qmd\n\n\nYou may be prompted to answer a few questions at the terminal. If it successfully published, it will provide a link to your published document\nAt this point, you’re all set!\n\nIf you’d like to learn more about publishing with Quarto Pub, see the official documentation."
  },
  {
    "objectID": "docs/slides.html#test-it-out",
    "href": "docs/slides.html#test-it-out",
    "title": "Slides",
    "section": "",
    "text": "Test it out by working in a much simpler directory than course-materials, one called practice-repo. Since you won’t be pushing any commits back up to GitHub, you don’t need a create your own fork.\n\nCreate a new project in Rstudio from a version control repository and paste in https://github.com/stat20/practice-repo for the url.\nModify slides.qmd in the summarizing-numerical-data directory by, say, replacing \"Instructor\" with your name in the header.\nIn the terminal, navigate into the sub-directory with the slides: cd summarizing-numerical-data\nStill at the terminal, publish your slides:\n\n\nTerminal\n\nquarto publish quarto-pub slides.qmd\n\nClick through any prompts you might see at the terminal.\nIf it publishes successfully, the terminal will print a link to your published document. Visit that site and check the link at the top that it says that it has been “Published at …”. It should appear as &lt;user_name&gt;.quarto.pub/summarizing-categorical-data/."
  },
  {
    "objectID": "office-hours.html",
    "href": "office-hours.html",
    "title": "Office Hours and Group Tutoring",
    "section": "",
    "text": "Office Hours and Group Tutoring\nPlease stop by introduce yourself! Stat 20 offers two types of session to ask chat about the course in person but outside of class.\nInstructor office hours are useful for to discuss topics that come in the reading or broader questions about statistics and data science. They are also a fine place to ask questions about the assignments you’re working on. Please attend only your instructor’s office hours.\nGroup tutoring (GT) sessions are held throughout the week on the 3rd floor of Evans Hall. They’re a great place to work on your assignments with fellow students and seek the help of tutors whenever you get stuck. One thing to know: tutors will expect that you have done the reading and generally been attending class; this is not meant to replace class time.\nYou’re welcome to attend whichever GT sessions work best for your schedule."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Lab assignments are an opportunity to put the concepts from the notes into practice to answer questions about a real data set. Your lab report should be a pdf file generated from a fully reproducible qmd file. For a helpful R reference, see base R, data visualization (ggplot2), and data wrangling (dplyr).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments.html#labs",
    "href": "assignments.html#labs",
    "title": "Assignments",
    "section": "",
    "text": "Lab assignments are an opportunity to put the concepts from the notes into practice to answer questions about a real data set. Your lab report should be a pdf file generated from a fully reproducible qmd file. For a helpful R reference, see base R, data visualization (ggplot2), and data wrangling (dplyr).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments.html#worksheets",
    "href": "assignments.html#worksheets",
    "title": "Assignments",
    "section": "Worksheets",
    "text": "Worksheets\nWorksheets are pen-and-paper practice problems that we work on in class. The goal of the worksheets is simply practice: they help you drill the techniques needed to complete the labs.\n\n\n\nWS 1: Summarizing Categorical Data\n\n\nWS 2: Summarizing Numerical Data\n\n\nWS 3: Taxonomy of Data\n\n\n\nNo matching items"
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/notes.html",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/notes.html",
    "title": "A Grammar of Graphics",
    "section": "",
    "text": "In the last set of notes, we saw that there is a side to the discipline of Statistics that looks like engineering. Summary statistics - medians, standard deviations, etc. - are carefully crafted tools that capture different characteristics of a data set for use in very specific situations. There is another practice in statistics that looks more like a science; that is, a field that seeks to take many different phenomena and explain them using a systematic overarching theory. That practice is data visualization.\nAt this point in the course, you’ve seen several several examples of data visualizations.\nThe diversity of shapes and structures used in these plots suggest that each one is a thing-unto-itself, specially devised to provide one particular style of visualization. But what elements do they share?\nFocus on the nature of the data being used. Exactly half of the plots above are illustrating the distribution of a single variable; the other half illustrate the relation between two variables. Can you tell which is which?\nConsider the manner in which variability in the data is being conveyed used different visual cues. How many of the plots above utilize an x-axis? A y-axis? Color?\nFinally, how are the observations finding their way onto the plot? Three of the plots above share the same data variable, utilize the same visual cues, and differ only in the shape used to encode the observations.\nBy asking these questions, we begin to find recurring structures in a wide range of plot types. These recurring structures have been compiled into a widely-used framework called the Grammar of Graphics.",
    "crumbs": [
      "Notes",
      "Summarization",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#the-grammar-of-graphics",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#the-grammar-of-graphics",
    "title": "A Grammar of Graphics",
    "section": "The Grammar of Graphics",
    "text": "The Grammar of Graphics\nIn 1999, a statistician named Leland Wilkinson published the first edition of what has been the most influential work in data visualization, The Grammar of Graphics1. The title is fitting. In the same way that a grammar defines the regular structures and composition of a language, his book outlines a framework to structure statistical graphics.\n\nNearly every current software tool used to build plots has been informed by this book2. Its influence can be found in Tableau, Plotly, and the Python libraries bokeh, altair, seaborn, and plotnine. The most complete implementation of the grammar is found in an R package called ggplot2 by Hadley Wickham3.\nIn Wickham’s adaptation of the grammar of graphics, a plot can be decomposed into three primary elements:\n\nthe data,\nthe aesthetic mapping of the variables in the data to visual cues, and\nthe geometry used to encode the observations on the plot.\n\nLet’s go through each of these components one-by-one to understand the role that they play in a plot like this, which we’ll refer to as the “penguin plot”.\n\n\n\n\n\n\n\n\n\nThe above plot is an example new type of plot which involves two numerical variables: a scatter plot. The points may also be colored by a third variable, generally a categorical one.\n\nData\nWhat variables are needed to construct the penguin plot above?\nWe see bill_length_mm and bill_depth_mm; those are labeled clearly on the x and y axes. We must also know the species of each of these penguins in order to know which color to label each point. In other words, there are three columns of a data frame that we need to have on hand.\n\n\n# A tibble: 333 × 3\n   bill_length_mm bill_depth_mm species\n            &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;  \n 1           39.1          18.7 Adelie \n 2           39.5          17.4 Adelie \n 3           40.3          18   Adelie \n 4           36.7          19.3 Adelie \n 5           39.3          20.6 Adelie \n 6           38.9          17.8 Adelie \n 7           39.2          19.6 Adelie \n 8           41.1          17.6 Adelie \n 9           38.6          21.2 Adelie \n10           34.6          21.1 Adelie \n# ℹ 323 more rows\n\n\nThrough working on your assignments, you may have also seen the following plot, which is a variant of the “penguin plot”:\n\n\n\n\n\n\n\n\n\nIn this course we’ve talked plenty about the structure of a data frame, so this part of the grammar of graphics is straight-forward. Be sure that every variable that you wish to include in your plot is present in the same data frame.\n\nMore fundamentally, be sure the data you’re using is well-suited to the message you aim to convey with your plot. Many plots go wrong right here at the outset, so be sure you’re on firm footing.\n\n\nAesthetics\nThe most impactful decision that you’ll make when constructing a plot using the grammar of graphics is deciding how to encode variables in a data frame into visual variation in your plot.\nThe penguin plot relies upon three forms of visual variation. The first is the location along the x-axis. Penguins with longer bills are placed on the right side of the plot and those with shorter bills are placed on the left. Variation in bill depth is captured by variation in the location along the y-axis, which is the second form. The third form is color: each of the three species is designated by one of three colors.\n\n\n\n\n\nWe can summarize this encoding, or “aesthetic mapping”, as:\n\nbill_length_mm is mapped to the x-axis\nbill_depth_mm is mapped to the y-axis\nspecies is mapped to color\n\nThese are three of many different techniques for visually encoding variability. Here is a list of the aesthetic attributes that are most commonly used:\n\nx: location along the x-axis\ny: location along the y-axis\ncolor: hue of the mark that represents the observation\nalpha: the level of transparency of the color\nsize: the size of the mark representing the observation\nshape: the shape of the mark representing the observation\nfill: the color of the inside of the representation of an observation\n\n\n\nGeometries\nWith the data set in place and the aesthetic mappings selected, the final choice in making our plot is to decide how to graphically express the observations themselves. For the penguin plot above, each observation in represented by a point, so it is said to use a “point” geometry. That is just one of many options. Other options are listed below.\n\npoint\nbar\nline\nhistogram\ndensity\nviolin\ndotplot\nboxplot\n\nWhen we speak about whether a plot is a scatter plot, a bar chart, a histogram, etc, we are discussing the geometry of a plot. The impact of this choice can be seen in the following two plots.\n\n\n\n\n\n\n\n\n\nBoth plots share the same data (penguins) and the same aesthetic mappings(bill_length to the x-axis and species to the y-axis). Where they differ is the geometry: the plot on the left uses the violin while the one on the right uses the boxplot.\n\n\nExample: Births over Time\nThe following plot displays the total number of births over time recorded in London, England during the 17th century.\n\n\n\n\n\n\n\n\n\nIt was constructed from a data frame with 82 rows, the first six of which are shown below.\n\n\n# A tibble: 6 × 2\n   year total\n  &lt;int&gt; &lt;int&gt;\n1  1629  9901\n2  1630  9315\n3  1631  8524\n4  1632  9584\n5  1633  9997\n6  1634  9855\n\n\nWe can decompose this graphic using the grammar of graphics.\n\ndata: the data frame displayed above\naesthetic mappings: year is mapped to the x-axis, total is mapped to the y-axis\ngeometry: the observations are expressed as a line\n\nThis process makes clear what decisions were made in constructing the plot and suggests ways in which we might consider changing the graphic. What if we changed the geometry so that the observations are expressed as points?\n\n\n\n\n\n\n\n\n\nIs this a better graphic? That depends on the message you aim to convey. The line geometry emphasizes the general trend over time. The point geometry makes clearer the total births in each particular year.\nWhat if you wanted to convey both of those messages? If two geometries are compatible, they can be combined.\n\n\n\n\n\n\n\n\n\nIs this a better graphic? Again, that depends. It makes it possible to see both the trend over time and the individual observations. But this plot is more complicated and therefore articulates each of those individual messages less clearly. Sometimes simplicity and a single message is best.\nHere’s another example of a plot that combines two geometries:\n\n\n\n\n\nHere, a density geometry is overlaid on top of a histogram geometry. It is unclear whether this was a good design decision. What do you think? What is the advantage of a stair-step histogram versus the smooth line of a density curve?",
    "crumbs": [
      "Notes",
      "Summarization",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#summary",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#summary",
    "title": "A Grammar of Graphics",
    "section": "Summary",
    "text": "Summary\nThe Grammar of Graphics is a framework to express a great variety of statistical graphics in terms of their shared elements. In this framework, the core features of the plot are the data, the aesthetic mapping between aesthetic attributions and variables in the data frame, and the geometry that is used to express the observation. There are a wide range of geometries and aesthetic attributes that can be drawn from and recombined in powerful ways. What we have done so far is cover just the fundamentals of the framework, so if you are unsatisfied with the resulting plots, that’s good. Now, we will polish up these plots to make thoughtful graphics that focus on effectively conveying a single message.\nContinue on to the tutorial portion of the notes",
    "crumbs": [
      "Notes",
      "Summarization",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#footnotes",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/notes.html#footnotes",
    "title": "A Grammar of Graphics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWilkinson, Leland. The grammar of graphics. Springer Science & Business Media, 2005.↩︎\nFor more context around The Grammar of Graphics and the development of modern visualization tools, read the brief Three Waves of Data Visualization by Elijah Meeks, Senior Data Visualization Engineer at Netflix: https://www.tableau.com/about/blog/2019/2/three-waves-data-visualization-brief-history-and-predictions-future-100830.↩︎\nThe ggplot2 package is described in the manuscript, A layered grammar of graphics, by Hadley Wickham in the Journal of Computational and Graphical Statistics in 2010.↩︎",
    "crumbs": [
      "Notes",
      "Summarization",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/learning-objectives.html",
    "href": "2-summarizing-data/02-summarizing-numerical-data/learning-objectives.html",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Summarizing Numerical Data\n\nConcept Acquisition\n\n\n\n\n\nTool Acquisition\n\n\n\n\n\nConcept Application\n\nDescribe a distribution in terms of shape, center, and spread"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/tutorial.html",
    "href": "2-summarizing-data/02-summarizing-numerical-data/tutorial.html",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Once you have your data in front of you, you’ve seen how we can form visual summaries with ggplot2. But how can we calculate numerical summaries? Furthermore, what if we are concerned about summarizing a portion of our data, like just one species of penguin at a time? We will answer these questions below, and introduce some new functions from the dplyr package (within the tidyverse library) along the way. We’ll also look at how factor() can come in handy while plotting.\nIf you are playing along in RStudio while reading these notes (which we strongly recommend!), be sure to start off by loading the two packages that are necessary for the tutorial by running the following code.\nlibrary(tidyverse)\nlibrary(stat20data)",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/tutorial.html#summary",
    "href": "2-summarizing-data/02-summarizing-numerical-data/tutorial.html#summary",
    "title": "Summarizing Numerical Data",
    "section": "Summary",
    "text": "Summary\nA summary of a summaries…this better be brief! Summaries of numerical data - graphical and numerical - often involve choices of what information to include and what information to omit. These choices involve a degree of judgement and knowledge of the criteria that were used to construct the commonly used statistics and graphics.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/reading-questions.html",
    "href": "2-summarizing-data/02-summarizing-numerical-data/reading-questions.html",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Question 1\nWhich of the following plot types maintain all of the information found in the original data set?\n\ndot plot ( ) histogram ( ) violin plot ( ) box plot\n\n\n\nQuestion 2\nIf you wish to see less detail in your histogram and perform more aggregation, which of the following is the best course of action?\n( ) switch to a dot plot ( ) switch to a bar chart ( ) instead of presenting the histogram, display the original data frame with the raw data (X) increase the bin width of the histogram ( ) decrease the bin width of the histogram\n\n\nQuestion 3\nWhich word best describes a distribution with a long tail stretching out to the left?\n\nleft skewed ( ) right skewed ( ) unimodal ( ) heteroskedastic\n\n\n\nQuestion 4\nIn which situation does the median do a better job than the mean at capturing the center of a distribution? Select the best answer.\n( ) when the median is less than the mean ( ) when the median is greater than the mean (X) when the variable under study is known to have a strongly skewed distribution ( ) when the mode doesn’t exist"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/notes.html",
    "href": "2-summarizing-data/01-summarizing-categorical-data/notes.html",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "The tools for calculating numerical summaries and graphical summaries can be cleanly divided between tools developed for categorical data and tools for numerical data. We’ll discuss each in turn, starting with categorical data.\nWhen Dr. Gorman collected data near Palmer Station, Antarctica, she recorded a total of eight variables on 333 penguins, 10 rows of which are presented here in a data frame.\nThe first two of these you’ll recognize as nominal categorical variables. The species of each penguin can take one of three levels: Adelie, Chinstrap, or Gentoo; and the island on which they were found can also take three levels: Biscoe, Dream, or Torgersen.",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/notes.html#summary",
    "href": "2-summarizing-data/01-summarizing-categorical-data/notes.html#summary",
    "title": "Summarizing Categorical Data",
    "section": "Summary",
    "text": "Summary\nA wise statistician once said, “In statistics, most of what we do is add things up. Sometimes we divide. The challenging part is deciding what to add and divide.” This captures the deceptive simplicity of summarizing categorical data. Categorical summaries involve counts of categories or proportions. Those proportions can be joint proportions, marginal proportions, or conditional proportions. Those counts and proportions are commonly displayed in contingency tables or in bar charts. Subtle choices of which proportion to present results in the telling of dramatically different stories.\nContinue on to the tutorial portion of the notes",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/labs/class-survey/lab.html",
    "href": "2-summarizing-data/labs/class-survey/lab.html",
    "title": "Class Survey",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "2-summarizing-data/labs/class-survey/lab.html#part-i-understanding-the-context-of-the-data",
    "href": "2-summarizing-data/labs/class-survey/lab.html#part-i-understanding-the-context-of-the-data",
    "title": "Class Survey",
    "section": "Part I: Understanding the Context of the Data",
    "text": "Part I: Understanding the Context of the Data\nPlease record your answers on the worksheet below and upload it to Gradescope.\n\nPart 1: Understanding the Context of the Data\n\nTo answer this worksheet, consult the printout of the original survey found here."
  },
  {
    "objectID": "2-summarizing-data/labs/class-survey/lab.html#part-ii-computing-on-the-data",
    "href": "2-summarizing-data/labs/class-survey/lab.html#part-ii-computing-on-the-data",
    "title": "Class Survey",
    "section": "Part II: Computing on the Data",
    "text": "Part II: Computing on the Data\nYou can access the real data from the Stat 20 Class Survey by adding the following line of code to a code cell at the top of your Quarto document.\n\nlibrary(tidyverse)\nclass_survey &lt;- read_csv(\"https://tinyurl.com/stat20-survey\")\n\nTo complete the following questions, you will need to find the columns in the class_survey data frame associated with each variable mentioned.\n\nQuestion 1\nDo students prefer to spend time at the beach or in the mountains?\nConstruct a plot that answers this question and calculate a measure of a typical observation (mean, median, or mode, as appropriate). Then use the plot and this summary to answer the original question in a sentence.\n\n\nQuestion 2\nIs there an association between students’ favorite season and terrain preference (beach or mountains)?\nConstruct a plot that answers this question. Use this plot to answer the question in one sentence.\n\n\nQuestion 3\nHow much coding experience do students have? (numerical scale)\nConstruct a plot that answers this question and calculate a measure of a typical observation (mean, median, or mode, as appropriate). Then use the plot and this summary to answer the original question in a sentence.\n\n\nQuestion 4\nWhat is the relationship between students’ optimism for cryptocurrency and their skepticism of the effect of technology on interpersonal relationships?\nConstruct a plot that answers this question. Use this plot to answer the question in one sentence.\n\nSix variables appear in the survey data frame that were derived from the original prof_label question: is_artist, is_humanist, is_nat_sci, is_soc_sci, is_comp_sci and is_entrepreneur. The is_artist variable is TRUE for those students who most identified as an artist and FALSE otherwise. The other five variables are defined similarly.\nFor the following four questions, please answer with a plot and a sentence or two written response given the structure in the plot.\n\n\nQuestion 5\nIs there an relationship between students most identifying as an entrepreneur and their optimism for cryptocurrency?\n\n\nQuestion 6\nIs there an relationship between students most identifying as a humanist and their optimism for cryptocurrency?\n\n\nQuestion 7\nPropose your own question involving one of the is_ variables and numerical variable of your choice. Construct a plot that addresses the question, calculate a measure of center for the two groups separately (e.g. comparing those who identify as artists with those who do not), then use them to answer your questions in one or two sentences.\n\n\nQuestion 8\nThis last one is a full choose-your-own adventure: propose your own question involving two or three variables and answer it using a plot with a written interpretation.\n\n\nLast Question\nWill you ensure that your submission to Gradescope…\n\nis of a pdf generated from a qmd file,\nhas all of your code visible to readers,\nand assigns each of the questions to all pages that show your work for that question?\n\n(This one is easy! Just answer “yes” or “no”)"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/lab.html",
    "href": "2-summarizing-data/labs/arbuthnot/lab.html",
    "title": "Arbuthnot",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/lab.html#part-1-understanding-the-context-of-the-data",
    "href": "2-summarizing-data/labs/arbuthnot/lab.html#part-1-understanding-the-context-of-the-data",
    "title": "Arbuthnot",
    "section": "Part 1: Understanding the Context of the Data",
    "text": "Part 1: Understanding the Context of the Data\nThe first part of each of our labs will be a worksheet where you’ll think more about the context of the data, help formulate your questions, and set expectations for what the data will look like. Please record your answers on the worksheet below and upload it to Gradescope as Lab 1.1.\n\nPart 1: Understanding the Context of the Data"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/lab.html#part-ii-computing-on-the-data",
    "href": "2-summarizing-data/labs/arbuthnot/lab.html#part-ii-computing-on-the-data",
    "title": "Arbuthnot",
    "section": "Part II: Computing on the Data",
    "text": "Part II: Computing on the Data\n\nQuarto Lab Format\nThe second part of each lab is your chance to dive into a real data set to answer the questions that you posed in Part 1. To ensure your analysis is reproducible, please record your answers to these questions (both the text and code) in a .qmd file. Render your work to an HTML file regularly as a check that your code is running. When you are pleased with the result, print that HTML to a pdf (File &gt; Print &gt; Save as pdf in your browser), then upload to Gradescope as Lab 1.2. See Ed for more info about lab submission.\n\n\nLab Questions\nThe first several questions pertain to the arbuthnot data frame found in library(stat20data).\n\nWhat is the time frame covered by Arbuthnot’s data?\nWhich year saw the greatest number of children christened?\nWhat is the proportion of girls christened in 1700?\nWhat is the trend over time in the total number of children christened? Please answer with a plot and written interpretation.\nWhat is the trend over time in the proportion of girls christened? Please answer with a plot and written interpretation.\n\n\nThe remaining questions pertain to the present data frame found in library(stat20data).\n\nWhat is the time frame covered by the present-day data?\nIn terms of general magnitude (size), how do the counts in Arbuthnot’s data compare to the counts in the present-day data?\nWhat is the trend over time in the proportion of births that are girls? Please answer with a plot and written interpretation.\nBased on these two data sets, what claim are you prepared to make regarding John Arbuthnot’s original question? What reservations, if any, do you have about using this data to make the claim?"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#the-goal-of-labs",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#the-goal-of-labs",
    "title": "Lab: Arbuthnot",
    "section": "The Goal of Labs",
    "text": "The Goal of Labs\n\n\nPut concepts into practice with real data\nFollow best practices in reproducible analyses (.qmd)\nIn class we’ll work on the most challenging problems\nYou likely will need to work outside of class to finish the assignment\nVisit office hours for extra help or ask on named thread on Ed"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#section",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#section",
    "title": "Lab: Arbuthnot",
    "section": "",
    "text": "What is the chance that a child born tomorrow is a girl?\n\n\nMost students will volunteer 50%. Follow up with:\n\nWhy do you think it’s 50%? How did you come to that number? - Did you read it somewhere? - Did you hear it from someone?\n\n\nIf you wanted to confirm it was 50% what would you do? - [likely answer: google it]\n\n\nWhat source for that number would you likely come across if you kept digging? - ultimately, maybe some scientific article.\n\n\nWhat would their evidence for that claim of 50%? - likely vast amounts of demographic / census data\n\n\n\n\n50%?\n\n\n\nWhat evidence do we ultimately rely upon?\n. . .\n\nVast amounts of data\n\n\nNow consider the case of a scientist who tackled this question long before google was around."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#dr.-john-arbuthnot",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#dr.-john-arbuthnot",
    "title": "Lab: Arbuthnot",
    "section": "Dr. John Arbuthnot",
    "text": "Dr. John Arbuthnot\n\n\n\n1667 - 1735\nScottish physician, mathematician, satirist\nInterested in the question of what the proportion of girls to boys was at birth\n\n\n\n\n\nA painted portrait of John Arbuthnot\n\n\n\n\n\nRead a bit about Arbuthnot on wikipedia to learn some of his backstory."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#arbuthnots-london",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#arbuthnots-london",
    "title": "Lab: Arbuthnot",
    "section": "Arbuthnot’s London",
    "text": "Arbuthnot’s London\n\n\n\n1710, St. Paul’s Cathedral completed\nVery few paved streets\nDefinitely no google\n\n\n\n\n\nA painting of London in 1710.\n\n\n\n\n\nArbuthnot was living in London while thinking about this problem. It was a period of rapid growth and modernization for the city but it still had no google.\nMain point to get across here: what we take for granted in terms of how we reason from data was nearly absent from life in 18th century UK. Most people would reason from direct experience, anecdote, appeals to tradition or religion, etc.\nIf you were Dr. Arbuthnot and you tell the person on the street: “My wife will soon be giving birth. What are the chances it’s a girl?”, what sort of answer do you think he might get? What type of information might that person be relying upon? - their own experience (the ratio of girls born in their family) - anecdotes that they’ve heard from others\nYou may want to note that even our notion of “chance” and probability was not wide spread at the time.\nArbuthnot’s work is notable because he takes the big step of realizing that an individual can learn a lot by pooling the experiences / anecdotes of others in a systematic way."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#section-1",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#section-1",
    "title": "Lab: Arbuthnot",
    "section": "",
    "text": "Where could Arbuthnot find vast amounts on systematically collected data regarding births?\n\n\n\nThe church."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#section-2",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#section-2",
    "title": "Lab: Arbuthnot",
    "section": "",
    "text": "A photograph of a page of a book of handwritten christening records taken a church in England in the 18th century\nThe church is the only organization that is collecting systematic demographic data in this era."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#section-3",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#section-3",
    "title": "Lab: Arbuthnot",
    "section": "",
    "text": "A zoomed in version of the christening records, where you can identify that each record was a single christening.\nMost children, shortly after they’re born, are taken to the nearby parish church and “christened” - given a name in the church. The parish churches record the name and date of each of these christenings.\nArbuthnot went from parish church to parish church in London, pored over these records and tallied the number of boys and girls. He then combined these counts across all of the parishes and created a data set that we can read into R today."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#what-is-a-christening-record",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#what-is-a-christening-record",
    "title": "Lab: Arbuthnot",
    "section": "What is a christening record?",
    "text": "What is a christening record?\n\nA Christening is a ceremony/rite in the Church of England where:\n\nThe parents bring their new born child to a priest at the church.\nAs part of the ceremony, the parents give a first name to the child before the child is baptized (inducted into the church).\nThe name of the child and their parents are recorded in a ledger.\n\n\n\nJohn Arbuthnot tabulated the total count of names in each year that were traditionally female and male names."
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/slides.html#your-lab-assignment",
    "href": "2-summarizing-data/labs/arbuthnot/slides.html#your-lab-assignment",
    "title": "Lab: Arbuthnot",
    "section": "Your Lab Assignment",
    "text": "Your Lab Assignment\n\n\nLab 1.1: Understanding the Context of the Data\n\nLearn context\nFormulate questions\nSet expectations\nSubmitted as pdf of worksheet\n\n\n\nLab 1.2: Computing with the Data\n\nDive into the data\nSubmitted as a pdf from a qmd."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/ps.html",
    "href": "2-summarizing-data/05-communicating-with-graphics/ps.html",
    "title": "Communicating with Graphics",
    "section": "",
    "text": "Question 1\nUse the gapminder data set in the gapminder library to recreate a version of the Hans Rosling’s famous data visualization (a single plot instead of a movie). You can revisit the slides from Grammar of Graphics to reference it.\nSome guidelines:\n\nPlot the data for just a single year. You can see at a glance which years are available by running count(gapminder, year).\nPut gdpPercap on the x-axis and lifeExp on the y-axis.\nTo distinguish the continents, you can use either shape or color. Which ever one you do not use, set its value to something other than the default.\nAlter the labels so that they’re more descriptive.\nChange to a theme of your choosing.\nAdd an annotation that draws attention to a particular feature of the data.\n\nTurn to the notes for today for guidance on how to add each of these elements.\n\n\nQuestion 2\nRecreate one of the plots that you created for Lab 2.2, but incorporate at least 3 of the 6 elements of Communicating with Graphics to polish your plot into one that tells a particular story."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html",
    "title": "Communicating with Graphics",
    "section": "",
    "text": "At this point in the course, you have a bevy of different types of statistical graphics under your belt: scatterplots, histograms, dot plots, violin plots, box plots, density curves, and bar plots of several kinds. You also have a broad framework to explain how these graphics are composed: the Grammar of Graphics. But to what purpose? Why plot data? For whom?\nEvery time you build a plot, you do so with one of two audiences in mind.\nThe process of building understanding from a data set is one that should be driven by curiosity, skepticism, and thoughtfulness. As a data scientist, you’ll find yourself in conversation with your data: asking questions of it, probing it for structure, and seeing how it responds. This thoughtful conversation is called exploratory data analysis (or EDA).\nDuring EDA, the aim is to uncover the shape and structure of your data and to uncover unexpected features. It’s an informal iterative process where you are your own audience. In this setting, you should construct graphics that work best for you.\nAt some point, you’ll find yourself confident in the claim that can be supported by your data and the focus changes to communicating that claim as effectively as possible with a graphic. Here, your audience shifts from yourself to someone else: other scientists, customers, co-workers in a different part of your company, or casual readers. You must consider the context in which they’ll be viewing your graphic: what they know, what they expect, what they want.\nIn these notes we discuss six ways to hone the message of your data visualization. They are:\nWe will use two running examples throughout these notes: a line plot of the number of christenings in 17th century London1 and a scatter plot showing the bill sizes of penguins near Palmer Station, Antarctica2."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#mapping-vs-setting",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#mapping-vs-setting",
    "title": "Communicating with Graphics",
    "section": "1. Mapping vs Setting",
    "text": "1. Mapping vs Setting\nOnce you have your first draft of a plot complete and you’re thinking about how to fine tune it for your audience, your eye will turn to the aesthetic attributes. Is that color right? What about the size of the points?\nConsider the first draft of the penguins plot above. It might feel a bit drab to have a large mass of points all in black, the same color as the labels and surrounding text. Let’s make the points blue instead to make them stand out a bit more.\n\n\nClick here when you’re ready to see the result.\n\n\n\n\n\n\n\n\n\n\n\nThis is . . . unexpected. Why did it color the points red? Is this a bug?\nWhat we’ve stumbled into is a subtle but essential distinction in the grammar of graphics: mapping vs setting. When you put an aesthetic attribute (x, color, size, etc.) into the aes() function, you’re mapping that attribute in the plot to whatever data lives in the corresponding column in the data frame. Mapping was this process:\n\n\n\n\n\nThat’s not what we set out to do here. We just wanted to tweak the look of our aesthetic attributes in a way that doesn’t have anything to do with the data in our data frame. This process is called setting the attribute.\nTo set the color to blue3, we need to make just a small change to the syntax. Let’s move the color = \"blue\" argument outside of the aes() function and into the geom_() function.\n\n\n\n\n\n\n\n\n\nAh, that looks much better!\nColor isn’t the only aesthetic attribute that you can set. Let’s increase slightly the size of our points by setting the size to three times the size of the default.\n\n\n\n\n\n\n\n\n\nIt’s not clear that that improves the readability of the plot - there is more overlap between the points now - but the setting worked. How would it have looked if instead we had mapped the size? When you map, you need a map to a column in your data frame, so let’s map size to species.\n\n\n\n\n\n\n\n\n\nWe’ve made a mess of our plot now, but it is clear what happened. R looked inside the species column, found a categorical variable with three levels and selected a distinct size for each of those levels.\nThis is another area in which the grammar of graphic guides clear thinking when constructing a graphic. The aesthetic attributes of a plot can be determined either by variability found in a data set or by fixed values that we set. The former is present in all data visualization but it’s the latter that comes into play when fine-tuning your plot for an audience."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#adding-labels-for-clarity",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#adding-labels-for-clarity",
    "title": "Communicating with Graphics",
    "section": "2. Adding Labels for Clarity",
    "text": "2. Adding Labels for Clarity\nYou may have noticed that ggplot2 pulls the labels for the x-axis, the y-axis, and the legend directly from the names of the variables in the data frame. This results in labels like bill_length_mm, which is no problem when you’re making plots for yourself - you know what this variable means. But will an outside audience?\nYou can change the labels of your plot by adding a labs() layer.\n\n\n\n\n\n\n\n\n\nAxis and legend labels should be concise and often include the units of measurement. If you find them getting too wordy, know that you can clarify or expand on what is being plotted either in a figure caption or in the accompanying text.\nSpeaking of captions, those a can be added too, as well as a title.\n\n\n\n\n\n\n\n\n\nThe title of a plot is valuable real estate for communicating the primary story of your plot. It should highlight the most important structure in the data. In the plot above, there appears to be little correspondence between bill length and bill depth. Of course, that changes when we map species to color. Let’s make that plot and title it accordingly.\n\n\n\n\n\n\n\n\n\nThe practice of using the plot title to convey the main message of the plot is used to powerful effect by the visualization experts at the British publication, The Financial Times4. They have developed a wealth of visualizations to help readers understand what is happening with public health throughout the pandemic. The sobering graphic below uses the title to guide the viewer to the most important visual structure in the plot: the yawning vertical gap between dosage rates between high and low income countries."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#the-importance-of-scale",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#the-importance-of-scale",
    "title": "Communicating with Graphics",
    "section": "3. The Importance of Scale",
    "text": "3. The Importance of Scale\nWhen a person views your plot, their first impression will be determined by a coarse interpretation of the boldest visual statement. When using a line plot, that is usually the general trend seen when reading left to right.\nWhat is the first word that comes to mind to describe the trend in each of the four plots below?\n\n\n\n\n\n\n\n\n\nClockwise from the upper left, you likely said something like “increasing”, “decreasing”, “variable”, and “stable”. Now take a second look. What exactly is being plotted here?\nThe labels along the axes are a hint to what you’re looking at here. These are, in fact, four plots from the exact same data: Arbuthnot christening records, with the proportion of girls christened on the x-axis. What differs is the limits of the x- and y-axes.\nMost software will automatically set the limits of your plot based on the range of the data. In the Arbuthnot data, the years range from 1629 to 1710 and the proportion of girls christened ranges from .463 to .497. The leads to the default graphic found in the lower left panel. Each of the other three plots have modified the limits of the x- or y-axis to capture different parts the data scaled in different ways. In ggplot2 this is done by adding an xlim() or ylim() layer.\nThis is the power of scaling. From one data set, you can convey four different (and incompatible!) messages by changing the scale. So which one is correct? It depends on the context and the question that drove the collection of the data. John Arbuthnot sought to understand the whether the chance of being born a girl is 1/2. That question is answered most clearly by the following plot (with the title driving home that main message).\n\n\n\n\n\n\n\n\n\nThe importance of scale extends beyond scatter and line plots. Barcharts are often the subject of careful scaling to convey a particular message. What do you think the goal was of the creator of the plot titled “Should Britain Leave EU?”5"
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#overplotting",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#overplotting",
    "title": "Communicating with Graphics",
    "section": "4. Overplotting",
    "text": "4. Overplotting\nIntroductory statistics students filled out a survey that asked them their opinion on several topics including:\n\n\n\n\n\n\n\n\n\n\nThe result was a data frame with 707 rows (one for every respondent) and 2 columns of discrete numerical data. A natural way to visualize this data is by creating a scatter plot.\n\n\n\n\n\n\n\n\n\nThe eye is immediately drawn to the eerie geometric regularity of this data. Isn’t real data messier than this? What’s going on?\nA hint is in the sample size. The number of observations in the data set was over 600 and yet the number of points shown here is just a bit under 100. Where did those other observations go?\nIt turns out they are in this plot, they’re just piled on on top of the other. Since there are only 10 possible values for each question, many students ended up selecting the same values for both, leading their points to be drawn on top of one another.\nThis phenomenon is called overplotting and it is very common in large data sets. There are several strategies for dealing with it, but here we cover two of them.\nOne approach to fixing the problem of points piled on top of one another is to unpile them by adding just a little bit of random noise to their x- and y-coordinate. This technique is called jittering and can be done in ggplot2 by replacing geom_point() with geom_jitter().\n\n\n\n\n\n\n\n\n\nAhh . . . there are those previously hidden students. Interestingly, the title on the first plot still holds true: even when we’re looking at all of the students, there doesn’t appear to be much of a pattern. There is certainly not the case in all overplotted data sets! Often overplotting will obscure a pattern that jumps out after the overplotting has been attended to.\nThe second technique is to make the points transparent by changing an aestheric attribute called the alpha value. Let’s combine tranparency with jittering to understand the effect.\n\n\n\n\n\n\n\n\n\nAlpha is a number between 0 and 1, where 1 is fully opaque and 0 is fully see-through. Here, alpha = .3, which changes all observations from black to gray. Where the points overlap, their alpha values add to create a dark blob.\nThere’s still no sign of a strong association between these variables, but at least, by taking overplotting into consideration, we’ve made that determination after incorporating all of the data."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#choosing-a-theme",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#choosing-a-theme",
    "title": "Communicating with Graphics",
    "section": "5. Choosing a Theme",
    "text": "5. Choosing a Theme\nWhat piece of software did I use to produce the following plot?\n\n\n\n\n\n\n\n\n\nIf you said “Excel”, you are correct! Well… it is Excel in spirit. What makes this plot look like it was made in Excel are a series of small visual choices that were made: the background is a dark gray, there are black horizontal guide lines, and the plot and the legend is surrounded by a black box. Small decisions like these that effect the overall look and feel of the plot are called the theme.\nLet’s look at a few more. Do they look familiar?\n\n\n\n\n\n\n\n\n\nThey are, from top to bottom, a theme based on The Wall Street Journal, The Economist, and one of the themes built into ggplot2 packaged called bw for “black and white” (there are no grays). The ggplot2 library has several themes to choose from and yet more live in other packages like ggthemes. To use a theme, all you need to do is add a layer called theme_NAME (e.g. for the black and white theme, use theme_bw).\nThemeing your plots is an easy way to change the look of your plot. Tinker with a few different themes and considering adding them to your labs6. But, as with all design decisions around graphics, be sure to think about your audience. You might find the Excel aesthetics ugly and dated, but will your audience? If you’re presenting your plot to a community that works with Excel plots day in and day out, that’s probably a sound choice. If you are preparing a plot for submission to a scientific journal, a more minimalist theme is more appropriate."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#annotations",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#annotations",
    "title": "Communicating with Graphics",
    "section": "6. Annotations",
    "text": "6. Annotations\nIn the same way that a title highlights the main message of a plot, you can rely upon visual cues to draw attention to certain components or provide helpful context.\nThe christening records collected by John Arbuthnot, although they seem like a very simple data set, actually capture a wealth of historical information. We can add this information to our plot by adding annotations.\n\n\n\n\n\n\n\n\n\nWere you curious about what caused that dip in the number of christenings in 17th century London? It happens to correspond to the duration of the English Civil War, when the monarchy was overthrown by a dictator named Oliver Cromwell. This very important context can be conveyed by adding a text label and a line segment through two new annotate() layers.\nWithin ggplot2, annotations are a flexible way to add the context or comparisons that help guide readers in interpreting your data. You can add text, shapes, lines, points. To learn more, consult the documentation7.\nSo if the drop after 1642 corresponds to the English Civil War, what about the spike down around 1666? What about 1703? If you’re curious, explore Wikipedia to find out and add those events as annotations to this plot."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#summary",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#summary",
    "title": "Communicating with Graphics",
    "section": "Summary",
    "text": "Summary\nThere are two main uses for data visualization. The first is as part of exploratory data analysis, when you are constructing plots for yourself to better understand the structure of the data. When you’re ready to communicate with an outside audience using graphics, more thought is needed: you must think about the difference between mapping and setting, the use of labels for clarity, the importance of scale, overplotting, themes, and annotations.\nThis is far from a complete list of what all can be done to improve your plots, but it is sufficient to produce polished graphics that effectively communicate your message."
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/notes.html#footnotes",
    "href": "2-summarizing-data/05-communicating-with-graphics/notes.html#footnotes",
    "title": "Communicating with Graphics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor data documentation, see the stat20data R package.↩︎\nFor data documentation, see the palmerpenguins R package.↩︎\nTo see the vast (and somewhat strange) palette of color names that R knows, type colors() at the console.↩︎\nVisualization drawn from the excellent collection of graphics at the Financial Times Covid Tracker https://ig.ft.com/coronavirus-vaccine-tracker/.↩︎\nGraphics from the keynote of John Burn-Murdoch at rstudio::conf() 2021.↩︎\nExplore the themes available within ggplot2 by reading the documentation https://ggplot2.tidyverse.org/reference/ggtheme.html. For the additional themes held in the ggthemes package, read this: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/.↩︎\nDocumentation for annotation layers in ggplot2: https://ggplot2.tidyverse.org/reference/annotate.html.↩︎"
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "In the last lecture we built our first linear model: an equation of a line drawn through the scatter plot.\n\\[ \\hat{y} = 96.2 + -0.89 x \\]\nWhile the idea is simple enough, there is a sea of terminology that floats around this method. A linear model is any model that explains the \\(y\\), often called the response variable or dependent variable, as a linear function of the \\(x\\), often called the explanatory variable or independent variable. There are many different methods that can be used to decide which line to draw through a scatter plot. The most commonly-used approach is called the method of least squares, a method we’ll look at closely when we turn to prediction. If we think more generally, a linear model fit by least squares is one example of a regression model, which refers to any model (linear or non-linear) used to explain a numerical response variable.\nThe reason for all of this jargon isn’t purely to infuriate students of statistics. Linear models are one of the most widely used statistical tools; you can find them in use in diverse fields like biology, business, and political science. Each field tends to adapt the tool and the language around them to their specific needs.\nA reality of practicing statistics in these field, however, is that most data sets are more complex than the example that we saw in the last notes, where there were only two variables. Most phenomena have many different variables that relate to one another in complex ways. We need a more more powerful tool to help guide us into these higher dimensions. A good starting point is to expand simple linear regression to include more than one explanatory variable!"
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#multiple-linear-regression",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#multiple-linear-regression",
    "title": "Multiple Linear Regression",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nMultiple Linear Regression\n\nA method of explaining a continuous numerical \\(y\\) variable in terms of a linear function of \\(p\\) explanatory terms, \\(x_i\\). \\[ \\hat{y} = b_0 + b_1x_1 + b_2x_2 + \\ldots +b_px_p \\] Each of the \\(b_i\\) are called coefficients.\n\n\nTo fit a multiple linear regression model using least squares in R, you can use the lm() function, with each additional explanatory variable separated by a +.\nMultiple linear regression is powerful because it has no limit to the number of variables that we can include in the model. While Hans Rosling was able to fit 5 variables into a single graphic, what if we had 10 variables? Multiple linear regression allows us to understand high dimensional linear relationships beyond whats possible using our visual system.\nIn today’s notes, we’ll discuss two specific examples where a multiple linear regression model might be applicable\n\nA scenario involving two numerical variables and one categorical variable\nA scenario involving three numerical variables."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#two-numerical-one-categorical",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#two-numerical-one-categorical",
    "title": "Multiple Linear Regression",
    "section": "Two numerical, one categorical",
    "text": "Two numerical, one categorical\nThe Zagat Guide was for many years the authoritative source of restaurant reviews. Their approach was very different from Yelp!. Zagat’s review of a restaurant was compiled by a professional restaurant reviewer who would visit a restaurant and rate it on a 30 point scale across three categories: food, decor, and service. They would also note the average price of a meal and write up a narrative review.\nHere’s an example of a review from an Italian restaurant called Marea in New York City.\n\n\n\n\n\nIn addition to learning about the food scores (27), and getting some helpful tips (“bring your bank manager”), we see they’ve also recorded a few more variables on this restaurant: the phone number and website, their opening hours, and the neighborhood (Midtown).\nYou might ask:\n\nWhat is the relationship between the food quality and the price of a meal at Italian restaurant? Are these two variables positively correlated or is the best Italian meal in New York a simple and inexpensive slice of pizza?\n\nTo answer these questions, we need more data. The data frame below contains Zagat reviews from 168 Italian restaurants in Manhattan.\n\n\n# A tibble: 168 × 6\n   restaurant          price  food decor service geo  \n   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;\n 1 Daniella Ristorante    43    22    18      20 west \n 2 Tello's Ristorante     32    20    19      19 west \n 3 Biricchino             34    21    13      18 west \n 4 Bottino                41    20    20      17 west \n 5 Da Umberto             54    24    19      21 west \n 6 Le Madri               52    22    22      21 west \n 7 Le Zie                 34    22    16      21 west \n 8 Pasticcio              34    20    18      21 east \n 9 Belluno                39    22    19      22 east \n10 Cinque Terre           44    21    17      19 east \n# ℹ 158 more rows\n\n\nApplying the taxonomy of data, we see that for each restaurant we have recorded the price of an average meal, the food, decor, and service scores (all numerical variables) as well as a note regarding geography (a categorical nominal variable). geo captures whether the restaurant is located on the east side or the west side of Manhattan1.\nLet’s summarize the relationship between food quality, price, and one categorical variable - geography - using a colored scatter plot.\n\n\n\n\n\n\n\n\n\nIt looks like if you want a very tasty meal, you’ll have to pay for it. There is a moderately strong, positive, and linear relationship between food quality and price. This plot, however, has a third variable in it: geography. The restaurants from the east and west sides are fairly well mixed, but to my eye the points on the west side might be a tad bit lower on price than the points from the east side. I could numerically summarize the relationship between these three variables by hand-drawing two lines, one for each neighborhood.\n\n\n\n\n\nFor a more systematic approach for drawing lines through the center of scatter plots, we need to return to the method of least squares, which is done in R using lm(). In this linear model, we wish to explain the \\(y\\) variable as a function of two explanatory variables, food and geo, both found in the zagat data frame. We can express that relationship using the formula notation.\n\n\n\nCall:\nlm(formula = price ~ food + geo, data = zagat)\n\nCoefficients:\n(Intercept)         food      geowest  \n    -15.970        2.875       -1.459  \n\n\nIt worked . . . or did it? If extend our reasoning from the last notes, we should write this model as\n\\[\\widehat{price} = -15.97 + 2.87 \\times food - 1.45 \\times geo\\]\nWhat does it mean to put a categorical variable, geo, into a linear model? And how do three three numbers translate into the two lines shown above?\n\nIndiciator variables\nWhen working with linear models like the one above, the value of the explanatory variable, \\(geowest\\), is multiplied by a slope, 1.45. According to the Taxonomy of Data, arithmetic functions like multiplication are only defined for numerical variables. While that would seem to rule out categorical variables for use as explanatory variables, statisticians have come up with a clever work-around: the indicator variable.\n\nIndicator Variable\n\nA variable that is 1 if an observation takes a particular level of a categorical variable and 0 otherwise. A categorical variable with \\(k\\) levels can be encoded using \\(k-1\\) indicator variables.\n\n\nThe categorical variable geo can be converted into an indicator variable by shifting the question from “Which side of Manhattan are you on?” to “Are you on the west side of Manhattan?” This is a mutate step.\n\n\n# A tibble: 168 × 4\n    food price geo   geowest\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;  \n 1    22    43 west  TRUE   \n 2    20    32 west  TRUE   \n 3    21    34 west  TRUE   \n 4    20    41 west  TRUE   \n 5    24    54 west  TRUE   \n 6    22    52 west  TRUE   \n 7    22    34 west  TRUE   \n 8    20    34 east  FALSE  \n 9    22    39 east  FALSE  \n10    21    44 east  FALSE  \n# ℹ 158 more rows\n\n\nThe new indicator variable geowest is a logical variable, so it has a dual representation as TRUE/FALSE as well as 1/0. Previously, this allowed us to do Boolean algebra. Here, it allows us to include an indicator variable in a linear model.\nWhile you can create indicator variables by hand using mutate, in practice, you will not need to do this. That’s because they are created automatically whenever you put a categorical variable into lm(). Let’s revisit the linear model that we fit above with geowest in the place of geo.\n\\[\\widehat{price} = -15.97 + 2.87 \\times food - 1.45 \\times geowest\\]\nTo understand the geometry of this model, let’s focus on what the fitted values will be for any restaurant that is on the west side. For those restaurants, the geowest indicator variable will take a value of 1, so if we plug that in and rearrange,\n\\[\\begin{eqnarray}\n\\widehat{price} &= -15.97 + 2.87 \\times food - 1.45 \\times 1 \\\\\n&= (-15.97 - 1.45) + 2.87 \\times food \\\\\n&= -17.42 + 2.87 \\times food\n\\end{eqnarray}\\]\nThat is a familiar sight: that is an equation for a line.\nLet’s repeat this process for the restaurants on the east side, where the geowest indicator variable will now take a value of 0.\n\\[\\begin{eqnarray}\n\\widehat{price} &= -15.97 + 2.87 \\times food - 1.45 \\times 0 \\\\\n&= -15.97 + 2.87 \\times food\n\\end{eqnarray}\\]\nThat is also the equation for line.\nIf you look back and forth between these two equations, you’ll notice that they share the same slope and have different y-intercepts. Geometrically, this means that the output of lm() was describing the equation of two parallel lines:\n\none where geowest is 1 (for restaurants on the west side of town)\none where geowest is 0 (for restaurants on the east side of town).\n\nThat means we can use the output of lm() to replace my hand-drawn lines with ones that arise from the method of least squares.\n\n\n\n\n\n\n\n\n\n\n\nReference levels\nOne question you still might have: Why did R include the indicator variable for the west side of town as opposed to the one for the east side?. The answer lies in the type of variable that geo is recorded as in the zagat dataframe. If you look closely at the initial output, you will see that geo is currently designated chr, which is short for character. geo is indeed a categorical variable with two levels: east and west.\nLike in previous settings, R will determine the “order” of levels in a categorical variable registered as a character by way of the alphabet. This means that east will be tagged first and chosen as the reference level: the level of a categorical variable which does not have an indicator variable in the model. If you would like west to be the reference level, then you would need to reorder the levels using factor() inside of a mutate() so that west comes first. This would change the equation that results from then fitting a linear model with lm(), as you can see below!\n\n\n\nCall:\nlm(formula = price ~ food + geo, data = mutate(zagat, geo = factor(geo, \n    levels = c(\"west\", \"east\"))))\n\nCoefficients:\n(Intercept)         food      geoeast  \n    -17.430        2.875        1.459  \n\n\nNow our equation looks a little bit different!\n\\[\\widehat{price} = -17.43 + 2.87 \\times food + 1.46 \\times geoeast\\]\nIn general, if you include a categorical variable with \\(k\\) levels in a regression model, there will be \\(k-1\\) indicator variables (and thus, coefficients) associated with it in the model: one for each level of the variable except the reference level2. Knowing the reference level also helps us interpret indicator variables that are part of the regression equation; we will see this in a moment. For now, let’s move to our second scenario."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#three-numerical",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#three-numerical",
    "title": "Multiple Linear Regression",
    "section": "Three numerical",
    "text": "Three numerical\nWhile the standard scatter plot allows us to understand the association between two numerical variables like price and food, to understand the relationship between three numerical variables, we will need to build this scatterplot in 3D3.\n\n\n\n\n\n\n\n\n\n\n\n\nTake a moment to explore this scatter plot4. Can you find the name of the restaurant with very bad decor but pretty good food and a price to match? (It’s Gennaro.) What about the restaurant that equally bad decor but has rock bottom prices that’s surprising given it’s food quality isn’t actually somewhat respectable? (It’s Lamarca.)\nInstead of depicting the relationship between these three variables graphically, let’s do it numerically by fitting a linear model.\n\n\n\nCall:\nlm(formula = price ~ food + decor, data = zagat)\n\nCoefficients:\n(Intercept)         food        decor  \n    -24.500        1.646        1.882  \n\n\nWe can write the corresponding equation of the model as\n\\[ \\widehat{price} = -24.5 + 1.64 \\times food + 1.88 \\times decor \\]\nTo understand the geometry of this model, we can’t use the trick that we did with indicator variables. decor is a numerical variable just like food, so it takes more values than just 0 and 1.\nIndeed this linear model is describing a plane.\n\n\n\n\n\n\n\n\n\n\n\n\nIf you inspect this plane carefully you’re realize that the tilt of the plane is not quite the same in every dimension. The tilt in the decor dimension is just a little bit steeper than that in the food dimension, a geometric expression of the fact that the coefficient in front of decor, 1.88, is just a bit higher than the coefficient in front of food, 1.64."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#interpreting-coefficients",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#interpreting-coefficients",
    "title": "Multiple Linear Regression",
    "section": "Interpreting coefficients",
    "text": "Interpreting coefficients\nWhen moving from simple linear regression, with one explanatory variable, to the multiple linear regression, with many, the interpretation of the coefficients becomes trickier but also more insightful.\n\nThree numerical\nMathematically, the coefficient in front of \\(food\\), 1.64, can be interpreted a few different ways:\n\nIt is the difference that we would expect to see in the response variable, \\(price\\), when two Italian restaurants are separated by a food rating of one and they have the same decor rating.\nControlling for \\(decor\\), a one point increase in the food rating is associated with a $1.64 increase in the \\(price\\).\n\nSimilarly for interpreting \\(decor\\): controlling for the quality of the food, a one-point increase in \\(decor\\) is associated with a $1.88 increase in the \\(price\\).\n\n\nTwo numerical, one categorical\nThis conditional interpretation of the coefficients extends to the first setting we looked at, when one variable is numerical and the other is an indicator. Here is that model:\n\\[\\widehat{price} = -15.97 + 2.87 \\times food - 1.45 \\times geowest\\]\nOne might interpret \\(food\\) like this:\n\nFor two restaurants both on the same side of Manhattan, a one point increase in food score is associated with a $2.87 increase in the price of a meal.\n\nAs for \\(geowest\\):\n\nFor two restaurants with the exact same quality of food, the restaurant on the west side is expected to be $1.45 cheaper than the restaurant on the east side.\n\nWe make the comparison to the the east side since this level is the reference level according to the linear model shown. This is a useful bit of insight - it gives a sense of what the premium is of being on the eastside.\nIt is also visible in the geometry of the model. When we’re looking at restaurants with the same food quality, we’re looking at a vertical slice of the scatter plot. Here the vertical gray line is indicating restaurants where the food quality gets a score of 18. The difference in expected price of meals on the east side and west side is the vertical distance between the red line and the blue line, which is exactly 1.45. We could draw this vertical line anywhere on the graph and the distance between the red line and the blue will still be exactly 1.45."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#summary",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#summary",
    "title": "Multiple Linear Regression",
    "section": "Summary",
    "text": "Summary\nWe began this unit on Summarizing Data with graphical and numerical summaries of just a single variable: histograms and bar charts, means and standard deviations. In the last set of notes we introduced our first bivariate numerical summaries: the correlation coefficient, and the linear model. In these notes, we introduced multiple linear regression, a method that can numerically describe the linear relationships between an unlimited number of variables. The types of variables that can be included in these models is similarly vast. Numerical variables can be included directly, generalizing the geometry of a line into a plane in a higher dimension. Categorical variables can be included using the trick of creating indicator variables: logical variables that take a value of 1 where a particular condition is true. The interpretation of all of the coefficients that result from a multiple regression is challenging but rewarding: it allows us to answer questions about the relationship between two variables after controlling for the values of other variables.\nIf this felt like a deep dive into a multiple linear regression, don’t worry. Linear models are one of the most commonly used statistical tools, so we’ll be revisiting them throughout the course: investigating their use in making generalizations, causal claims, and predictions."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/notes.html#footnotes",
    "href": "2-summarizing-data/07-multiple-linear-regression/notes.html#footnotes",
    "title": "Multiple Linear Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFifth Avenue is the wide north-south street that divides Manhattan into an east side and a west side.↩︎\nThis is the case for a model including an intercept term; these models will be our focus this semester and are the most rcommonly used.↩︎\nWhile ggplot2 is the best package for static statistical graphics, it does not have any interactive functionality. This plot was made using a system called plotly, which can be used both in R and Python. Read more about how it works at https://plotly.com/r/.↩︎\nThis is a screenshot from an interactive 3D scatter plot. We’ll see the interactive plot in class tomorrow.↩︎"
  },
  {
    "objectID": "assets/final-exam-slide.html#section",
    "href": "assets/final-exam-slide.html#section",
    "title": "Final Exam",
    "section": "",
    "text": "Before the exam begins\n\n🧹 Clear your desk of everything except a pen/pencil, your cheat sheet, and your ID.\n🧢 Remove hats, hoods, and sunglasses.\n📱 All electronic devices (laptop, phone, airbuds, smart watch) should be remain in your bag for the entire class period. All items should be on the floor not on nearby seats.\nSpread out as much as possible. We may reseat you to space people out.\nWhen you get an exam, do not begin.\n\n\nDuring the exam\n\n✅ All answers must be marked on the answer sheet.\n👀 If a proctor sees your eyes wandering to other students’ work, you will be reseated. If it happens again, it is considered academic misconduct.\nIf you need to use the bathroom, bring phone and exam materials to the front of the class.\n⌛ When you are done with this exam, please bring your exam, answer sheet, and cheat sheet to a proctor at the front of the class.\n\n\nGood luck! 🍀\n\n\n\n−+\n90:00\n\n\n\n\n\n\n−+\n90:00"
  },
  {
    "objectID": "6-prediction/labs/07-baseball/slides.html#baseball-rules",
    "href": "6-prediction/labs/07-baseball/slides.html#baseball-rules",
    "title": "Lab 5: Multiple Regression with Baseball",
    "section": "Baseball Rules",
    "text": "Baseball Rules\n\n\nKey terms to define here are Runs (R) and Wins (W). Here’s a helpful glossary from MLB: https://www.mlb.com/glossary"
  },
  {
    "objectID": "6-prediction/labs/07-baseball/slides.html#baseball-rules-1",
    "href": "6-prediction/labs/07-baseball/slides.html#baseball-rules-1",
    "title": "Lab 5: Multiple Regression with Baseball",
    "section": "Baseball Rules",
    "text": "Baseball Rules"
  },
  {
    "objectID": "6-prediction/labs/07-baseball/slides.html#sabermetrics",
    "href": "6-prediction/labs/07-baseball/slides.html#sabermetrics",
    "title": "Lab 5: Multiple Regression with Baseball",
    "section": "Sabermetrics",
    "text": "Sabermetrics\nCoined by Bill James in 1980, sabermetrics is\n\n“the search for objective knowledge about baseball.”"
  },
  {
    "objectID": "6-prediction/labs/07-baseball/slides.html#history-of-sabermetrics",
    "href": "6-prediction/labs/07-baseball/slides.html#history-of-sabermetrics",
    "title": "Lab 5: Multiple Regression with Baseball",
    "section": "History of Sabermetrics",
    "text": "History of Sabermetrics\n\nHenry Chadwick, a NY sportswriter, developed the box score in 1859\n“Percentage Baseball” by Earnshaw Cook in 1964\nThe Bill James Baseball Abstract, annual book beginning in 1977\nMoneyball"
  },
  {
    "objectID": "glossary-fns.html",
    "href": "glossary-fns.html",
    "title": "Functions",
    "section": "",
    "text": "Questions and Data"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Prerequisites\nInstall Docker.\nIf you are running on a computer with Apple Silicon (using a new “M” processor), - Update macOS to Venture 13 or newer. - Install Apple’s Rosetta emulation by running softwareupdate --install-rosetta. - In Docker Desktop, enable Settings &gt; Features in development &gt; Use Rosetta for x86/amd64 emulation on Apple Silicon.\nIf you are running Microsoft Windows, - Install WSL. - In a Command or Power Shell window, run wsl --install -d Ubuntu. - In an Ubuntu window, run apt update, then apt install make. - Run exec ssh-agent bash to start your SSH agent.\nCheckout this repository into a new working directory.\n\n\nRun the Container\nIn a terminal window, change into the working directory and run make up. This initializes your environment by creating the file .env. It then runs docker compose.\nWhen your environment changes, for example if you log out and back in, or if you manually copy your working directory to another platform, run make clean or manually delete the .env file. Then run make up.\n\n\nBuild a Custom Image (WIP)\nThe container is normally built automatically by a CI process on GitHub Actions. If you need to alter the image, for example if you want to locally test a new library addition, you can do the following:\n\nCheckout the https://github.com/stat20/stat20-docker repository.\nMake any changes\nRun docker build -t somename:sometag .. If on an alternative hardware platform like Apple’s ARM (modern Apple computers), you can run docker build -t somename:sometag --platform linux/amd64 ..\nCreate a new file names docker-compose.override.yml with the following contents:\n\nversion: \"3.8\"\nservices:\n  stat20:\n    image: somename:sometag"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#agenda",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#agenda",
    "title": "Understanding the World with Data",
    "section": "Agenda",
    "text": "Agenda\n\nIntroductions\nThe Data Science Lifecycle\nTypes of Claims with Practice\nCourse Structure and Syllabus\nIntro to R and RStudio\nLooking forward"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "What’s going on here?"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-2",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-2",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "As a group, formulate at least three possible explanations for what’s going on in the picture.\n\n\n\n\n  \n    −\n    +\n \n 03:00"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-4",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-4",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "These three photos were taken in quick succession by a physician and amateur photographer who was vising the San Diego Zoo Safari Park. He was watching the shoebill as it was walking down a path in the reeds. As the shoebill was ambling along, it encountered a duck in the middle of the path. It leaned down, picked up the duck in its beak, turned to the side, dropped the duck in the reeds, then proceeded to amble down the path."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-5",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-5",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Understand\nthe World\n\n\n\nData"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-6",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-6",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Understand\nthe World\n\n\n\nData"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#takeaways-from-this-exercise",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#takeaways-from-this-exercise",
    "title": "Understanding the World with Data",
    "section": "Takeaways from this exercise",
    "text": "Takeaways from this exercise\nWe can call the process of:\n\nhaving a question,\n\n\n\nfinding data to investigate that question,\n\n\n\n\nreaching a conclusion,\n\n\n\n\nand then thinking of a next step which starts everything over again\n\n\n\n\nthe data science lifecycle.\n\nThis lifecycle involves constructing and critiquing claims made using data: which is the main goal of our course!"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#course-goal",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#course-goal",
    "title": "Understanding the World with Data",
    "section": "Course Goal",
    "text": "Course Goal\n\n\nTo learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-7",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-7",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-8",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-8",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-9",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-9",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-10",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-10",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-11",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-11",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-12",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-12",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "To learn to critique and construct\nclaims made using data."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-13",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-13",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "A numerical, graphical, or verbal description of an aspect of data that is on hand.\n\n\n\n\n\n\nExample\nUsing data from the Stat 20 class survey, the proportion of respondents to the survey who reported having no experience writing computer code is 70%."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-14",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-14",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "A numerical, graphical, or verbal description of a broader set of units than those on which data was been recorded.\n\n\n\n\n\n\n\nExample\nUsing data from the Stat 20 class survey, the proportion of Berkeley students who have no experience writing computer code is 70%."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-15",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-15",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "A claim that changing the value of one variable will influence the value of another variable.\n\n\n\n\n\n\nExample\nData from a randomized controlled experiment shows that taking a new antibiotic eliminates more than 99% of bacterial infections."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-16",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-16",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "A guess about the value of an unknown variable, based on other known variables.\n\n\n\n\n\n\nExample\nBased on reading the news and the price of Uber’s stock today, I predict that Uber’s stock price will go up 1.2% tomorrow."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#practice-concept-questions-1",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#practice-concept-questions-1",
    "title": "Understanding the World with Data",
    "section": "Practice Concept Questions",
    "text": "Practice Concept Questions\nWe will now re-examine a few pathways in the data science lifecycle:\n\nForming a question -&gt; collecting data\n\n\n\nCollecting data -&gt; making a claim"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#from-questions-to-data",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#from-questions-to-data",
    "title": "Understanding the World with Data",
    "section": "From Questions to Data",
    "text": "From Questions to Data\n\n\nIs the incidence of COVID on campus going up or down?\n\n\n\n\nDiscuss:\nA. What type of data can help answer this question? Consider\n\nWhich different people / institutions collect relevant data\nIs certain data not available? Why not?\n\nB. Will this question be answered by a summary, a prediction, a generalization, or a causal claim?\n\n\n  \n    −\n    +\n \n 06:00"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#from-data-to-claims",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#from-data-to-claims",
    "title": "Understanding the World with Data",
    "section": "From Data to Claims",
    "text": "From Data to Claims\nOne source of data:\n\n\n\n\n\n“The following dashboard provides information on COVID-19 testing performed at University Health Services or through the PCR Home Test Vending Machines on campus. It does not capture self-reported positive tests. It provides a look at new cases and trends, at a glance.”"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-17",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-17",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Formulate one claim that is supported by this data1.\n\n\n  \n    −\n    +\n \n 03:00\n \nThe positivity rate is the number of positive tests over the total number of tests."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-23",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-23",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Read lecture notes\nWork through reading questions\n\n\n\n\n\nWork through concept questions solo / in groups / as a class\nMake progress on assignments"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#section-24",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#section-24",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "All of the materials and links for the course can be found at:\nhttps://stat20.berkeley.edu/fall-2024"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#ed-discussion-forum",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#ed-discussion-forum",
    "title": "Understanding the World with Data",
    "section": "Ed Discussion Forum",
    "text": "Ed Discussion Forum\n\n\n\n\n\nForum to ask questions, answer questions, and course announcements\nPlease answer each other’s questions!\n\n\nPractice by asking/answering a question on the “Syllabus Discussion” thread on Ed via the link on the course website."
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#load-the-lab-1-template-into-rstudio",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#load-the-lab-1-template-into-rstudio",
    "title": "Understanding the World with Data",
    "section": "Load the Lab 1 Template into RStudio",
    "text": "Load the Lab 1 Template into RStudio\nClick the link below…\n\n\n\n\nLoad Lab Templates into RStudio"
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/slides.html#general-lab-workflow",
    "href": "1-questions-and-data/01-understanding-the-world/slides.html#general-lab-workflow",
    "title": "Understanding the World with Data",
    "section": "General Lab Workflow",
    "text": "General Lab Workflow\n\nLab Questions will be posted to the course website.\nYou’ll author your Lab Reports as Quarto Documents that blend text and code. They should contain only answers.\nRender your .qmd file to a .pdf file then download that file from RStudio to your computer.\nGo to Gradescope and upload your .pdf lab report, being sure to assign questions to the pages."
  },
  {
    "objectID": "1-questions-and-data/labs/unvotes/lab.html",
    "href": "1-questions-and-data/labs/unvotes/lab.html",
    "title": "UN Votes",
    "section": "",
    "text": "Answer the following questions in the Quarto document template linked in the slides for the first day of class. Render the document, download the resulting pdf file, and submit it to Gradescope."
  },
  {
    "objectID": "1-questions-and-data/labs/unvotes/lab.html#the-context-of-the-data",
    "href": "1-questions-and-data/labs/unvotes/lab.html#the-context-of-the-data",
    "title": "UN Votes",
    "section": "The Context of the Data",
    "text": "The Context of the Data\nSince its founding in 1946, the United Nation has regularly put forth resolutions that aim to express the will of its members. Impactful historical resolutions have involved the Declaration of Human Rights in 1948, a prohibition on the use of nuclear and thermonuclear weapons in 1968, and the establishment of a no-fly zone in Libya in 2011. After each resolution is proposed, it is voted on in a roll-call vote of the member nations.\nThe data set at hand contains the voting records of every nation in the UN from 1946 - 2019 on three different issues: Colonialism, Human Rights, and Nuclear Weapons."
  },
  {
    "objectID": "1-questions-and-data/labs/unvotes/lab.html#computing-on-the-data",
    "href": "1-questions-and-data/labs/unvotes/lab.html#computing-on-the-data",
    "title": "UN Votes",
    "section": "Computing on the Data",
    "text": "Computing on the Data\n\nQuestion 1\nCreate a data visualization the shows the proportion of “yes” votes over time on three different issues: Colonialism, Human Rights, and Nuclear Weapons. Construct the plot to compare the voting patterns of the United States, the United Kingdom, and one other country of your choosing (not Turkey).\n\n\nQuestion 2\nFormulate two claims about voting behavior that is supported by this graphic. Categorize each claim as begin a summary, generalization, causal claim, or prediction.\n\n\nQuestion 3\nWhat else would you like to learn about this data set or the context of voting at the United Nations that would allow you to make more informed, accurate, thoughtful, and effective claims? List three specific items."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-as-data",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-as-data",
    "title": "Taxonomy of Data",
    "section": "Images as data",
    "text": "Images as data\n\n\n\nImages are composed of pixels (this image is 1520 by 1012)\nThe color in each pixel is in RGB\n\nEach band takes a value from 0-255\nThis image is data with 1520 x 1012 x 3 values."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#grayscale",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#grayscale",
    "title": "Taxonomy of Data",
    "section": "Grayscale",
    "text": "Grayscale\n\n\n\nGrayscale images have only one band\n0 is black, 255 is white\nThis image is data with 1520 x 1012 x 1 values."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#grayscale-1",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#grayscale-1",
    "title": "Taxonomy of Data",
    "section": "Grayscale",
    "text": "Grayscale\n\n\nTo simplify, assume our photos are 8 x 8 grayscale images."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-in-a-data-frame",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-in-a-data-frame",
    "title": "Taxonomy of Data",
    "section": "Images in a Data Frame",
    "text": "Images in a Data Frame\nConsider the following images which are our data:\n\n\n\n\n\n\n\n\n\nLet’s simplify them to 8 x 8 grayscale images"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-in-a-data-frame-1",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#images-in-a-data-frame-1",
    "title": "Taxonomy of Data",
    "section": "Images in a Data Frame",
    "text": "Images in a Data Frame\n\n\n\n\n\n\n\n\n\nIf you were to put the data from these (8 x 8 grayscale) images into a data frame, what would the dimensions of that data frame be in rows x columns? Answer at pollev.com.\n\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#a-note-on-variables",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#a-note-on-variables",
    "title": "Taxonomy of Data",
    "section": "A note on variables",
    "text": "A note on variables\nThere are three things that “variable” could be referring to:\n\n\na phenomenon\nhow the phenomenon is being recorded or measured into data\n\nwhat values can it take? (this is often an intent- or value-laden exercise!)\nfor numerical units, what unit should we express it in?\n\nHow the recorded data is being analyzed\n\nmight you bin/discretizing income data? what are the consequences of this?\n\n\n\n\n\nFor the following question, you may work under the second definition."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#what-type-of-variable-is-age",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#what-type-of-variable-is-age",
    "title": "Taxonomy of Data",
    "section": "What type of variable is age?",
    "text": "What type of variable is age?\nFor each of the following scenarios where age could be a variable, choose the most appropriate taxonomy according to the Taxonomy of Data.\n\n\nAges of television audiences/demographics\nAges of UC Berkeley students\nThe age of a rock\n\n\n\n\nAnswer at pollev.com.\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-1",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-1",
    "title": "Taxonomy of Data",
    "section": "Educated Guess 1",
    "text": "Educated Guess 1\n\nWhat will happen here?\n\n\nAnswer at pollev.com/&lt;name&gt;\n\n\n\n\n1 + \"one\"\n\n\n  \n    −\n    +\n \n 01:00\n \n\n\n“one” is a string with no link at all to the number 1\nwithout that link, without two objects that are recognized for their numerical value, + doesn’t work."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-2",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-2",
    "title": "Taxonomy of Data",
    "section": "Educated Guess 2",
    "text": "Educated Guess 2\n\nWhat will happen here?\n\n\nAnswer at pollev.com/&lt;name&gt;\n\n\n\n\na &lt;- c(1, 2, 3, 4)\nsqrt(log(a))\n\n\n  \n    −\n    +\n \n 01:00\n \n\nTalking points - a is a vector of length four - log and sqrt are functions that will return vectors of length four - they’re nested and will be evaluated from the inside out"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-3",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-3",
    "title": "Taxonomy of Data",
    "section": "Educated Guess 3",
    "text": "Educated Guess 3\n\nWhat will happen here?\n\n\nAnswer at pollev.com/&lt;name&gt;\n\n\n\n\na &lt;- 1 + 2\na + 1\n\n\n  \n    −\n    +\n \n 01:00\n \n\n\na is a not a string, it’s the name of an object that’s a number\nto overwrite a with a + 1 requires re-assigning it to a: a &lt;- a + 1 (in some languages, a + 1 would change the value of a)\na &lt;- a + 1 is a good time to mention that while a = a + 1 works in R and they might see it online, its convention to use &lt;- for many reasons including that mathematically the statement with = is confusing."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-4",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#educated-guess-4",
    "title": "Taxonomy of Data",
    "section": "Educated Guess 4",
    "text": "Educated Guess 4\n\nWhat will happen here?\n\n\nAnswer at pollev.com/&lt;name&gt;\n\n\n\n\na &lt;- c(1, 3.14, \"seven\")\nclass(a)\n\n\n  \n    −\n    +\n \n 01:00\n \n\n\nthe definition of a vector requires every element to be of the same type\nbased on their reading, there are three classes that they’re familiar with: numeric, factor, and character\nthere’s no way to translate “seven” into 7, so instead 1 and 3.14 must be translated into strings\nthey will likely encounter this when looking at a data set in R (or other languages) and finding that vectors with what looked like numbers are stored as strings. This usually happens because there’s a single errant character that the language doesn’t know how to parse as a number."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#functions-on-vectors",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#functions-on-vectors",
    "title": "Taxonomy of Data",
    "section": "Functions on vectors",
    "text": "Functions on vectors\nA vector is the simplest structure used in R to store data. It can be created using the function c().\n\nmy_vector &lt;- c(1, 3, 4)\nmy_vector\n\n[1] 1 3 4\n\n\n\nA function operates on an R object and produces output. R has many of the mathematical functions that you would expect.\n\nsum(my_vector)\n\n[1] 8"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#your-turn",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#your-turn",
    "title": "Taxonomy of Data",
    "section": "Your Turn",
    "text": "Your Turn\n\n\nCreate a vector named vec with the even integers between 1 and 10 as well as the number 99 (six elements total).\nFind the sum of that vector.\nFind the max of that vector.\nTake the mean of that vector and round it to the nearest integer.\n\n\nThese should all be solved with R code. If you don’t know the name of a function to use, with hazard a guess by looking for a help file (e.g. ?sum) or google it.\n\n  \n    −\n    +\n \n 05:00\n \n\nvec &lt;- c(2, 4, 6, 8, 10, 99) sum(vec) max(vec) ?round round(mean(vec))"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#working-in-a-qmd-file",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#working-in-a-qmd-file",
    "title": "Taxonomy of Data",
    "section": "Working in a qmd file",
    "text": "Working in a qmd file\nWorking in a new .qmd file allows you to save your code for later.\n\nDemo\n\nCreate a new qmd file from the RStudio menu, name it, and save it.\nInsert a new code cell.\nWrite your code into the cell.\nRender the document."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#building-a-data-frame",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#building-a-data-frame",
    "title": "Taxonomy of Data",
    "section": "Building a data frame",
    "text": "Building a data frame\nYou can combine vectors into a data frame using data.frame()1\n\nbill_depth_mm &lt;- c(15.0, 17.1, 18.7, 18.9)\nbill_length_mm &lt;- c(47.5, 40.2, 39.0, 35.3)\nspecies &lt;- c(\"Gentoo\", \"Adelie\", \"Adelie\", \"Adelie\")\n\n\n\n\n\npenguins_df &lt;- data.frame(bill_depth_mm, bill_length_mm, species)\npenguins_df\n\n  bill_depth_mm bill_length_mm species\n1          15.0           47.5  Gentoo\n2          17.1           40.2  Adelie\n3          18.7           39.0  Adelie\n4          18.9           35.3  Adelie\n\n\n\nYou can also use the tibble() function from the tidyverse package."
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/slides.html#your-turn-1",
    "href": "1-questions-and-data/02-taxonomy-of-data/slides.html#your-turn-1",
    "title": "Taxonomy of Data",
    "section": "Your Turn",
    "text": "Your Turn\n\n\nCreate a new .qmd file, name it, and save it.\nInsert a new code cell.\nCreate three vectors, name, hometown, and sibs_and_pets that contain observations on those variables from 6 people in this class.\nCombine them into a data frame called my_classmates.\n\n\n\n  \n    −\n    +\n \n 06:00"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html",
    "title": "The Taxonomy of Data",
    "section": "",
    "text": "The concepts of a variable, its type, and the structure of a data frame are useful because they help guide our thinking about the nature of a data. But we need more than definitions. If our goal is to construct a claim with data, we need a tool to aid in the construction. Our tool must be able to do two things: it must be able to store the data and it must be able to perform computations on the data. This is where R comes in!\nFirst, we will discuss how R can store and perform computations on data. Then, we will relate these basics to the Taxonomy of Data we have just discussed.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#r-and-rstudio",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#r-and-rstudio",
    "title": "The Taxonomy of Data",
    "section": "R and RStudio",
    "text": "R and RStudio\nR is one of the most powerful languages for doing statistics and data science. One of the reasons for its power and popularity is that it is both free and open-source. This turns languages like R into something that resembles Wikipedia: a collaborative effort that is constantly evolving. Extensions to the R language have been authored by professional programmers1, people working in industry and government2, professors3, and students like you4.\nYou’ll be writing and running code through an app called RStudio. Beyond writing R code, RStudio allows you to manage your files and author polished documents that weave together code and text. RStudio can be run through a browser and we have set up an account for you that you can access by sending a browser tab to https://stat20.datahub.berkeley.edu/ or clicking the  link in the upper right corner of the course website.\nWhen you log into RStudio, the place where you can type and run R code is called the console and it’s located right here:\n\n\n\n\n\n\nFigure 1: The R console in RStudio.\n\n\n\n\n\n\n\n\n\nCode along\n\n\n\nAs you read through these notes, keep RStudio open in another window to code along at the console.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#r-as-a-calculator",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#r-as-a-calculator",
    "title": "The Taxonomy of Data",
    "section": "R as a Calculator",
    "text": "R as a Calculator\nAlthough R is capable of running sophisticated statistical models, it’s also more than able to act as a calculator. Type the sum 1 + 2 into the console (the area to the right of the &gt;) and press Enter. What you should see is this:\n\n1 + 2\n\n[1] 3\n\n\nAll of the arithmetic operations work in R.\n\n1 - 2\n\n[1] -1\n\n1 * 2\n\n[1] 2\n\n1 / 2\n\n[1] 0.5\n\n\nEach of these four lines of code is called a command and the response from R is the output. The [1] at the beginning of the output is there just to indicate that it is the first element of the output. This helps you keep track of things when the output spans many lines.\nAlthough it is easiest to read code when the numbers are separated from the operator by a single space, it’s not necessary. R ignores all spaces when it runs your code, so each of the following also work.\n\n1/2\n\n[1] 0.5\n\n1   /         2\n\n[1] 0.5\n\n\nYou can add exponents by using ^, but don’t forget about the order of operations. If you want an alternative ordering, use parentheses.\n\n2 ^ 3 + 1\n\n[1] 9\n\n2 ^ (3 + 1)\n\n[1] 16",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#saving-objects",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#saving-objects",
    "title": "The Taxonomy of Data",
    "section": "Saving Objects",
    "text": "Saving Objects\nWhenever you want to save the output of an R command, add an assignment arrow &lt;- (less than, minus) as well as a name, such as “answer” to the left of the command.\n\nanswer &lt;- 2 ^ (3 + 1)\n\nWhen you run this command, there are two things to notice.\n\nThe word answer appears in the upper right hand corner of RStudio, in the “Environment” tab.\nNo output is returned at the console.\n\nEvery time you run a command, you can ask yourself: do I want to just see the output at the console or do I want to save it for later? If the latter, you can always see the contents of what you saved by just typing its name at the console and pressing Enter.\n\nanswer\n\n[1] 16\n\n\nThere are a few rules around the names that R will allow for the objects that you’re saving. First, while all letters are fair game, special characters like +, -, /, !, $, are off-limits. Second, names can contain numbers, but not as the first character. That means names like answer, a, a12, my_pony, and FOO will all work. 12a and my_pony! will not.\nBut just because I’ve told you that those names won’t work doesn’t mean you shouldn’t give it a try…\n\nmy_pony! &lt;- 2 ^ (3 + 1)\n\nError: &lt;text&gt;:1:8: unexpected '!'\n1: my_pony!\n           ^\n\n\nThis is an example of an error message and, though they can be alarming, they’re also helpful in coaching you how to correct your code. Here, it’s telling you that you had an “unexpected !” and then it points out where in your code that character popped up.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#creating-vectors",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#creating-vectors",
    "title": "The Taxonomy of Data",
    "section": "Creating Vectors",
    "text": "Creating Vectors\nWhile it is helpful to be able to store a single number as an R object, to store data sets we’ll need to store a series of numbers. You can combine multiple values by putting them inside c() separated by commas.\n\nmy_fav_numbers &lt;- c(9, 11, 19, 28)\nmy_fav_numbers\n\n[1]  9 11 19 28\n\n\nThis is object is called a vector.\n\nVector (in R)\n\nA set of contiguous data values that are of the same type.\n\n\nAs the definition suggests, you can create vectors out of many different types of data. To store words as data, use the following:\n\nmy_fav_colors &lt;- c(\"green\", \"orange\", \"purple\")\nmy_fav_colors\n\n[1] \"green\"  \"orange\" \"purple\"\n\n\nAs this example shows, R can store more than just numbers as data. \"green\", \"orange“, and \"purple\" are each called character strings and when combined together with c() they form a character vector. You can identify a string because it is wrapped in quotation marks and gets highlighted a different color in RStudio.\nVectors are often called atomic vectors because, like atoms, they are the simplest building blocks in the R language. Most of the objects in R are, at the end of the day, constructed from a series of vectors.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#functions",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#functions",
    "title": "The Taxonomy of Data",
    "section": "Functions",
    "text": "Functions\nWhile the vector will serve as our atomic method of storing data in R, how do we perform computations on it? That is the role of functions.\nLet’s use a function to find the arithmetic mean of the vector my_fav_numbers.\n\nmean(my_fav_numbers)\n\n[1] 16.75\n\n\nA function in R operates in a very similar manner to functions that you’re familiar with from mathematics.\n\n\n\n\n\n\nFigure 2: A mathematical function as a box with inputs and outputs.\n\n\n\nIn math, you can think of a function, \\(f()\\) as a black box that takes the input, \\(x\\), and transforms it to the output, \\(y\\). You can think of R functions in a very similar way. For our example above, we have:\n\nInput: the vector of four numbers that serves as the input to the function, my_fav_numbers.\nFunction: the function name, mean, followed by parentheses.\nOutput: the number 16.75.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#functions-on-vectors",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#functions-on-vectors",
    "title": "The Taxonomy of Data",
    "section": "Functions on Vectors",
    "text": "Functions on Vectors\nmean() is just one of thousands of different functions that are available in R. Most of them are sensibly named, like the following, which compute square roots and natural logarithms.\n\n\nBy default, log() computes the natural log. To use other bases, see ?log.\n\nsqrt(my_fav_numbers)\n\n[1] 3.000000 3.316625 4.358899 5.291503\n\nlog(my_fav_numbers)\n\n[1] 2.197225 2.397895 2.944439 3.332205\n\n\nNote that with these two functions, the input was a vector of length four and the output is a vector of length four. This is a distinctive aspect of the R language and it is helpful because it allows you to perform many separate operations (taking the square root of four numbers, one by one) with just a single command.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#the-taxonomy-of-data-in-r",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#the-taxonomy-of-data-in-r",
    "title": "The Taxonomy of Data",
    "section": "The Taxonomy of Data in R",
    "text": "The Taxonomy of Data in R\nIn the last lecture notes, we introduced the Taxonomy of Data as a broad system to classify the different types of variables on which we can collect data. If you recall, a variable is a characteristic of an object that you can measure and record. When Dr. Gorman walked up to her first penguin (the unit of observation) and measured its bill length, she collected a single observation of the variable bill_length_mm. You could record that in R using,\n\nbill_length_mm &lt;- 50.7\n\nShe continued on to measure the next penguin, then the next, then the next… Instead of recording these as separate objects, it is more efficient to store them as a vector.\n\nbill_length_mm &lt;- c(50.7, 48.5, 52.8, 44.5, 42.0, 46.9, 50.2, 37.9)\n\nThis example shows that\n\nA vector in R is a natural way to store observations on a variable.\n\nso in the same way that we have asked, “what is the type of that variable?” we can now ask “what is the class of that variable in R?”.\n\nClass (R)\n\nA collection of objects, often vectors, that share similar attributes and behaviors.\n\n\nWhile there are many classes in R, you can get a long way only knowing three. The first is represented by our vector my_fav_numbers. Let’s check it’s class using the class() function.\n\nclass(my_fav_numbers)\n\n[1] \"numeric\"\n\n\nHere we learn that my_fav_numbers is a numeric vector. Numeric vectors, as the name suggests, are composed only of numbers and can include measurements from both discrete and continuous numerical variables.\nWhat about my_fav_colors?\n\nclass(my_fav_colors)\n\n[1] \"character\"\n\n\nR stores that as a character vector. This is a very flexible class that can be used to store text as data. But what if there are only a few fixed values that a variable can take? In that case, you can do better than a character vector by usinggit a factor. Factor is a very useful class in R because it encodes the notion of levels discussed in the last notes.\nTo illustrate the difference, let’s make a character vector but then enrich it by turning it into a factor using factor().\n\nchar_vec &lt;- c(\"cat\", \"cat\", \"dog\")\nfac &lt;- factor(char_vec)\nchar_vec\n\n[1] \"cat\" \"cat\" \"dog\"\n\nfac\n\n[1] cat cat dog\nLevels: cat dog\n\n\nThe original character vector stores the same three strings that we used as input. The factor adds some additional information: the possible values that this vector can take.\nThis is particularly useful when you want to let R know that these levels have a natural ordering. If you have strong opinions about the relative merit of dogs over cats, you could specify that using:\n\nordered_fac &lt;- factor(char_vec, levels = c(\"dog\", \"cat\"))\nordered_fac\n\n[1] cat cat dog\nLevels: dog cat\n\n\n\n\nThis example also demonstrates that you can create a (character) vector inside a function.\nWhile this doesn’t change the way the levels are ordered in the vector itself, it will effect the way they behave when we use them to create plots, as we’ll do in the next set of notes.\nThese three vector classes do a good job of putting into flesh and bone (or at least silicon) the abstract types captured in the Taxonomy of Data.\n\n\n\n\n\n\nFigure 3: The Taxonomy of Data with equivalent classes in R.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#data-frames-in-r",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#data-frames-in-r",
    "title": "The Taxonomy of Data",
    "section": "Data Frames in R",
    "text": "Data Frames in R\nWhile vectors in R do a great job of capturing the notion of a variable, we will need more than that if we’re going to represent something like a data frame. Conveniently enough, R has a structure well-suited to this task called…(drumroll…)\n\nDataframe (R)\n\nA two dimensional data structure used to store vectors of the same length. A direct analog of the data frame defined previously5.\n\n\nLet’s use R to recreate the penguins data frame collected by Dr. Gorman.\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nspecies\n\n\n\n\n43.5\n18.1\nChinstrap\n\n\n48.1\n15.1\nGentoo\n\n\n49.0\n19.5\nChinstrap\n\n\n45.4\n18.7\nChinstrap\n\n\n34.6\n21.1\nAdelie\n\n\n49.8\n17.3\nChinstrap\n\n\n40.9\n18.9\nAdelie\n\n\n45.3\n13.7\nGentoo\n\n\n\n\n\n\n\n\nCreating a data frame\nIn the data frame above, there are three variables; the first two numeric continuous, the last one categorical nominal. Since R stores variables as vectors, we’ll need to create three vectors.\n\nbill_length_mm &lt;- c(50.7, 48.5, 52.8, 44.5, 42.0, 46.9, 50.2, 37.9)\nbill_depth_mm &lt;- c(19.7, 15.0, 20.0, 15.7, 20.2, 16.6, 18.7, 18.6)\nspecies &lt;- factor(c(\"Chinstrap\", \"Gentoo\", \"Chinstrap\", \"Gentoo\", \"Adelie\", \n             \"Chinstrap\", \"Chinstrap\", \"Adelie\"))\n\nWhile bill_length_mm and bill_depth_mm are both being stored as numeric vectors, species was first collected into a character vector, then passed directly to the factor() function. This is an example of nesting one function inside of another and it combined two lines of code into one.\nWith the three vectors stored in the Environment, all you need to do is staple them together with data.frame().\n\npenguins_df &lt;- data.frame(bill_length_mm, bill_depth_mm, species)\npenguins_df\n\n  bill_length_mm bill_depth_mm   species\n1           50.7          19.7 Chinstrap\n2           48.5          15.0    Gentoo\n3           52.8          20.0 Chinstrap\n4           44.5          15.7    Gentoo\n5           42.0          20.2    Adelie\n6           46.9          16.6 Chinstrap\n7           50.2          18.7 Chinstrap\n8           37.9          18.6    Adelie",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#summary",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#summary",
    "title": "The Taxonomy of Data",
    "section": "Summary",
    "text": "Summary\nThis was our first introduction to R, a supercharged calculator for storing and computing on data. We learned how to do basic arithmetic, construct and save a vector, call functions, query the class of an object, and construct a data frame. This forms the foundation of our use of R. If that foundation feels shakey, don’t fret. We’ll get plenty of practice in class.\n\n\n\n\n\n\nFigure 4: The arc of learning R6.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#exercises",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#exercises",
    "title": "The Taxonomy of Data",
    "section": "Exercises",
    "text": "Exercises\n\nEx: R as a Calculator\nMeet Leia, a fictitious undergrad student taking Stat 20. Leia loves to drink coffee in the morning, and she brews her own coffee at home. She even has a monthly budget of $20 to cover this type of expense. As you know, we can use R to create an object or variable coffee for Leia’s budget:\n\ncoffee &lt;- 20\n\nAlternatively, you can also use the equals sign = as an assignment operator:\n\ncoffee = 20\n\n\n\nYour Turn: Leia’s Expenses\nConsider the bills of Leia’s fixed monthly expenses:\n\nphone $80\ntransportation $20\ngroceries $600\nrent $1800\n\n\nMake more assignments to create variables phone, transportation, groceries, and rent with their corresponding amounts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nphone &lt;- 80\ntransportation &lt;- 20\ngroceries &lt;- 600\nrent &lt;- 1800\n\n\n\n\n/\n\nNow that you have all the variables, create a total object with the sum of her fixed monthly expenses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\ntotal &lt;- phone + transportation + groceries + rent\ntotal\n\n\n\n\n/\n\nAssuming that Leia has the same expenses every month, how much would she spend during a school “semester”? (assume the semester involves five months).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\ntotal * 5\n\n\n\n\n/\n\nMaintaining the same assumption about the monthly expenses, how much would Leia spend during a school “year”? (assume the academic year is 10 months).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\ntotal * 10\n\n\n\n\n/\n\n\nEx: Taxonomy of Data and R Vectors\nFrom the taxonomy of data, you know that we have 4 flavors of variables, and their corresponding classes in R (shown below inside parenthesis) illustrated in the following examples:\n\n# continuous (numeric)\nx1 &lt;- c(1.2, 3.3, -0.5)\n\n# discrete (numeric)\nx2 &lt;- c(2, 4, 6)\n\n# ordinal (ordered factor)\nx3 &lt;- factor(c(\"sm\", \"md\", \"lg\", \"sm\"), levels = c(\"sm\", \"md\", \"lg\"))\n\n# nominal (character or factor)\nx4 &lt;- c(\"strawberry\", \"lemon\", \"vanilla\")\nx4bis &lt;- factor(c(\"strawberry\", \"lemon\", \"vanilla\"))\n\n\n\nYour Turn: Terrestrial Planets\nConsider the following data set—shown in the table below—containing variables of so-called Terrestrial planets. These planets include Mercury, Venus, Earth, and Mars. They are called like this because they are “Earth-like” planets: relatively small in size and in mass, with a solid rocky surface, and metals deep in its interior.\n\n\n\nname\ngravity\nmoons\n\n\n\n\nMercury\n3.7\n0\n\n\nVenus\n8.9\n0\n\n\nEarth\n9.8\n1\n\n\nMars\n3.7\n2\n\n\n\n/\n\nConsider the column name in the provided table of terrestrial planets. Use the c() function to create a character vector name containing the names of the Terrestrial planets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nname = c(\"Mercury\", \"Venus\", \"Earth\", \"Mars\")\n\n\n\n\n/\n\nConsider the column gravity in the provided table of terrestrial planets. Use the combine function c() to make a numeric vector gravity for the Terrestrial planets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ngravity = c(3.7, 8.9, 9.8, 3.7)\n\n\n\n\n/\n\nConsider the column moons in the provided table of terrestrial planets. Use the combine function c() to make an ordinal factor moons.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nmoons = factor(c(0, 0, 1, 2), ordered = TRUE)\n\n\n\n\n/\n\n\nEx: Data Frames in R\nConsider again the data set of Terrestrial planets—shown in the table below.\n\n\n\nname\ngravity\nmoons\n\n\n\n\nMercury\n3.7\n0\n\n\nVenus\n8.9\n0\n\n\nEarth\n9.8\n1\n\n\nMars\n3.7\n2\n\n\n\n/\nUse the vectors that you defined in the previous section in order to create a data frame planets:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nplanets = data.frame(\n  \"name\" = name,\n  \"gravity\" = gravity,\n  \"moons\" = moons,\n  \"haswater\" = haswater\n)\n\n\n\n\n/\n\n\nEx: Challenge\nLet’s apply everything that you’ve learned so far in order to create a data frame students containing the following data, and the provided specifications listed below:\n\n\n\nname\nheight\nyear\nresident\n\n\n\n\nLeia\n160\nsophomore\nTRUE\n\n\nLuke\n170\nfreshman\nFALSE\n\n\nHan\n182\nsenior\nTRUE\n\n\nLando\n178\njunior\nFALSE\n\n\n\n/\n\nname: nominal variable (character)\nheight continuous variable (numeric)\nyear: ordinal variable (ordered factor)\nresident: nominal variable (logical)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nstudents = data.frame(\n  \"name\" = c(\"Leia\", \"Luke\", \"Han\", \"Lando\"),\n  \"height\" = c(160, 170, 182, 178),\n  \"year\" = factor(x = c(\"sophomore\", \"freshman\", \"senior\", \"junior\"),\n                  levels = c(\"freshman\", \"sophomore\", \"junior\", \"senior\")),\n  \"resident\" = c(TRUE, FALSE, TRUE, FALSE)\n)\n\n\n\n\n\n\nReferences and further reading\n\nHands on Programming with R by Garret Grolemund. A friendly introduction to the R language with fun examples.\nThe official (somewhat dense) documentation fo the R language. https://cran.r-project.org/doc/manuals/r-release/R-lang.html\nR for Data Science by Hadley Wickham and Garrett Grolemund. A comprehensive but approachable guide to doing data science with R. A good reference once you’re deeper into this course..",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#footnotes",
    "href": "1-questions-and-data/02-taxonomy-of-data/tutorial.html#footnotes",
    "title": "The Taxonomy of Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe googlesheets4 package, which reads spreadsheet data into R was authored by Jenny Bryan, a developer at Posit: :https://googlesheets4.tidyverse.org/.↩︎\nThe statistics office of the province of British Columbia maintains a public R package with all of their data: https://bcgov.github.io/bcdata/↩︎\nDr. Christopher Paciorek in the Department of Statistics at UC Berkeley maintains a package to fit a very broad class of statistical models called Bayesian Models: https://r-nimble.org/.↩︎\nSimon Couch wrote the stacks package for model ensembling while an undergraduate https://stacks.tidymodels.org/index.html.↩︎\nR is an unusual language in that the data frame has been for decades a core structure of the language. The analogous structure in Python is the data frame found in the Pandas library.↩︎\nR monster artwork by @allison_horst.↩︎",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "R Tutorials",
    "section": "",
    "text": "Tutorials serve to introduce you to the fundamentals of the R language.",
    "crumbs": [
      "Tutorials",
      "R Tutorials"
    ]
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#benfords-law",
    "href": "3-probability/labs/04-elections/slides.html#benfords-law",
    "title": "Lab 3: Elections",
    "section": "Benford’s Law",
    "text": "Benford’s Law\n\nMany naturally occurring numerical variables have a recurring pattern in the distribution of the first digit.\n\n\n\nFirst digits of stock prices, populations of cities, and election results have been observed to follow this pattern."
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#benfords-law-1",
    "href": "3-probability/labs/04-elections/slides.html#benfords-law-1",
    "title": "Lab 3: Elections",
    "section": "Benford’s Law",
    "text": "Benford’s Law\nLet \\(X\\) be the first digit of a randomly selected number. \\(X \\sim Benfords()\\) if\n\\[P(X = x) = \\log_{10}\\left(1 + 1/x \\right)\\]"
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#iran-election-1",
    "href": "3-probability/labs/04-elections/slides.html#iran-election-1",
    "title": "Lab 3: Elections",
    "section": "2009 Iran Election",
    "text": "2009 Iran Election\n\n\n\nBackground\n\nOngoing public sentiment that previous election was fraudulent\nThe highest voter turnout in Iran’s history\n\n\n\nLeading candidates\n\nMahmoud Ahmadinejad: Leader of conservatives and incumbent president.\nMir-Hossein Mousavi: Reformist and former prime minister. Seeking rapid political evolution.\n\n\n\n\n\n\n\n\n\n\nOutcome\nAhmadinejad won the election with 62.6% of the votes cast, while Mousavi received 33.75% of the votes cast."
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#post-election-controversies-and-unrest",
    "href": "3-probability/labs/04-elections/slides.html#post-election-controversies-and-unrest",
    "title": "Lab 3: Elections",
    "section": "Post-election controversies and unrest",
    "text": "Post-election controversies and unrest\n\n\n\n\n\nAllegations of fraud\nPublic protests and unrests\nThe green wave movement, led by Mousavi, against the allegedly fraudulent election and Ahmadinejad’s regime"
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#section",
    "href": "3-probability/labs/04-elections/slides.html#section",
    "title": "Lab 3: Elections",
    "section": "",
    "text": "Was the election fraudulent?"
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#fraud-detection-using-benfords-law",
    "href": "3-probability/labs/04-elections/slides.html#fraud-detection-using-benfords-law",
    "title": "Lab 3: Elections",
    "section": "Fraud detection using Benford’s Law",
    "text": "Fraud detection using Benford’s Law\n\nA common theory is that in a normally occurring, fair, election, the first digit of the vote counts county-by-county should follow Benford’s Law. If they do not, that might suggest that vote counts have been manually altered.\n\n\n\nThis theory was brought to bear to determine whether the 2009 presidential election in Iran showed irregularities1.\n\n\nhttps://physicsworld.com/a/benfords-law-and-the-iranian-e/"
  },
  {
    "objectID": "3-probability/labs/04-elections/slides.html#lab-3",
    "href": "3-probability/labs/04-elections/slides.html#lab-3",
    "title": "Lab 3: Elections",
    "section": "Lab 3",
    "text": "Lab 3\nIn this lab we will:\n\nExamine the Benford’s Law probability distribution\n\n\n\nCompare the first digits of vote counts in the 2009 Iranian election to this distribution\n\n\n\n\nReach a conclusion on whether the election was fraudulent (or whether the Benford’s Law is a good tool at detecting fraud in the first place)."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#making-claims-with-data",
    "href": "5-causation/labs/06-taste-test/slides.html#making-claims-with-data",
    "title": "Lab 7: A Matter of Taste",
    "section": "Making Claims with Data",
    "text": "Making Claims with Data\n\nSo far: Pose question -&gt; observe data -&gt; analyze data -&gt; make claim.\n\n\n\ne.g. Iranian election:\n\nDid fraud occur?\nObserve vote counts by city.\nTest of hypothesis that votes follow Benford’s law.\nVotes don’t follow Benford’s law well but not clear that this means fraud."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#making-claims-with-data-1",
    "href": "5-causation/labs/06-taste-test/slides.html#making-claims-with-data-1",
    "title": "Lab 7: A Matter of Taste",
    "section": "Making Claims with Data",
    "text": "Making Claims with Data\n\nThis week:\n\nIdentify possible claim\nImagine analysis that would show it.\nPlan data collection to allow that analysis.\nCarry out data collection + analysis.\nCheck claim.\n\n\n\nThis week students will work backwards: start with a claim that they think may be true, then decide how to collect data in a manner that will be most effective at determining whether or not the claim is true."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#but-first",
    "href": "5-causation/labs/06-taste-test/slides.html#but-first",
    "title": "Lab 7: A Matter of Taste",
    "section": "But first",
    "text": "But first\nPlease get into groups of 3 (or 4). Take turns introducing yourselves."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#a-matter-of-taste",
    "href": "5-causation/labs/06-taste-test/slides.html#a-matter-of-taste",
    "title": "Lab 7: A Matter of Taste",
    "section": "A Matter of Taste",
    "text": "A Matter of Taste\nYour challenge: Determine whether you can affect one your teammates’ perceptions of bubble water by manipulating their experience of tasting.\n\n\n\n\nEach team will have access to\n\n50 minutes (half of next class)\n2 cans of soda water, each one from a different flavor\nsmall paper cups\nsaltine crackers\nother materials welcome"
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#group-members",
    "href": "5-causation/labs/06-taste-test/slides.html#group-members",
    "title": "Lab 7: A Matter of Taste",
    "section": "Group Members",
    "text": "Group Members\n\n\nThe main reason for the roles here is to dedicate just one person to handling the materials for health safety."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#question-and-hypotheses",
    "href": "5-causation/labs/06-taste-test/slides.html#question-and-hypotheses",
    "title": "Lab 7: A Matter of Taste",
    "section": "Question and Hypotheses",
    "text": "Question and Hypotheses\n\n\nPrompt them to think carefully about their wording here in the question. How ambitious and general do they want to be?\nIt is also very common for people to suggest non-causal questions. It will help to underline the idea of intervention on this slide."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#hypotheses",
    "href": "5-causation/labs/06-taste-test/slides.html#hypotheses",
    "title": "Lab 7: A Matter of Taste",
    "section": "Hypotheses",
    "text": "Hypotheses"
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#protocol",
    "href": "5-causation/labs/06-taste-test/slides.html#protocol",
    "title": "Lab 7: A Matter of Taste",
    "section": "Protocol",
    "text": "Protocol\n\n\nHere they must be very precise. We’re spoken about reproducible science in class, so use that language to encourage careful work. They must be able to pass this protocol off to another group, and they should be able to carry out the intended experiment with no ambiguity."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#data",
    "href": "5-causation/labs/06-taste-test/slides.html#data",
    "title": "Lab 7: A Matter of Taste",
    "section": "Data",
    "text": "Data\n\n\nThis is intended to be a blank table with n rows and at least 1 column. They may plan to record either several extraneous variables or not enough to draw the conclusions they intend. As before, don’t correct them. They may discover mid-experiment that they did this part wrong, and that’s great."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#graphics",
    "href": "5-causation/labs/06-taste-test/slides.html#graphics",
    "title": "Lab 7: A Matter of Taste",
    "section": "Graphics",
    "text": "Graphics\n\n\nEncourage them to check that their viz is possible given their data frame and their data frame is possible give their protocol, and that their viz bears directly on their hypotheses."
  },
  {
    "objectID": "5-causation/labs/06-taste-test/slides.html#things-to-remember",
    "href": "5-causation/labs/06-taste-test/slides.html#things-to-remember",
    "title": "Lab 7: A Matter of Taste",
    "section": "Things to remember",
    "text": "Things to remember\n\nBe precise in your protocol.\nBe sure your claim corresponds to your protocol corresponds to your data corresponds to your plots.\nImportant: Lab 7.1 must be fully completed and shown to instructor before beginning Lab 7.2. Finish today if possible, by Friday night (due date) at latest.\n\n\n\n\n−+\n50:00"
  },
  {
    "objectID": "3-probability/labs/04-elections/learning-objectives.html",
    "href": "3-probability/labs/04-elections/learning-objectives.html",
    "title": "Stat 20",
    "section": "",
    "text": "Write down a probability model for vote counts.\nReview\n\n\nUnit of observation\n\n\n\nlibrary(rvest)\n# Reading in the table from Wikipedia\ntab &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_tallest_buildings\") %&gt;% \n  html_node(\".wikitable\") %&gt;%\n  html_table(fill = TRUE)\n\nReferences:\nOriginal iran analysis:\nhttps://www.researchgate.net/publication/45856921_A_first-digit_anomaly_in_the_2009_Iranian_presidential_election\nhttps://arxiv.org/pdf/0906.2789.pdf\nFollow up by walter mebane:\nhttp://websites.umich.edu/~wmebane/note18jun2009.pdf\nGelman’s take:"
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/notes.html",
    "href": "1-questions-and-data/02-taxonomy-of-data/notes.html",
    "title": "The Taxonomy of Data",
    "section": "",
    "text": "In the beginning was data, and from that data was built an understanding of the world.\nIn the beginning was understanding, and from that understanding sprung questions that sought to be answered with data.\nSo, which is it?\nThis is a philosophical question and it is up for debate. What is clearer is that in the process of engaging in data science, you will inevitably find yourself at one of these beginnings, puzzling over how to make your way to the other one.\nThe defining element of data science is the centrality of data as the means of advancing our understanding of the world. The word “data” is used in many different ways, so let’s write down a definition to get everyone on the same page.\nThis broad definition permits a staggering diversity in the forms that data can take. When you conducted a chemistry experiment in high school and recorded your measurements in a table in a lab notebook, that was data. When you registered for this class and your name showed on CalCentral, that was data. When the James Webb Space Telescope took a photo of the distant reaches of our solar system, recording levels of light pixel-by-pixel, that was data.\nSuch diversity in data is more precisely described as diversity in the types of variables that are being measured in a data set.\nIn your chemistry notebook you may have recorded the temperature and pressure of a unit of gas, two variables that are of scientific interest. In the CalCentral data set, name is the variable that was recorded (on you!) but you can imagine other variables that the registrars office might have recorded: your year at Cal, your major, etc. Each of these are called variables because the value that is measured generally varies as you move from one object to the next. While your value of the name variable might be Penelope, if we record the same variable on another student we’ll likely come up with different value.",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/notes.html#a-taxonomy-of-data",
    "href": "1-questions-and-data/02-taxonomy-of-data/notes.html#a-taxonomy-of-data",
    "title": "The Taxonomy of Data",
    "section": "A Taxonomy of Data",
    "text": "A Taxonomy of Data\nWhile the range of variables that we can conceive of is innumerable, there are recurring patterns in those variables that allow us to group them into persistent types that have shared properties. Such a practice of classification results in a taxonomy, which has been applied most notably in evolutionary biology to classify all forms of life.\nWithin the realm of data, an analogous taxonomy has emerged.\n\n\n\n\n\n\nFigure 2: the Taxonomy of Data.\n\n\n\n\nTypes of Variables\nThe principle quality of a variable is whether it is numerical or categorical.\n\n\nNumerical Variable\n\nA variable that take numbers as values and where the magnitude of the number has a quantitative meaning.\n\n\n\n\n\nCategorical Variable\n\nA variable that take categories as values. Each unique category is called a level.\n\n\n\nWhen most people think “data” they tend to think about numerical variables (like the temperature and pressure recorded in your lab notebook) but categorical variables (like the name recorded on CalCentral) are very common.\nAll numerical variables can be classified as either continuous or discrete.\n\n\nContinuous Numerical Variable\n\nA numerical variable that takes values on an interval of the real number line.\n\n\n\n\n\nDiscrete Numerical Variable\n\nA numerical variable that takes values that have jumps between them.\n\n\n\nA good example of a continuous numerical variable is temperature. If we are measuring outside air temperature on Earth in Fahrenheit, it is possible that we would record values anywhere from around -125 degrees F and +135 degrees F. While we might end up rounding our measurement to the nearest integer degree, we can imagine that the phenomenon of temperature itself varies smoothly and continuously across this range.\nA good example of a discrete numerical variable is household size. When the US Census goes door-to-door every year collecting data on every household, they record the number of people living in that household. A household can have 1 person, or 2 people, or 3 people, or 4 people, and so on, but it cannot have 2.83944 people. This makes it discrete.\nWhat unites both types of numerical variables is that the magnitude of the numbers have meaning and you can perform mathematical operations on them and the result also has meaning. It is possible and meaningful to talk about the average air temperature across three locations. It is also possible and meaningful to talk about the sum total number of people across ten households.\nThe ability to perform mathematical operations drops away when we move to ordinal variables. All categorical variables can be classified as either ordinal or nominal.\n\n\nOrdinal Categorical Variable\n\nA categorical variable with levels that have a natural ordering.\n\n\n\n\n\nNominal Categorical Variable\n\nA categorical variable with levels with no ordering.\n\n\n\nYou have likely come across ordinal categorical variables if you have taken an opinion survey. Consider the question:“Do you strongly agree, agree, feel neutral about, disagree, or strongly disagree with the following statement: Dogs are better than cats?” When you record answers to this question, you’re recording measurements on a categorical variable that takes values “strongly agree”, “agree”, “neutral”, “disagree”, “strongly disagree”. Those are the levels of the categorical variable and they have a natural ordering: “strongly agree” is closer to “agree” than it is to “strongly disagree”.\nYou can contrast this with a nominal categorical variable. Consider a second question that asks (as the registrar does): “What is your name?” There are many more possible levels in this case - “Penelope”, “David”, “Shobhana”, etc. - but those levels have no natural ordering. In fact this is very appropriate example of a nominal variable because the word itself derives from the Latin nomen, or “name”.\nLet’s take a look at a real data set to see if we can identify the variables and their types.\n\n\nExample: Palmer Penguins\nDr. Kristen Gorman is a fisheries and wildlife ecologist at the University of Alaska, Fairbanks whose work brought her to Palmer Station, a scientific research station run by the National Science Foundation in Antarctica. At Palmer Station, she took part in a long-term study to build an understanding of the breeding ecology and population structure of penguins.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Dr. Gorman recording measurements on penguins and Palmer Station, a research station in Antarctica.\n\n\n\nIn order to build her understanding of this community of penguins, she and fellow scientists spent time in the field recording measurements on a range of variables that capture important physical characteristics.\n\n\n\nTwo of the variables that were recorded were bill length and bill depth1. Each of these capture a dimension of the bill of a penguin recorded in millimeters These are identifiable as continuous numerical variables. They’re numerical because the values have quantitative meaning and they’re continuous because bill sizes don’t come in fixed, standard increments. They vary continuously.\nAnother variable that was recorded was the species of the penguin, either “Adelie”, “Gentoo”, or “Chinstrap”. Because these values are categories, this is a categorical variable. More specifically, it’s a nominal categorical because there is no obvious natural ordering between these three species.\n\n\n\nThese are just three of many variables that recorded in the penguins data set and published along their scientific findings in the paper, Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis)2. We will return throughout this course to this data set and this study. It is a prime example of how careful data collection and careful scientific reasoning can expand our understanding of a corner of our world about which we know very little.\n\n\nWhy Types Matter\nThe Taxonomy of Data is a useful tool of statistics and data science because it helps guide the manner in which data is recorded, visualized, and analyzed. Many confusing plots have been made by not thinking carefully about whether a categorical variable is ordinal or not or by mistaking a continuous numerical variable for a categorical variable. You will get plenty of practice using this taxonomy to guide your data visualization in the next unit.\nLike many tools built by scientists, though, this taxonomy isn’t perfect. There are many variables that don’t quite seem to fit into the taxonomy or that you can argue should fit into multiple types. That’s usually a sign that something interesting is afoot and is all the more reason to think carefully about the nature of the variables and the values it might take before diving into your analysis.",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/notes.html#a-structure-for-data-the-data-frame",
    "href": "1-questions-and-data/02-taxonomy-of-data/notes.html#a-structure-for-data-the-data-frame",
    "title": "The Taxonomy of Data",
    "section": "A Structure for Data: The Data Frame",
    "text": "A Structure for Data: The Data Frame\nWhen we seek to grow our understanding of a phenomenon, sometimes we select a single variable that we go out and collect data on. More often, we’re dealing with more complex phenomenon that are characterized by a few, or a few dozen, or hundreds (or even millions!) of variables. CalCentral has far more than just your name on file. To capture all of the complexity of class registration at Cal, it is necessary to record dozens of variables.\nTo keep all of this data organized, we need a structure. While there are several different ways to structure a given data set, the format that has become most central to data science is the data frame.\n\n\nData Frame\n\nAn array that associates the observations (downs the rows) with the variables measured on each observation (across the columns). Each cell stores a value observed for a variable on an observation.\n\n\n\nWhile this definition might seem opaque, you are already familiar with a data frame. You are you just more accustomed to seeing it laid out this like this:\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nspecies\n\n\n\n\n43.5\n18.1\nChinstrap\n\n\n48.1\n15.1\nGentoo\n\n\n49.0\n19.5\nChinstrap\n\n\n45.4\n18.7\nChinstrap\n\n\n34.6\n21.1\nAdelie\n\n\n49.8\n17.3\nChinstrap\n\n\n40.9\n18.9\nAdelie\n\n\n45.3\n13.7\nGentoo\n\n\n\n\n\n\n\nYou might be accustomed to calling this a “spreadsheet” or a “table”, but the organizational norm of putting the variables down the columns and the observations across the rows make this a more specific structure.\nOne of the first questions that you should address when you first come across a data frame is to determine what the unit of observation is.\n\n\nUnit of Observation\n\nThe class of object on which the variables are observed.\n\n\n\nIn the case of data frame above, the unit of observation is a single penguin near Palmer Station. The first row captures the measurements on the first penguin, the second row captures the measurements of the second penguin, and so on. If I log into CalCentral to see the data frame that records information on the students enrolled in this class, the unit of observation is a single student enrolled in this class.\n\nNot a Data Frame\nBefore you leave thinking that “data frame” = “spreadsheet”, consider this data set:\n\n\n\n\n\nFor it to be a data frame, we would have to read across the columns and see the names of the variables. You can imagine recording whether or not an alien is green or blue, but those variables would take the values “yes” and “no”, not the counts that we see here. Furthermore, total is not a variable that we’ve recorded a single unit; this column captures aggregate properties of the whole data set.\nWhile this structure might well be called a “table” or possibly a “spreadsheet”, it doesn’t meet our definition for a data frame.",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/notes.html#summary",
    "href": "1-questions-and-data/02-taxonomy-of-data/notes.html#summary",
    "title": "The Taxonomy of Data",
    "section": "Summary",
    "text": "Summary\nIn this lecture note we have focused on the nature of the data that will serve as the currency from which we’ll construct an improved understanding of the world. A first step is to identify the characteristics of the variables that are being measured and determine their type within the Taxonomy of Data. A second step is to organize them into a data frame to clearly associate the value that is measured for a variable with a particular observational unit.\nWith these ideas in hand, we learned how to bring data onto our computer, so that in our next class, we can begin the process of identifying its structure and communicating that structure numerically and visually.\nContinue on to the tutorial portion of the notes",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/02-taxonomy-of-data/notes.html#footnotes",
    "href": "1-questions-and-data/02-taxonomy-of-data/notes.html#footnotes",
    "title": "The Taxonomy of Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPenguin artwork by @allison_horst.↩︎\nGorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081. https://doi.org/10.1371/journal.pone.0090081↩︎",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "The Taxonomy of Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/notes.html",
    "href": "1-questions-and-data/01-understanding-the-world/notes.html",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Welcome to Stat 20! We are very excited to have you here this semester. There are no reading questions for today’s content, but make sure that you have:\n\ngotten the name of your instructor and in-class tutors\nread the syllabus and asked any questions you have about it on your lecture’s corresponding Ed thread\nstarted the first lab assignment\n\nThe goal of our course is to construct and critique claims made using data. This raises the question: what type of claims can be made?",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "Understanding the World with Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/notes.html#intro-and-syllabus",
    "href": "1-questions-and-data/01-understanding-the-world/notes.html#intro-and-syllabus",
    "title": "Understanding the World with Data",
    "section": "",
    "text": "Welcome to Stat 20! We are very excited to have you here this semester. There are no reading questions for today’s content, but make sure that you have:\n\ngotten the name of your instructor and in-class tutors\nread the syllabus and asked any questions you have about it on your lecture’s corresponding Ed thread\nstarted the first lab assignment\n\nThe goal of our course is to construct and critique claims made using data. This raises the question: what type of claims can be made?",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "Understanding the World with Data"
    ]
  },
  {
    "objectID": "1-questions-and-data/01-understanding-the-world/notes.html#types-of-claims",
    "href": "1-questions-and-data/01-understanding-the-world/notes.html#types-of-claims",
    "title": "Understanding the World with Data",
    "section": "Types of Claims",
    "text": "Types of Claims\n\n\n\n\n\n\n\nSummary\n\nA numerical, graphical, or verbal description of an aspect of data that is on hand.\n\n\n\nExample: Using data from the Stat 20 class survey, the proportion of respondents to the survey who reported having no experience writing computer code is 70%.\n\n\nGeneralization\n\nA numerical, graphical, or verbal description of a broader set of units than those on which data was been recorded.\n\n\n\n\nExample: Using data from the Stat 20 class survey, the proportion of Berkeley students who have no experience writing computer code is 70%.\n\n\nCausal Claim\n\nA claim that changing the value of one variable will influence the value of another variable.\n\n\n\nExample: Data from a randomized controlled experiment shows that taking a new antibiotic eliminates more than 99% of bacterial infections.\n\n\nPrediction\n\nA guess about the value of an unknown variable, based on other known variables.\n\n\n\nExample: Based on reading the news and the price of Uber’s stock today, I predict that Uber’s stock price will go up 1.2% tomorrow.",
    "crumbs": [
      "Notes",
      "Questions and Data",
      "Understanding the World with Data"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Navigate the notes using the menu in the left sidebar or the search in the upper right corner of the page.",
    "crumbs": [
      "Notes"
    ]
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#fine-needle-aspiration-biopsy",
    "href": "6-prediction/labs/08-cancer/slides.html#fine-needle-aspiration-biopsy",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "Fine needle aspiration biopsy",
    "text": "Fine needle aspiration biopsy\n\n\nOften when someone is suspected to have cancer (e.g. a bump is found) a fine needle aspiration biopsy is taken to determine whether or not the growth is cancerous (malignant – may grow dangerously out of control) or not (benign)."
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#artificial-intelligence-in-medicine",
    "href": "6-prediction/labs/08-cancer/slides.html#artificial-intelligence-in-medicine",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "Artificial intelligence in medicine",
    "text": "Artificial intelligence in medicine\n\nAutomating certain diagnostic tasks can increase access to healthcare\nGlobal shortage of pathologists, especially outside of wealthy healthcare systems\n\nExpert pathologists take years to be fully trained (4 year medical school + 4 year residency)\n\n\n\nhttps://www.linkedin.com/pulse/how-ai-can-help-address-global-shortage-pathologists-colangelo/"
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#lab-6-breast-cancer-diagnosis",
    "href": "6-prediction/labs/08-cancer/slides.html#lab-6-breast-cancer-diagnosis",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "Lab 6: breast cancer diagnosis",
    "text": "Lab 6: breast cancer diagnosis\n\nSamples are 568 biopsies\n\nEach biopsy has 30 features\n\nGoal: classify biopsy as benign or malignant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe tissue is purple because it is stained with Hematoxylin and Eosin. These are purple and pink stains that make the tissue structure easier to see under a microscope.\nMost of the visible objects in these images are cell nuclei, not the full cell; the cytoplasm is mostly invisible on these images.\n(From https://stanfordhealthcare.org/medical-conditions/cancer/cancer.html): Tumors can be benign (noncancerous) or malignant (cancerous). Benign tumors tend to grow slowly and do not spread. Malignant tumors can grow rapidly, invade and destroy nearby normal tissues, and spread throughout the body."
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#nuclear-morphology",
    "href": "6-prediction/labs/08-cancer/slides.html#nuclear-morphology",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "Nuclear morphology",
    "text": "Nuclear morphology\n\nMorphology = what the cell looks like under a microscope\n\nsize, shape, texture\n\nCells in malignant biopsies tend to\n\nbe larger\nirregularly shaped\nhighly variable\n\nOnly measure morphology of cell nucleus"
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#nuclear-morphology-features",
    "href": "6-prediction/labs/08-cancer/slides.html#nuclear-morphology-features",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "10 nuclear morphology features",
    "text": "10 nuclear morphology features\n\n\n\n\n\n\nWe compute 10 morphological features for each cell nucleus in the biopsy image.\nIt may be helpful to first draw one unit (one glass slide, that you would see under the microscope). Then in this slide, you make a data frame with cells, and then group by-summarise. Then the resulting calculations become one row in the final dataset."
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#biopsy-features",
    "href": "6-prediction/labs/08-cancer/slides.html#biopsy-features",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "30 biopsy features",
    "text": "30 biopsy features\n\n\n\n\n\n\nEach biopsy has 30 features; these come from computing 3 summary statistics (mean, max, standard deviation) of each of the 10 cell features to summarize the population of cells in the biopsy."
  },
  {
    "objectID": "6-prediction/labs/08-cancer/slides.html#lab-worktime",
    "href": "6-prediction/labs/08-cancer/slides.html#lab-worktime",
    "title": "Lab 6: Diagnosing Cancer",
    "section": "Lab worktime",
    "text": "Lab worktime\n\n\n\n−+\n25:00"
  },
  {
    "objectID": "4-generalization/labs/05-peoples-park/slides.html#section",
    "href": "4-generalization/labs/05-peoples-park/slides.html#section",
    "title": "Lab: People’s Park",
    "section": "",
    "text": "This is a promo video produced by the University to make an argument for the project. This was released at roughly the same time as the survey results."
  },
  {
    "objectID": "4-generalization/labs/05-peoples-park/slides.html#peoples-park-project",
    "href": "4-generalization/labs/05-peoples-park/slides.html#peoples-park-project",
    "title": "Lab: People’s Park",
    "section": "People’s Park Project",
    "text": "People’s Park Project\nThe University wishes to turn a university-owned plot of land called People’s Park into housing.\n\n\n\nOpponents\n\nAdvocates for the homeless residents living on site\nNeighbors who don’t want a tall tower built\nHistorical preservationists who want to preserve it for its role in countercultural movement of the ’60s.\n\n\n\nProponents\n\nAdvocates for homeless more generally\nNeighbors who want the blight and crime gone\nStudents who want easier access to housing\nCity of Berkeley who wants more housing built"
  },
  {
    "objectID": "4-generalization/labs/05-peoples-park/slides.html#the-chancellors-survey",
    "href": "4-generalization/labs/05-peoples-park/slides.html#the-chancellors-survey",
    "title": "Lab: People’s Park",
    "section": "The Chancellor’s Survey",
    "text": "The Chancellor’s Survey\n\n\n\n\n\nChancellor Carol Christ\n\n\n\nIn fall of 2021, the Chancellor’s Office commissioned a survey of the Berkeley community to gauge opinions on people’s park.\n\n\n\nIn this lab you will gain access to this survey data."
  },
  {
    "objectID": "4-generalization/labs/05-peoples-park/slides.html#part-i-understanding-the-context-of-the-data",
    "href": "4-generalization/labs/05-peoples-park/slides.html#part-i-understanding-the-context-of-the-data",
    "title": "Lab: People’s Park",
    "section": "Part I: Understanding the Context of the Data",
    "text": "Part I: Understanding the Context of the Data\n\n\n\n−+\n25:00"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License.\nThe source materials for the curriculum for this course and the software that builds this website are available under at:\nhttps://github.com/stat20/stat20"
  },
  {
    "objectID": "assets/quiz-slides.html#individual-quiz",
    "href": "assets/quiz-slides.html#individual-quiz",
    "title": "Quiz",
    "section": "Individual Quiz",
    "text": "Individual Quiz\n\n\nBefore the quiz begins\n\n🧹 Clear your desk of everything except a pen/pencil and your cheat sheet.\n🧢 Remove hats, hoods, and sunglasses.\n📱 All electronic devices (laptop, phone, airbuds, smart watch) should be remain in your bag for the entire class period.\nSpread out as much as possible: 1 student to a triangle desk, 2 to a tall desk.\nWhen you get a quiz, cover it with your cheat sheet and do not begin.\n\n\nDuring the quiz\n\n👀 Keep your eyes on your own quiz.\nIf you need to use the bathroom, bring phone and quiz to the front of the class.\n⌛If you finish early, please raise your hand and we will pick it up.\n❗You must stop writing when time is called or risk a 0.\n\nGood luck! 🍀\n\n\n  \n    −\n    +\n \n 25:00"
  },
  {
    "objectID": "assets/quiz-slides.html#group-quiz",
    "href": "assets/quiz-slides.html#group-quiz",
    "title": "Quiz",
    "section": "Group Quiz",
    "text": "Group Quiz\n\n\nBefore the quiz begins\n\nForm groups of 2-3 people.\n🧹 Everything except a pen/pencil and your cheat sheet must remain off your desk.\n📱 All electronic devices (laptop, phone, airbuds, smart watch) should be remain in your bag for the entire class period.\nWhen you get a group quiz, write all group members names on it but do not begin.\n\n\nDuring the quiz\n\n🗣️Discuss each of the problems and decide as a group which answer is best.\n⌛If you finish early, please raise your hand and we will pick it up.\n❗You must stop writing when time is called or risk a 0.\n\nGood luck! 🍀\n\n\n  \n    −\n    +\n \n 15:00"
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#agenda",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#agenda",
    "title": "Multiple Linear Regression",
    "section": "Agenda",
    "text": "Agenda\n\nAnnouncements\nMultiple Linear Regression Refresher\nQuiz Review (this week’s notes)\nBreak\nLab 2.2 (extended)"
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#announcements",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#announcements",
    "title": "Multiple Linear Regression",
    "section": "Announcements",
    "text": "Announcements\n\nQuiz 1 is Monday, in-class and covers all lectures from the beginning to the semester until today.\n\n\n\nLab 2.2, Problem Set 4 and Problem Set 5 are due Tuesday 9am\n\nMake sure you follow Lab Submission Guidelines on Ed\n\n\n\n\n\nRQ: Introducing Probability due on Monday/Tuesday at 11:59pm; Probability unit begins next week\n\n\n\n\nExtra Practice for Multiple Linear Regression added to the resources tab on the course home page."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-1",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-1",
    "title": "Multiple Linear Regression",
    "section": "Question 1",
    "text": "Question 1\n\nm1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\nm2 &lt;- lm(bill_depth_mm ~ bill_length_mm + body_mass_g + species, \n         data = penguins)\n\n\nHow many more coefficients does the second model have than the first?\n\n\nRemind students that they need to remember whether species and body_mass_g are numerical or categorical. Students should know how many species there are (three).\nOne addl. coefficient for body mass; two addl. for species (one less than the number of species, which is three). This gives a total of three more coefficients."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-2",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-2",
    "title": "Multiple Linear Regression",
    "section": "Question 2",
    "text": "Question 2\n\n\n\n−+\n01:00\n\n\n\n\n\n\nm2\n\n\nCall:\nlm(formula = bill_depth_mm ~ bill_length_mm + body_mass_g + species, \n    data = penguins)\n\nCoefficients:\n     (Intercept)    bill_length_mm       body_mass_g  speciesChinstrap  \n        10.33083           0.09484           0.00117          -0.90748  \n   speciesGentoo  \n        -5.80117  \n\n\n\nWhich is the correct interpretation of the coefficient in front of bill length? Select all that apply.\n\n\nThis one assesses their ability to use a conditional interpretation of a regression coefficient (controlling for the other variables in the model…).\nThe correct interpretation controls for both other variables (body mass and species), and has the x variable and the y variable in the correct places."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-3",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-3",
    "title": "Multiple Linear Regression",
    "section": "Question 3",
    "text": "Question 3\n\n\n\n−+\n01:00\n\n\n\n\n\n\nm2\n\n\nCall:\nlm(formula = bill_depth_mm ~ bill_length_mm + body_mass_g + species, \n    data = penguins)\n\nCoefficients:\n     (Intercept)    bill_length_mm       body_mass_g  speciesChinstrap  \n        10.33083           0.09484           0.00117          -0.90748  \n   speciesGentoo  \n        -5.80117  \n\n\n\nWhich is the correct interpretation of the coefficient in front of Gentoo?\n\n\nThis one assesses their ability to use a conditional interpretation of a regression coefficient (controlling for the other variables in the model…)\nThe correct interpretation needs to involve a comparison to the reference level, Adelie and should not involve anything about bill length or body mass, (other than to say they should be fixed)."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-4",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-4",
    "title": "Multiple Linear Regression",
    "section": "Question 4",
    "text": "Question 4\n\n\n\n−+\n01:00\n\n\n\n\n\n\nm2\n\n\nCall:\nlm(formula = bill_depth_mm ~ bill_length_mm + body_mass_g + species, \n    data = penguins)\n\nCoefficients:\n     (Intercept)    bill_length_mm       body_mass_g  speciesChinstrap  \n        10.33083           0.09484           0.00117          -0.90748  \n   speciesGentoo  \n        -5.80117  \n\n\n\nHow would this linear model best be visualized?\n\n\nThree numerical variables means we will have planes in a 3D space. The indicator coefficients will shift the planes up and down. There are three species, so three parallel planes is what we are looking for."
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-5",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-5",
    "title": "Multiple Linear Regression",
    "section": "Question 5",
    "text": "Question 5\nConsider the following linear regression output where the variable school is categorical and the variable hours_studied is numerical.\n\n\n\nCoefficients\nEstimate\n\n\n\n\n(Intercept)\n2.5\n\n\nhours_studied\n.2\n\n\nschoolCal\n1\n\n\nschoolStanford\n-1"
  },
  {
    "objectID": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-5-cont.",
    "href": "2-summarizing-data/07-multiple-linear-regression/slides.html#question-5-cont.",
    "title": "Multiple Linear Regression",
    "section": "Question 5 (cont.)",
    "text": "Question 5 (cont.)\n\nSay I wanted to create a data frame from the original edu dataframe which contains the minimum, median, and IQR for hours_studied among each school. In order to do this, I make use of group_by() followed by summarize(). I save this data frame into an object called GPA_summary.\n\n\n\nWhat are the dimensions of GPA_summary?\n\n\n\n\n\n\n−+\n01:00\n\n\n\n\n\n\nThe correct answer in the poll should be 3x4. The three rows are for the three levels in the school category (there is an additional level beyond \"Cal\" and \"Stanford\", regardless if it is not stated). One column is for the school name, the other three are for each of the statistics calculated; the three rows are for the three levels in the school category."
  },
  {
    "objectID": "2-summarizing-data/notes.html",
    "href": "2-summarizing-data/notes.html",
    "title": "Summarization",
    "section": "",
    "text": "In spring of 2022, the New York Times ran the following story1.\n“Consumer Prices” refers to the Consumer Price Index2, a weighted average of the prices of thousands of everyday consumer goods: sports equipment, soft drinks, sneakers, internet service, etc. An increase in that index is thought to correspond to rising inflation.\nLook carefully at the line plot. Which of the following four claims does it support?\nIn truth, this plot could be consistent with all these claims. They are, in turn, a summary, a prediction, a generalization, and a causal claim. This newspaper headline falls squarely in the first category, a summary, which seeks only to describe the data set that is on hand.\nAlthough 8.3% seems like a simple enough number, it is actually summarizing a vast data set of thousands of prices. The process of describing a data set invariably involves summarizing it, either with numerical summaries like 8.3% or with graphical summaries like the line plot show above.\nIn this unit, we will learn to critique and construct descriptive claims made with data. Although they sound elementary, descriptive claims are the most common form of claim made using data. They have the power to move, if not mountains, at least markets.",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarization"
    ]
  },
  {
    "objectID": "2-summarizing-data/notes.html#footnotes",
    "href": "2-summarizing-data/notes.html#footnotes",
    "title": "Summarization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSmialek, Jeanna (2022, May 11). Consumer Prices are Still Climbing Rapidly. The New York Times. https://www.nytimes.com/2022/05/11/business/economy/april-2022-cpi.html↩︎\nTo learn more, check out the Wikipedia page on the CPI in the US and the exhaustive description of how the data is collected at the US Bureau of Labor Statistics↩︎",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarization"
    ]
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/slides.html#agenda",
    "href": "2-summarizing-data/05-communicating-with-graphics/slides.html#agenda",
    "title": "Communicating with Graphics",
    "section": "Agenda",
    "text": "Agenda\n\nConcept Question\nPractice: Communicating with Graphics"
  },
  {
    "objectID": "2-summarizing-data/05-communicating-with-graphics/slides.html#question-1",
    "href": "2-summarizing-data/05-communicating-with-graphics/slides.html#question-1",
    "title": "Communicating with Graphics",
    "section": "Question 1",
    "text": "Question 1\n\nWhich elements have been applied to the following plot?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n01:00"
  },
  {
    "objectID": "2-summarizing-data/labs/arbuthnot/learning-objectives.html",
    "href": "2-summarizing-data/labs/arbuthnot/learning-objectives.html",
    "title": "Stat 20",
    "section": "",
    "text": "Note: this is leftover verbiage from a previous iteration of this lab. It can be adapted form the learning objectives.\n\nThe Stucture of Lab Assignments\nQuestions in Part I deal with the context in which Arbuthnot collected his data. These questions should should be answered before you have looked at the data itself. In general, in Part I you will identify the question of interest, consider the manner in which it arose, and set expectations for the shape and structure of the data.\nPart II is where you get your hands on the data and consider where it aligns with and diverges from your expections from Part I. Part III features extensions of the ideas in Part I and Part II, often to a new data set.\nYour work should feature writing that is clear and in full sentences. Your document should be formatted cleanly, with appropriate use of headers, body text, and lists. Your code should be clear and simple, with no extraneous code.\nCertain questions on the labs in this class call for speculation or for your opinion. There may not be a single correct answer, but some are more reasonable and thoughtful than others. You’re encouraged to talk these questions through with your peers and course staff during lab sessions, evening study session, and office hours.\n\n\n\nConcepts\n\nProposing a research question and articulating the evidence (data and other) that could bear on that question.\nIdentification of the unit of observation and the names and types of variables.\nCreating a statistical graphic that can answer a research question and interpreting the observed structure in the data.\nAssessing the degree to which a statistical graphic supports a claim / answers a question.\n\n\n\nSkills from the R Workshop\n\nRStudio Terminology\n\nConsole\nEnvironment\nEditor\nFile Directory\n\n\n\nR/RStudio Concepts\n\nPrinting to the console vs saving to the environment\nR scripts as final draft of code, console as the sandbox \n\n\n\nR Functions\n\n+, -, *, /, ^\n&lt;-\n?\nlibrary()\nc()\nclass()\nsum()\nmean()\ndata()\ntibble()\nselect()\narrange()\nmutate()\n\n\n\n\n\nSkills from Thursday lab\n\nloading arbuthnot\nloading tidyverse\npractice with select(), mutate(), and arrange()\nmaking a line plot using ggplot"
  },
  {
    "objectID": "2-summarizing-data/labs/flights/slides.html#section-2",
    "href": "2-summarizing-data/labs/flights/slides.html#section-2",
    "title": "Lab: Flights",
    "section": "",
    "text": "−+\n25:00"
  },
  {
    "objectID": "2-summarizing-data/labs/flights/lab.html",
    "href": "2-summarizing-data/labs/flights/lab.html",
    "title": "Lab 2: Flights",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "2-summarizing-data/labs/flights/lab.html#part-i-understanding-the-context-of-the-data",
    "href": "2-summarizing-data/labs/flights/lab.html#part-i-understanding-the-context-of-the-data",
    "title": "Lab 2: Flights",
    "section": "Part I: Understanding the Context of the Data",
    "text": "Part I: Understanding the Context of the Data\nFor the questions on the handout, consult the image of the data frame found in the slides linked above.\n\nPart 1: Understanding the Context of the Data"
  },
  {
    "objectID": "2-summarizing-data/labs/flights/lab.html#part-ii-computing-on-the-data",
    "href": "2-summarizing-data/labs/flights/lab.html#part-ii-computing-on-the-data",
    "title": "Lab 2: Flights",
    "section": "Part II: Computing on the Data",
    "text": "Part II: Computing on the Data\nThe data for this lab can be found in the flights data frame in the stat20data package. Run ?flights at the console to learn more about the columns. Where applicable, answer each question with one pipeline, which may include dplyr code, ggplot2 code or both.\n\nQuestion 1\nHow many flights in the dataset left in the springtime and were destined for Portland, Oregon?\n\n\nQuestion 2\nArrange the data set to find out: which flight holds the record for longest departure delay (in hrs) and what was its destination? What was the destination and delay time (in hrs) for the flight that was least delayed, i.e. that left the most ahead of schedule? This can be done in two separate pipelines.\n\n\nQuestion 3\nI attempted to find some summary statistics on the arrival delay of flights, grouped by their airline carrier. You can find the mininmum and maximum of numerical variables using the min() and max() function, respectively. This is the code that I ran.\n\nflights |&gt;\n    group_by(carrier) |&gt;\n    summarise(min_arr_delay = min(arr_delay)) |&gt;\n    summarise(max_arr_delay = max(arr_delay)) |&gt;\n    summarise(prop_long_flight = mean(distance &gt; 1000))\n\nHowever, I received an error and the code would not run. Explain the origin of this error, then modify/correct the code and run it to display the output I was hoping to achieve.\n\n\nQuestion 4\nUsing the airport nearest your hometown, which day of the week and which airline seems best for flying there from San Francisco? If you’re from near SFO or OAK or from abroad, use Chicago as your hometown. Be clear on how you’re defining best. Feel free to mutate a column(s) to your dataset which might be your preferred way to determine best.\nThere is no explicit weekday column in this data set, but there is sufficient information to piece it together. The following line of code can be added to your pipeline to create that new column. Note also that it uses functions which are contained in the lubridate package.\n\nmutate(day_of_week =\n            wday(ymd(paste(year, month, day, set = \"-\")),\n            label = T))\n\n\n\nQuestion 5\nThe plot below shows the relationship between the number of flights going out of SFO and the average departure delay. It illustrates the hypothesis that more flights on a given day would lead to a more congested airport which would lead to greater delays on average. Each point represents single day in 2020; there are 366 of them on the plot. Form a single dplyr and ggplot2 chain that will create this plot, starting with the original data set. Hint: What does each point on the plot represent? Is it the same as the unit of observation of the initial dataset?\n\n\n\n\n\n\n\nQuestion 6\nCreate a histogram showing the distribution of departure delays for all flights. You must follow the steps below:\n\nSet the limits of the x-axis to focus on where most of the data lie.\nOutline the bars of your histogram with one color.\nAdd a text annotation somewhere on the plot that explains the meaning of a negative departure delay.\nFinally, title your plot with a claim about the shape and modality of the distribution.\n\n\n\nQuestion 7\nCreate a plot to examine the relationship between average speed and distance (you will have to make the average speed column first) in one pipeline, labeling your x and y axes. Save this plot into an object and print it to the screen.\n\n\nQuestion 8\nRewrite the code for the plot you made in Question 7, coloring the points by destination, and use this to provide a possible explanation for the relationship between the two variables (particularly, the noticeable gap) in the plot title.\n\n\nQuestion 9\n\nFirst, calculate the correlation coefficient between average speed and distance.\nThen, mutate two new variables onto the data frame:\n\n(natural) log of average speed\n(natural) log of distance\n\nVisualize the new variables and title your plot with a claim based on what you see.\nFinally, calculate the correlation coefficient between log of average speed and log of distance.\n\nThe process of applying functions to existing variables (such as logarithm or squaring) in a dataset is often called transforming one’s data.\n\n\nQuestion 10\nExplain which pair of variables have a relationship which is better described via a linear model:\n\ndistance and average speed\nlog distance and log average speed\n\nExplain in one or two sentences, using your results from Question 7 and Question 9 as support.\n\n\nQuestion 11\nFit a linear model to the variables you chose from Question 10. Then determine which flight had the fastest average speed given its distance traveled.\n\n\nQuestion 12\nFit a multiple linear regression model that explains arrival delay using departure delay and the distance of the flight and print out the coefficients (the intercept and two slopes).\n\n\nQuestion 13\nOn average, which carrier’s flights had the smallest arrival delay given their departure delay and distance?\n\n\nQuestion 14\nCan we compare the coefficients for departure delay and distance to understand which has the stronger relationship? Why or why not? State your answer in 2-3 sentences."
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html",
    "href": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(infer)\ndata(gss)\n\nggplot(gss, aes(x = partyid, \n                fill = college)) +\n    geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\nggplot(gss, aes(x = partyid, \n                fill = college)) +\n    geom_bar(position = \"fill\") +\n    labs(y = \"proportion\")"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html#question-2.1",
    "href": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html#question-2.1",
    "title": "Summarizing Categorical Data",
    "section": "Question 2.1",
    "text": "Question 2.1\nWhat was the most frequently cited party that respondents identified with?\n( ) dem (X) ind ( ) rep ( ) other ( ) no degree ( ) degree"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html#question-2.2",
    "href": "2-summarizing-data/01-summarizing-categorical-data/reading-questions.html#question-2.2",
    "title": "Summarizing Categorical Data",
    "section": "Question 2.2",
    "text": "Question 2.2\nTrue or False: most of the survey respondents had a college degree.\n( ) True (X) False"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html",
    "href": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "In this tutorial we’ll grow your R toolbox to visualize categorical data but first, a very general skill: how to ask for help.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#libraries",
    "href": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#libraries",
    "title": "Summarizing Categorical Data",
    "section": "Libraries",
    "text": "Libraries\n\n\n\nThe tidyverse library, which contains many useful packages for data science\n\n\nIn Taxonomy of Data, we learned about a few different functions that can be used on vectors, such as mean(). We also learned about a function called data.frame(), which allowed us to bring vectors together as part of a new structure called a data frame, with each of the vectors used as columns.\nWhile the base functionality provided by R is powerful, developers often seek to find more efficient ways to complete tasks. In doing so, they push the power of R forward. R has a vast ecosystem of libraries that add new functions. Any installed library can be loaded with the library() function. Here, we will load the tidyverse library, one of the core external libraries that we will be using this semester.\n\nlibrary(tidyverse)\n\nTo use these functions within this library (or any other library), you will need to run the above line of code each time you start an RStudio session!\nThe tidyverse library has many different packages which contain smaller pieces of functionality. Today, our focus is to summarize categorical data, and one avenue we have explored already is a visual summary; a bar chart. Let’s explore how the plots shown earlier in this set of notes were made. We will use ggplot2, tidyverse’s resident visualization package.\nFirst, we should load the penguins data into our environment. The penguins data is actually located in a special library made just for this course called stat20data. This library hosts the datasets which will be the subjects of your labs. Therefore, we need to load this library first.\n\nlibrary(stat20data)\n\nThen, we can load in the penguins data by using the aptly named data function.\n\ndata(penguins)\n\nOnce you do this, you will see the penguins dataset, in all of its glory, appear in the environment pane at the top right of your RStudio session (you may need to click in the area once or twice).\n\n\n\n\n\nYou can click the blue dropdown arrow to see each variable in the dataset, or for a more traditional view, you can click the white spreadsheet icon to the right:\n\n\n\n\n\nNow, we’re ready to write some ggplot2 code and make our first visualization of the year! We will create the exact stacked, normalized bar chart you saw earlier in the notes.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#a-first-visualization-with-ggplot2",
    "href": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#a-first-visualization-with-ggplot2",
    "title": "Summarizing Categorical Data",
    "section": "A first visualization with ggplot2",
    "text": "A first visualization with ggplot2\nThe main function within the ggplot2 package is, well, ggplot().\n\nggplot(data = penguins)\n\n\n\n\n\n\n\n\nThe ggplot() function takes as its first argument a data frame (the data argument). By itself, there’s not much to look at; it just creates a blank canvas.\nLet’s now indicate how we want to map our variables to each area of the plot. For now, let’s just focus on the species of penguin; we’ll handle the island later.\nWe had species of penguin on the horizontal (x) axis. This piece of information (which is known as an aesthetic attribute of the plot), goes into a second argument called mapping and within a function called aes().\n\nggplot(data = penguins, \n       mapping = aes(x = species))\n\n\n\n\n\n\n\n\nNow we’re getting somewhere. We can see the x axis has been set up with labels for the species of penguins.\nAll that is left is to actually put the observations on the plot. We do this by declaring what geometry we want and adding this information to our existing code. We can add this information via a new layer, which can be added on by using the + syntax and taking a newline.\n\nggplot(data = penguins, \n       mapping = aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe layer we added was a geometry layer corresponding to the bar chart, called geom_bar().\nNote that the bars are not colored like before, but are just gray. This is because we are missing the island variable! Island was represented by coloring in (filling) the bars for us according to the conditional proportions of penguins within a specific species belonging to a specific island. We can include this by adding to our aes() function in the original layer.\n\nggplot(data = penguins, \n       mapping = aes(x = species, \n                     fill = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nAlmost there! Note that what we have right now is just a stacked bar chart. There’s one more fix that we need to apply. Note that geom_bar() can be thought of as a function as well. One of its arguments, position, will help us solve this issue1. position defaults to a stacked bar chart, but we can fix this by supplying it with \"fill\"!\n\nggplot(data = penguins, \n       mapping = aes(x = species, \n                     fill = island)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nA side-by-side (dodged) bar chart can be produced by replacing \"fill\" with \"dodge\". To recover the original, stacked bar chart, use \"stack\"!\nThere we have it!",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#footnotes",
    "href": "2-summarizing-data/01-summarizing-categorical-data/tutorial.html#footnotes",
    "title": "Summarizing Categorical Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis argument is generally not important for the other plots we create in this course, which is why in the initial piece of code featuring geom_bar(), it was not specified at all.↩︎",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "Summarizing Categorical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#cq-1",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#cq-1",
    "title": "Summarizing Categorical Data",
    "section": "CQ 1",
    "text": "CQ 1\n\nThe next four subquestions are based on the same table."
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "The table below displays data from a survey on a class of students.\n\n\nWhat proportion of the class was in the marching band?\n\n\n  \n    −\n    +\n \n 00:30\n \n\nAn example of a marginal proportion."
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-1",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-1",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "What proportion of those in the marching band where juniors?\n\n\n  \n    −\n    +\n \n 00:30\n \n\nAn example of a conditional proportion."
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-2",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-2",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "What proportion were sophomores not in the marching band?\n\n\n  \n    −\n    +\n \n 00:30\n \n\nAn example of a joint proportion."
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-3",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-3",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "What were the dimensions of the raw data from which this table was constructed?\n\n\n  \n    −\n    +\n \n 00:30"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-4",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-4",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "How would you characterize the association between these two variables?\n\n\n  \n    −\n    +\n \n 00:30"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#cq-2",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#cq-2",
    "title": "Summarizing Categorical Data",
    "section": "CQ 2",
    "text": "CQ 2\nPolitical affiliation and college degree status of 500 survey participants.\n\n\nWhich group is the largest?\n\n\nThe General Social Survey is a widely used sources of data on the attitudes, behaviors, and attributes of Americans. This plot shows the relationship between the political affiliation and college degree status of 500 participants.\nCannot tell which group is the largest since this plot as been normalized so that the proportions within each party sum to 1. The unnormalized plot on the following slide is one that allows us to answer this questions.\nThe unnormalized bar chart of counts preserves original counts and thus is good at comparing joint proportions. The normalized bar count shows condition proportions and thus is good for showing associations between variables.\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-5",
    "href": "2-summarizing-data/01-summarizing-categorical-data/slides.html#section-5",
    "title": "Summarizing Categorical Data",
    "section": "",
    "text": "What does this plot show?\n\n\nImportant note: it looks like a leading “1” was cropped from the numbers along the y axis.\nThis is a confusing stacked bar chart! (unfortunately I wasn’t able to track down the source.)\nThe height of each total bar appears to be the energy supply from renewables worldwide in each of these years. The proportion on top, however, appears to be that number divided by the global total energy supply, which changes every year. The fact that those proportions are decreasing left to right as the bar heights are increasing suggests that renewables are increasing every year (the numerator) but the total energy supply (the denominator) is increasing at a faster rate.\n\n\n  \n    −\n    +\n \n 01:00"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Man feigns madness, contemplates life and death, and seeks revenge.\nSon avenges his father, and it only takes four hours.\nA tragedy written by the English playwright around 1600.\n29,551 words on a page.\nYou may recognize each of these as summaries of the play, “Hamlet”. None of these are wrong, per se, but they do focus on very different aspects of the work. Summarizing something as rich and complex as Hamlet invariably involves a large degree of omission; we’re reducing a document of 29,551 words down to a single sentence or phrase, after all. But summarization also involves important choices around what to include.\nThe same considerations of omission and inclusion come into play when developing a numerical or graphical summary of a data set. Some guidance to bear in mind:\nWhat should I include?\nWhat should I omit?\nIn these notes we’ll keep this guidance in mind as we discuss how to summarize numerical data with graphics, in words, and with statistics. Specifically, we will learn how to:\nSummarizing two numerical variables is a task which deserves its own set of notes; that set of notes will come later on!",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html#constructing-graphical-summaries",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html#constructing-graphical-summaries",
    "title": "Summarizing Numerical Data",
    "section": "Constructing Graphical Summaries",
    "text": "Constructing Graphical Summaries\nLet’s turn to an example admittedly less complex than Hamlet: the Palmer penguins. One of the numerical variables Dr. Gorman recorded was the length of the bill in millimeters. The values of the first 16 penguins are:\n\n\n\n\n\n\n\n\nbill_length_mm\n\n\n\n\n39.1\n\n\n39.5\n\n\n40.3\n\n\n36.7\n\n\n39.3\n\n\n38.9\n\n\n39.2\n\n\n41.1\n\n\n38.6\n\n\n34.6\n\n\n36.6\n\n\n38.7\n\n\n42.5\n\n\n34.4\n\n\n46.0\n\n\n37.8\n\n\n\n\n\nWe have many options for different plot types that we could use to summarize this data graphically. To understand the differences, it’s helpful to lay out the criterion that we hold for a summary to be a success. Let’s call those criteria the desiderata, a word meaning “that which is desired or needed”.\nFor our first graphic, let’s set a high bar.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nAll information must be preserved.\n\n\n\nThe most commonly used graphic that fulfills this criterion is the dot plot.\n\n\n\n\n\n\n\n\n\nThe dot plot is, in effect, a one-dimensional scatter plot. Each observation shows up as a dot and its value corresponds to its location along the x-axis. Importantly, it fulfills our desiderata: given this graphic, one can recreate the original data perfectly. There was no information loss.\nAs the number of observations grow, however, this sort of graphical summary becomes unwieldy. Instead of focusing on the value of each observation, it becomes more practical to focus on the general shape of the distribution. Let’s consider a broader goal for our graphic.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nBalance depiction of the general characteristics of the distribution with a fidelity to the individual observations.\n\n\n\nThere are several types of graphics that meet this criterion: the histogram, the density plot, and the violin plot.\n\nHistograms\n\n\n\n\n\n\n\n\n\nAt first glance, a histogram looks like deceptively like a bar chart. There are bars arranged along the x-axis according to their values with heights that correspond to the count of each value found in the data set. So how is this not a bar chart?\nA histogram involves aggregation. The first step in creating a histogram is to divide the range of the variable into bins of equal size. The second step is to count up the number of observations that occur in each bin. In this way, some observations will have their own bar (every bar with a count of one) but other observations will be aggregated into the same bar: the tallest bar, with a count of 3, corresponds to all observations from 39.09 to 39.30: 39.1, 39.2, and 39.3.\nThe degree of aggregation performed by the histogram is determined by the binwidth. Most software will automatically select the binwidth1, but it can be useful to tinker with different values to see the distribution at different levels of aggregation. Here are four histograms of the same data that use four different binwidths.\n\n\n\n\n\n\n\n\n\nIf you are interested in only the coarsest structure in the distribution, best to use the larger binwidths. If you want to see more detailed structure, a smaller binwidth is better.\nThere is a saying that warns about times when you, “can’t see the forest for the trees”, being overwhelmed by small details (the trees) and unable to see the bigger picture (the forest). The histogram, as a graphical tool for summarizing the distribution of a numerical variable, offers a way out. Through your choice of binwidth, you can determine how much to focus on the forest (large bindwidth) or the trees (small binwidth).\n\n\nDensity plots\nImagine that you build a histogram and place a cooked piece of spaghetti over the top of it. The curve created by the pasta is a form of a density plot.\n\n\n\n\n\n\n\n\n\nBesides the shift from bars to a smooth line, the density plot also changes the y-axis to feature a quantity called “density”. We will return to define this term later in the course, but it’s sufficient to know that the values on the y-axis of a density plot are rarely useful. The important information is relative: an area of the curve with twice the density as another area has roughly twice the number of observations.\nThe density plot, like the histogram, offers the ability to balance fidelity to the individual observations against a more general shape of the distribution. You can tip the balance to feature what you find most interesting by adjusting the bandwidth of the density plot.\n\n\n\n\n\n\n\n\n\nA density curve tends to convey the overall shape of a distribution more quickly than does a histogram, but be sure to experiment with different bandwidths. Strange but important features of a distribution can be hidden behind a density curve that is too smooth.\n\n\nViolin plots\nOften we’re interested not in the distribution of a single variable, but in the way the distribution of that variable changes from one group of observational units to another. Let’s add this item to our list of criteria for a statistical graphic.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nBalance depiction of the general characteristics of the distribution with a fidelity to the individual observations.\nAllow for easy comparisons between groups.\n\n\n\nThere are several different ways to compare the distribution of a variable across two or more groups, but one of the most useful is the violin plot. Here is a violin plot of the distribution of bill length across the three species of penguins.\n\n\n\n\n\n\n\n\n\nThe distribution of bill length in each species is represented by a shape that often looks like a violin but is in fact a simple density curve reflected about its x-axis. This means that you can tinker with a violin plot the same as a density plot, but changing the bandwidth.\nIf this plot type looks familiar, you may have seen its cousin, the box plot.\n\n\n\n\n\n\n\n\n\nThe box plot conveys a similar story to the violin plot: Adelies have shorter bills than Chinstraps and Gentoos. Box plots have the advantage of requiring very little computation to construct2, but in a world of powerful computers, that is no longer remarkable. What they lack is a “smootness-knob” that you can turn to perform more or less smoothing. For this reason, violin plots are a more flexible alternative to box plots.",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html#describing-distributions",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html#describing-distributions",
    "title": "Summarizing Numerical Data",
    "section": "Describing Distributions",
    "text": "Describing Distributions\nThe desideratum that we used to construct the histogram and the violin plot include the ability to “depict general characteristics of the distribution”. The most important characteristics of a distribution are its shape, center, and spread.\nWhen describing the shape of a distribution in words, pay attention to its modality and skew. The modality of a distribution captures the number of distinct peaks (or modes) that are present.\n\n\n\n\n\nA good example of a distribution that would be described as unimodal is the original density plot of bill lengths of 16 Adelie penguins (below left). There is one distinct peak around 39. Although there is another peak around 34, it is not prominent enough to be considered a distinct mode. The distribution of the bill lengths of all 344 penguins (below right), however, can be described as bimodal.\n\n\n\n\n\n\n\n\n\nMultiple modes are often a hint that there is something more going on. In the plot to the right above, Chinstraps and Gentoo penguins, which are larger, are clumped under the right mode while the smaller Adelie penguins are dominant in the left mode.\nThe other important characteristic of the shape of a distribution is its skew.\n\n\n\n\n\nThe skew of a distribution describes the behavior of its tails: whether the right tail stretches out (right skew), the left tail stretches out (left skew), or if both tails are of similar length (symmetric). An example of a persistently right skewed distribution is household income in the United States:\n\n\n\n\n\nIn the US, the richest households have much much higher incomes than most, while the poorest households have incomes that are only a bit lower than most.\nWhen translating a graphical summary of a distribution into words, some degree of judgement must be used. When is a second peak a mode and when is it just a bump in the distribution? When is one of the tails of a distribution long enough to tip the description from being symmetric to being right skewed? You’ll hone your judgement in part through repeated practice: looking at lots of distributions and readings lots of descriptions. You can also let the questions of inclusion and omission be your guide. Is the feature a characteristic relevant to the question you’re answering and the phenomenon you’re studying? Or is it just a distraction from the bigger picture?\nModality and skew capture the shape of the distribution, but how do we describe its center and spread? “Eyeballing it” by looking at a graphic is an option. A more precise option, though, is to calculate a statistic.",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html#constructing-numerical-summaries",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html#constructing-numerical-summaries",
    "title": "Summarizing Numerical Data",
    "section": "Constructing Numerical Summaries",
    "text": "Constructing Numerical Summaries\nStatistics is both an area of academic study and the object of that study. Any numerical summary of a data set - a mean or median, a count or proportion - is a statistic. A statistic is, fundamentally, a mathematical function where the data is the input and the output is the observed statistic.\n\n\n\nStatisticians don’t just study statistics, though, they construct them. A statistician gets to decide the form of \\(f\\) and, as with graphics, they construct it to fulfill particular needs: the desiderata.\nTo examine the properties of common statistics, let’s move to an even simpler data set: a vector called x that holds 11 integers.\n\\[8, 11, 7, 7, 8, 11,  9,  6,  10,  7,  9\\]\n\n\n\nMeasures of Center\nThe mean, the median, and the mode are the three standard statistics used to measure the center of a distribution. Despite their ubiquity, these three are not carved somewhere on a stone tablet. They’re common because they’re useful and they’re useful because they were constructed very thoughtfully.\nLet’s start by laying out some possible criteria for a measure of center.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nSynthesizes the magnitudes of all \\(n\\) observations.\nAs close as possible to all of the observations.\n\n\n\nThe (arithmetic) mean fulfills all of these needs.\n\n\nThe function in R: mean()\n\\[\n\\frac{8 + 11 + 7 + 7 + 8 + 11 + 9 + 6 + 10 + 7 + 9}{11} = \\frac{93}{11} = 8.45\n\\]\nThe mean synthesizes the magnitudes by taking their sum, then keeps that sum from getting larger than any of the observations by dividing by \\(n\\). In order to express this function more generally, we use the following notation\n\\[\n\\bar{x} = \\frac{x_1 + x_2 + \\ldots + x_n}{n}\n\\]\nwhere \\(x_1\\) is the first observation, \\(x_2\\) is the second observation, and so on till the \\(n^{th}\\) observation, \\(x_n\\); and \\(\\bar{x}\\) is said “x bar”.\nThe mean is the most commonly used measure of center, but has one notable drawback. What if one of our observations is an outlier, that is, has a value far more extreme than the rest of the data? Let’s change the \\(6\\) to \\(-200\\) and see what happens.\n\\[\n\\frac{8 + 11 + 7 + 7 + 8 + 11 + 9 - 200 + 10 + 7 + 9}{11} = \\frac{-113}{11} = -10.27\n\\]\nThe mean has plummeted to -10.27, dragged down by this very low outlier. While it is doing it’s best to stay “as close as possible to all of the observations”, it isn’t doing a very good job of representing 10 of the 11 values.\nWith this in mind, let’s alter the first criterion to inspire a different statistic.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nSynthesize the order of all \\(n\\) observations.\nAs close as possible to all of the observations.\n\n\n\nIf we put the numbers in order from smallest to largest, then the number that is as close as possible to all observations will be the middle number, the median.\n\n\nThe function in R: median()\n\\[ 6 \\quad 7 \\quad 7 \\quad  7 \\quad 8 \\quad {\\Large 8} \\quad 9 \\quad 9 \\quad 10 \\quad 11  \\quad 11\\]\nAs measured by the median, the center of this distribution is 8 (recall the mean measured 8.45). If there were an even number of observations, the convention is to take the mean of the middle two values.\nThe median has the desirable property of being resistant (or “robust”) to the presence of outliers. See how it responds to the inclusion of -200.\n\\[ -200 \\quad 7 \\quad 7 \\quad  7 \\quad 8 \\quad {\\Large 8} \\quad 9 \\quad 9 \\quad 10 \\quad 11  \\quad 11\\]\nWith this outlier, the median remains at 8 while the mean had dropped to -10.27. This property makes the median the favored statistic for capturing the center of a skewed distribution.\nWhat if we took a stricter notion of “closeness”?\n\n\n\n\n\n\nDesiderata\n\n\n\n\nIs identical to as many observations as possible.\n\n\n\nThat leads us to the measure of the mode, or the most common observation. For our example data set, the mode is \\(7\\).\n\\[ 6 \\quad {\\Large 7 \\quad 7 \\quad  7} \\quad 8 \\quad 8 \\quad 9 \\quad 9 \\quad 10 \\quad 11  \\quad 11\\]\nWhile using the mode for this data set is sensible, it is common in numerical data for each value to be unique3. In that case, there are no repeated values, and no identifiable mode. For that reason, it is unusual to calculate the mode to describe the center of a numerical variable.\nFor categorical data, however, the mode is very useful. The mode of the species variable among the Palmer penguins is “Adelie”. Trying to compute the mean or the median species will leave you empty-handed. This is one of the lingering lessons of the Taxonomy of Data: the type of variable guides how it is analyzed.\n\n\nMeasures of Spread\nThere are many different ways to capture spread or dispersion of data. Here are some basic desiderata we might hope to achieve with a measure of spread.\n\n\n\n\n\n\nDesiderata\n\n\n\n\nThe statistic should be low when the numbers are the same or very similar to one another.\nThe statistic should be high when the numbers are very different.\nThe statistic should not grow or shrink with the sample size ( n ).\n\n\n\nThese desiderata are not met by every measure of spread. Here is one such measure of spread which does not meet all three!\n\nRange\nThe range of a set of numbers is simply the maximum number in the dataset minus its minimum.\n\\[ range = max - min\\]\nFor our set of numbers, the range will be \\(5\\).\n\\[ {\\Large 6} \\quad {\\ 7 \\quad 7 \\quad  7} \\quad 8 \\quad 8 \\quad 9 \\quad 9 \\quad 10 \\quad 11  \\quad {\\Large 11}\\]\nAlthough the first two criterion above are met by the range, the third one is not. The reason is that if we add a number to our set which is greater than the maximum value, or smaller than the minimum value, the value of range will change. Therefore, increasing our sample size \\(n\\) could cause our statistic to grow or shrink.\nHere are some measures of spread which do meet all three criterion. They do this by using incorporating some of the measures of center that we have already talked about, such as the mean and the median.\n\n\nThe Sample Variance\nThe sample variance:\n\nTakes the differences from each observation, \\(x_i\\), to the sample mean \\(\\bar{x}\\);\nsquares them;\nadds them all up;\ndivides by \\(n - 1\\);\nthen finally, takes the square root.\n\n\n\nThe function in R: var()\n\\[ s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} \\left( x_i - \\bar{x}\\right)^2 \\] This formula is rather dense; don’t worry! We won’t ask you to memorize it. The key is that is fits the three criterion we were hoping for.\nThe distance \\((x_i - \\bar{x})^2\\) will be small when \\(x_i\\) is close to the mean, and large when it’s not. This means the first two criterion are met. Additionally, because we are dividing by a number close to \\(n\\), (\\(n-1\\)), the statistic does not grow or shrink with \\(n\\). This means the last criterion is met!\nOne other question you might have: why the square?\nThe reason is that spread/distance is a positive quantity. Recall that the mean of our list was \\(8.45\\). Two numbers in our list, \\(7\\) and \\(9\\), are both \\(1.45\\) units away from the mean. However, \\(7-8.45 = -1.45\\) and \\(9-8.45 = 1.45\\). As part of the sum, we will have to add up \\(-1.45\\) and \\(1.45\\), which comes out to \\(0\\).\nThis means that the information from the two data points \\(7\\) and \\(9\\) have been canceled out! We don’t want this to happen, so we need to make all of the terms in the sum positive. The square takes care of that.\nFor our list:\n\\[ s^2 =  2.87 \\]\n\n\nThe Sample Standard Deviation\n\\[ s = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} \\left( x_i - \\bar{x}\\right)^2} \\]\n\n\nThe function in R: sd()\nThe sample standard deviation \\(s\\) is the same as the sample variance \\(s^2\\): we’ve just taken the square root. One reason for using the sample standard deviation is that it at times is more interpret-able than the sample variance, since it’s measured in units rather than units squared.\nFor our list:\n\\[ s =  1.69 \\] We can say, therefore, that each data point is about 1.7 units apart from each other.\n\nWhile the sample variance and sample standard deviation are great for measuring symmetric data (which appear enough in statistics) and also show up a lot in the theory of some topics that we will later discover, they do have their faults.\nNamely, when data is not symmetric, the square around \\(x_i - \\bar{x}\\) can cause some issues. Asymmetrical data will have many values \\(x_i\\) (large or small) which are far from the mean \\(\\bar{x}\\).\nIf \\(x_i - \\bar{x}\\) is large, then \\((x_i - \\bar{x})^2\\) will be very large. Therefore, \\(s^2\\) and \\(s\\) can produce values that are overestimates of the spread of most of the data. Here are two measures of spread which counter-act this.\n\n\nIQR (Interquartile Range)\nThe IQR is the difference between the median of the larger half of the sorted data set, \\(Q3\\), and the median of the smaller half, \\(Q1\\).\n\n\nThe function in R: IQR()\n \n\\[ IQR = Q_3 - Q_1 \\]  \nLet’s calculate the IQR for the list of eleven numbers we’ve been working with. First, we find the median of our dataset. That’s \\(8\\). Then, we split the data into two halves of five. Then we find the medians of these halves. and take the difference. These steps are visualized below.\n \n\\[ 6 \\quad 7 \\quad {\\Large 7 \\quad  7} \\quad 8 \\quad  {\\large 8} \\quad 9 \\quad {\\Large 9 \\quad 10} \\quad 11  \\quad 11\\]  \nWe have that \\(Q_3 = 9.5\\) and \\(Q_1 = 7\\). Then:\n \n\\[IQR =  9.5−7 = 2.5\\]\nThe reason the IQR works well for asymmetric data is because the measure of center it’s based on is the median, not the mean. The median, being just the middle point of the data and not a value obtained by calculation of all the numbers in a list, is not impacted when extreme values are tacked onto the end of the list.\n\n\n\n\n\n\nAdditional Desiderata\n\n\n\n\nIs robust to extreme values (outliers).\n\n\n\nOur final measure of spread is another option which is resillent against outliers, but is based off of the mean instead of the median.\n\n\nMean Absolute Deviation (MAD)\nThe \\(MAD\\) is very similar to the sample variance \\(s^2\\), except that:\n\nwe divide by \\(n\\) rather than \\(n-1\\);\nwe take the absolute value of \\(x_i - \\bar{x}\\) instead of squaring it.\n\n\\[\nMAD: \\quad \\frac{1}{n}\\sum_{i = 1}^n |x_i - \\bar{x}|\n\\]\nThe key difference is the second one. The MAD is great for summarizing skewed distributions because it isn’t bothered too much by the presence of extreme values in a set of numbers. That’s because the absolute value bar just ensures a number is positive; it doesn’t further amplify that number by squaring it.\n\n\n\n\n\n\nAdditional Desiderata\n\n\n\n\nIs robust to extreme values (outliers).",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html#summary",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html#summary",
    "title": "Summarizing Numerical Data",
    "section": "Summary",
    "text": "Summary\nA summary of a summaries…this better be brief! Summaries of numerical data - graphical and numerical - often involve choices of what information to include and what information to omit. These choices involve a degree of judgement and knowledge of the criteria that were used to construct the commonly used statistics and graphics.\nContinue on to the tutorial portion of the notes",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/notes.html#footnotes",
    "href": "2-summarizing-data/02-summarizing-numerical-data/notes.html#footnotes",
    "title": "Summarizing Numerical Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe ggplot2 package in R defaults to 30 bins across the range of the data. That’s a very rough rule-of-thumb, so tinkering is always a good idea.↩︎\nTo read more about one common way to construct a box plot, see the ggplot2 documentation.↩︎\nThat is, unless you aggregate! The aggregation performed by a histogram or a density plot is what allows us to describe numerical data as unimodel or bimodal.↩︎",
    "crumbs": [
      "Notes",
      "Summarization",
      "Summarizing Numerical Data"
    ]
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#describing-shape",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#describing-shape",
    "title": "Summarizing Numerical Data",
    "section": "Describing Shape",
    "text": "Describing Shape\n\nWhich of these variables do you expect to be uniformly distributed?\n\nbill length of Gentoo penguins\nsalaries of a random sample of people from California\nhouse sale prices in San Francisco\nbirthdays of classmates (day of the month)\n\nPlease vote at pollev.com.\n\n\n  \n    −\n    +\n \n 01:00\n \n\nCorrect answer: 4.T\nThis lends itself very well to boardwork: you can ask a student to tell you how to draw the distribution birthdays. Topics to bring up:\n\nBarchart shows more information than a histgram (which would aggregate)\nFor discrete numerical, barchart is fine as long as the number of categories isn’t too great.\nBirthdays isn’t quite uniform: you would expect 29, 30, 31 to have fewer since not all months have those dayes.\n\nYou can continue the same approach to drawing the remaining three distribution: 1) bimodal (separated out by species) and symmetric (as demonstrated on the next slide) 2) unimodal and heavily right skewed 3) unimodal and right skewed."
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#mean-median-mode-which-is-best",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#mean-median-mode-which-is-best",
    "title": "Summarizing Numerical Data",
    "section": "Mean, median, mode: which is best?",
    "text": "Mean, median, mode: which is best?\n\n\nIt depends on your desiderata: the nature of your data and what you seek to capture in your summary.\n\n\n\n\nGet out a piece of paper. You’ll be watching a 3 minute video that discusses characteristics of a typical human. Note which numerical summaries are used and what for."
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-1",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-1",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "After the video, you can write on the board each of mean, median, mode and have students list measures that were reported. There are many modes because lots of the data that they collect is categorical."
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#general-advice",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#general-advice",
    "title": "Summarizing Numerical Data",
    "section": "General Advice",
    "text": "General Advice\n\n\nMeans are often a good default for symmetric data.\n\n\n\n\nMeans are sensitive to very large and small values, so can be deceptive on skewed data. &gt; Use a median\n\n\n\n\nModes are often the only option for categorical data.\n\n\n\nBut there are other notions of typical… what about a maximum?"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-2",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-2",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "This is an interesting example of when we don’t use a measure of central tendency to characterize the distribution. The answer to, “What will the temperature be tomorrow?” is generally answered not with an average but with a max. This is a good question to put to students: why do we characterize daily temperatures by their max?"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-4",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-4",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "This is a nice but not necessary example of an excellent visualization of summary statistics. Every dot is a max temp on a day of the year over a 40 year span. The annotations of the PWN heat dome are very effective in showing by how much they are the max of a distribution of maxes."
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-5",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-5",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Why are measures of spread so important? Consider the following question.\n\n\n\nThere are two new food delivery services that open in Berkeley: Oski Eats and Cal Cravings. A friend of yours that took Stat 20 collected data on each and noted that Oski Eats has a mean delivery time of 29 minutes and Cal Cravings a mean delivery time of 27 minutes. Which would would you rather order from?\n\n\nThis starts off as a softball, so you probably don’t want to give too much time or bother with a poll. Simply ask students why they voted for Cal Cravings and then give them a bit more information…"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#one-possible-reality",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#one-possible-reality",
    "title": "Summarizing Numerical Data",
    "section": "One possible reality",
    "text": "One possible reality"
  },
  {
    "objectID": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-6",
    "href": "2-summarizing-data/02-summarizing-numerical-data/slides.html#section-6",
    "title": "Summarizing Numerical Data",
    "section": "",
    "text": "Which would would you rather order from?\n\n\n  \n    −\n    +\n \n 01:00\n \n\nNow you can ask students to make a good argument for both options. Cal Cravings is shorter on average but is very variable; its good for the gamblers. For students who value predictability, Oski Eats is better because of its smaller spread."
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html",
    "title": "A Grammar of Graphics",
    "section": "",
    "text": "The Grammar of Graphics is an abstract framework of data visualization and so far we’ve kept things abstract. But to construct your own plots you’ll need to be able to implement them in software. We are fortunate to have a translation of the grammar into readible, flexible, and powerful code: the ggplot2 package in R (found within library(tidyverse)).\nThe basic template for describing a plot in code using ggplot2 is:\nWhere DATAFRAME is the name of your data frame, ATTR is the aesthetic attribute that you’ll be using, VAR is a variable in your data frame, and GEOMETRY is the name of a geometry.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#building-a-ggplot",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#building-a-ggplot",
    "title": "A Grammar of Graphics",
    "section": "Building a ggplot",
    "text": "Building a ggplot\nLet’s code up the penguin plot bit by bit.\n\n\n\n\n\n\n\n\nThe ggplot() function takes as its first argument a data frame. By itself, there’s not much to look at; it just creates our blank canvas.\nLet’s now indicate how we want to map our aesthetic attributes to variables in that data frame by including them inside the aes() function as the second argument to ggplot().\n\n\n\n\n\n\n\n\nNow we’re getting somewhere. Our axes are now set up with labels and values that are determined by looking into the data frame and checking the range of each variable. Note that we can pass more than one aesthetic mapping inside aes(), we just need to separate them with a comma.\nAll that is left is to actually put the observations on the plot by declaring what geometry we want. Let’s express each penguin as a point by using + to add on a new layer called geom_point().\n\n\n\n\n\n\n\n\nWhen you run this code, R gives you a Warning. These warnings appear when R did something that isn’t a problem necessarily, but thinks you should know about. In this case, it “removed 2 rows containing missing values or values outside the scale range”. In other words, there were two penguins who didn’t have a recorded value for either the x or the y, so there are 342 points on this plot, two less than the 344 rows in the data frame.\nThe plot that is created by this combination of aesthetic mappings and the point geometry is called a scatter plot. This is a good choice of plot for visualizing the relationship between two numerical variables. The original penguin plot, though, visualizes the relationship between three variables. To complete our plot, let’s add in that third variable by mapping species to the color aesthetic attribute.\n\n\n\n\n\n\n\n\nBeautiful!\n\nExercises\n\n\n\n\n\n\nTip\n\n\n\nThe code block that follows is an example of an exercise code block. Modify the code block to achieve the task laid out in the exercise. When you get it correct, it will praise your fine programming skills. If you get stuck, use the “Solution” button.\n\n\n\nA different penguins plot\nThe code cell below creates the penguins plot above. Modify the code to visualize the relationship between the flipper length of penguins on the x-axis (flipper_length_mm) and their body bass on the y-axis (body_mass_g).\n\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = body_mass_g,\n                     color = species)) +\n    geom_point()\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = body_mass_g,\n                     color = species)) +\n    geom_point()",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#communicating-with-graphics",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#communicating-with-graphics",
    "title": "A Grammar of Graphics",
    "section": "Communicating with Graphics",
    "text": "Communicating with Graphics\nAt this point in the course, you have a bevy of different types of statistical graphics under your belt: scatterplots, histograms, dot plots, violin plots, box plots, density curves, and bar plots of several kinds. You also have a broad framework to explain how these graphics are composed: the Grammar of Graphics. But to what purpose? Why plot data? For whom?\nEvery time you build a plot, you do so with one of two audiences in mind.\n\nYourself.\nSomeone else.\n\nThe process of building understanding from a data set is one that should be driven by curiosity, skepticism, and thoughtfulness. As a data scientist, you’ll find yourself in conversation with your data: asking questions of it, probing it for structure, and seeing how it responds. This thoughtful conversation is called exploratory data analysis (or EDA).\nDuring EDA, the aim is to uncover the shape and structure of your data and to uncover unexpected features. It’s an informal iterative process where you are your own audience. In this setting, you should construct graphics that work best for you.\nAt some point, you’ll find yourself confident in the claim that can be supported by your data and the focus changes to communicating that claim as effectively as possible with a graphic. Here, your audience shifts from yourself to someone else: other scientists, customers, co-workers in a different part of your company, or casual readers. You must consider the context in which they’ll be viewing your graphic: what they know, what they expect, what they want.\nIn this tutorial we’ll focus on three ways to hone the message of your data visualization.\n\nMapping versus setting\nLabels for clarity  \nChoosing a theme \n\n\n\n\nMapping vs Setting\nOnce you have your first draft of a plot complete and you’re thinking about how to fine tune it for your audience, your eye will turn to the aesthetic attributes. Is that color right? What about the size of the points?\nConsider the first draft of the penguins plot above. It might feel a bit drab to have a large mass of points all in black, the same color as the labels and surrounding text. Let’s make the points blue instead to make them stand out a bit more. Click “Run Code” to see the new plot.\n\n\n\n\n\n\n\n\nThis is . . . unexpected. Why did it color the points red? Is this a bug?\nWhat we’ve stumbled into is a subtle but essential distinction in the grammar of graphics: mapping vs setting. When you put an aesthetic attribute (x, color, size, etc.) into the aes() function, you’re mapping that attribute in the plot to whatever data lives in the corresponding column in the data frame. Mapping was this process:\n\n\n\n\n\nThat’s not what we set out to do here. We just wanted to tweak the look of our aesthetic attributes in a way that doesn’t have anything to do with the data in our data frame. This process is called setting the attribute.\nTo set the color to blue1, we need to make just a small change to the syntax. Let’s move the color = \"blue\" argument outside of the aes() function and into the geom_() function.\n\n\n\n\n\n\n\n\nAh, that looks much better!\nColor isn’t the only aesthetic attribute that you can set. Let’s increase slightly the size of our points by setting the size to three times the size of the default.\n\n\n\n\n\n\n\n\nIt’s not clear that that improves the readability of the plot - there is more overlap between the points now - but the setting worked. One thing we might do to get more visibility on some of the points that were clumped is to use the alpha mapping!\n\n\n\n\n\n\n\n\nHow would it have looked if instead we had mapped the size? When you map, you need a map to a column in your data frame, so let’s map size to species.\n\n\n\n\n\n\n\n\nWe’ve made a mess of our plot now, but it is clear what happened. R looked inside the species column, found a categorical variable with three levels and selected a distinct size for each of those levels.\nAll in all, this is another area in which the grammar of graphic guides clear thinking when constructing a graphic. The aesthetic attributes of a plot can be determined either by variability found in a data set or by fixed values that we set. The former is present in all data visualization but it’s the latter that comes into play when fine-tuning your plot for an audience.\n\n\nAdding Labels for Clarity\nYou may have noticed that ggplot2 pulls the labels for the x-axis, the y-axis, and the legend directly from the names of the variables in the data frame. This results in labels like bill_length_mm, which is no problem when you’re making plots for yourself - you know what this variable means. But will an outside audience?\nYou can change the labels of your plot by adding a labs() layer.\n\n\n\n\n\n\n\n\nAxis and legend labels should be concise and often include the units of measurement. If you find them getting too wordy, know that you can clarify or expand on what is being plotted either in a figure caption or in the accompanying text.\nSpeaking of captions, those a can be added too, as well as a title.\n\n\n\n\n\n\n\n\nThe title of a plot is valuable real estate for communicating the primary story of your plot. It should highlight the most important structure in the data. In the plot above, there appears to be little correspondence between bill length and bill depth. Of course, that changes when we map species to color. Let’s make that plot and title it accordingly.\n\n\n\n\n\n\n\n\nThe practice of using the plot title to convey the main message of the plot is used to powerful effect by the visualization experts at the British publication, The Financial Times2. They have developed a wealth of visualizations to help readers understand what is happening with public health throughout the pandemic. The sobering graphic below uses the title to guide the viewer to the most important visual structure in the plot: the yawning vertical gap between dosage rates between high and low income countries.\n\n\n\n\n\n\n\n\n\nChoosing a Theme\nWhat piece of software did I use to produce the following plot?\n\n\n\n\n\n\n\n\n\nIf you said “Excel”, you are correct! Well… it is Excel in spirit. What makes this plot look like it was made in Excel are a series of small visual choices that were made: the background is a dark gray, there are black horizontal guide lines, and the plot and the legend is surrounded by a black box. Small decisions like these that effect the overall look and feel of the plot are called the theme. The theme used here belongs to the ggthemes library. Here’s the code used.\n\n\n\n\n\n\n\n\nLet’s look at a few more. Do they look familiar?\n\n\n\n\n\n\n\n\n\nThey are, from top to bottom, a theme based on The Wall Street Journal, The Economist, and one of the themes built into ggplot2 packaged called bw for “black and white” (there are no grays). The ggplot2 library has several themes to choose from and yet more live in other packages like ggthemes. To use a theme, all you need to do is add a layer called theme_NAME (e.g. for the black and white theme, use theme_bw()).\nThemeing your plots is an easy way to change the look of your plot. Tinker with a few different themes and considering adding them to your labs3. But, as with all design decisions around graphics, be sure to think about your audience. You might find the Excel aesthetics ugly and dated, but will your audience? If you’re presenting your plot to a community that works with Excel plots day in and day out, that’s probably a sound choice. If you are preparing a plot for submission to a scientific journal, a more minimalist theme is more appropriate.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#summary",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#summary",
    "title": "A Grammar of Graphics",
    "section": "Summary",
    "text": "Summary\nOver the coming weeks, you’ll get lots of practice with ggplot2. It is an incredibly flexible and powerful piece of software that helps you not just build plots, but think about each of the design decisions that you make. Throughout your journey it is helpful to have a source of documentation to learn about the functionality of the tool. The help files on each function are only so useful. A better option is the official ggplot2 documentation: https://ggplot2.tidyverse.org/.\nThere are two main uses for data visualization. The first is as part of exploratory data analysis, when you are constructing plots for yourself to better understand the structure of the data. When you’re ready to communicate with an outside audience using graphics, more thought is needed: you must think about the difference between mapping and setting, the use of labels for clarity, and themes.",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#footnotes",
    "href": "2-summarizing-data/03-a-grammar-of-graphics/tutorial.html#footnotes",
    "title": "A Grammar of Graphics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo see the vast (and somewhat strange) palette of color names that R knows, type colors() at the console.↩︎\nVisualization drawn from the excellent collection of graphics at the Financial Times Covid Tracker https://ig.ft.com/coronavirus-vaccine-tracker/.↩︎\nExplore the themes available within ggplot2 by reading the documentation https://ggplot2.tidyverse.org/reference/ggtheme.html. For the additional themes held in the ggthemes package, read this: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/.↩︎",
    "crumbs": [
      "Tutorials",
      "R Tutorials",
      "A Grammar of Graphics"
    ]
  },
  {
    "objectID": "glossary-defs.html",
    "href": "glossary-defs.html",
    "title": "Definitions",
    "section": "",
    "text": "Questions and Data\n\n\nData\n\nAn item of (chiefly numerical) information, especially one obtained by scientific work, a number of which are typically collected together for reference, analysis, or calculation. From Latin datum: that which is given. Facts.\n\n\n\n\n\nVariable\n\nA characteristic of an object or observational unit that can be measured and recorded.\n\n\n\n\n\nNumerical Variable\n\nA variable that take numbers as values and where the magnitude of the number has a quantitative meaning.\n\n\n\n\n\nCategorical Variable\n\nA variable that take categories as values. Each unique category is called a level.\n\n\n\n\n\nContinuous Numerical Variable\n\nA numerical variable that takes values on an interval of the real number line.\n\n\n\n\n\nDiscrete Numerical Variable\n\nA numerical variable that takes values that have jumps between them.\n\n\n\n\n\nOrdinal Categorical Variable\n\nA categorical variable with levels that have a natural ordering.\n\n\n\n\n\nNominal Categorical Variable\n\nA categorical variable with levels with no ordering.\n\n\n\n\n\nData Frame\n\nAn array that associates the observations (downs the rows) with the variables measured on each observation (across the columns). Each cell stores a value observed for a variable on an observation.\n\n\n\n\n\nUnit of Observation\n\nThe class of object on which the variables are observed.\n\n\n\n\n\nSummary\n\nA numerical, graphical, or verbal description of an aspect of data that is on hand.\n\n\n\n\n\nGeneralization\n\nA numerical, graphical, or verbal description of a broader set of units than those on which data was been recorded.\n\n\n\n\n\nCausal Claim\n\nA claim that changing the value of one variable will influence the value of another variable.\n\n\n\n\n\nPrediction\n\nA guess about the value of an unknown variable, based on other known variables."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course Culture\nStudents taking Stat 20 come from a wide range of backgrounds. We hope to foster an inclusive and supportive learning environment based on curiosity rather than competition. All members of the course community—the instructor, students, tutors, and readers—are expected to treat each other with courtesy and respect.\nYou will be interacting with course staff and fellow students in several different environments: in class, over the discussion forum, and in office hours. Some of these will be in person, some of them will be online, but the same expectations hold: be kind, be respectful, be professional.\nIf you are concerned about classroom environment issues created by other students or course staff, please come talk to us about it.\n\n\nMode of Instruction\nThis course is structured as a flipped class, meaning that you will first be encountering new concepts in statistics and data science outside of class. Class time is dedicated to expanding on the work you’ve done outside of class by working through questions solo, in groups, and as a class.\n\nBefore class\nIt is your responsibility to become familiar with the topics that appear in the course notes and to work through the reading questions on Gradescope by 11:59 pm on the day before class.\n\n\nDuring class on Tue/Wed and Thu/Fri\nClass time (2 hrs) will be spent on a range of activities, but the most common will be concept questions (using Poll Everywhere) and working through components of your Worksheets and Labs. Therefore, the most efficient way to complete your assignments is to be an active participant in class. Attendance is expected on these class days.\n\n\nDuring class on Monday\nMonday is shorter (1 hr) class that alternates between:\n\nWorkshops: less-structured class dedicated to finishing up work on your assignments\nQuizzes: see information on quizzes below.\n\n\n\n\nGroup tutoring\nTutors will offer group tutoring sessions several times each week. This is an opportunity to finish up any assignments that you’ve started in class or review any topics that are confusing for you. Each group tutoring session will be staffed by 2-4 tutors. You’re welcome to attend any session that works well for your schedule. Check the Office Hours page to see the group tutoring schedule.\nGroup tutoring is a great place to go to meet other students and collaborate on assignments with tutors on hand to help you get unstuck.\n\n\nInstructor Office Hours\nThe instructors will offer office hours each week across a range of times. We ask that you only visit the office hours of your instructor, but you are welcome to visit the tutoring sessions of any tutors, not just the ones who work in your section. We may adjust the office hour and group tutoring sessions schedule throughout the semester as we understand student needs and preferences. Please check the Office Hours page to see the times of the various office hour/group tutoring sessions.\nOffice hours are an opportunity to chat one-on-one with your instructor. Please come to office hours! Coming to office hours does not send a signal that you are behind or need extra help. On the contrary, coming to office hours early and often tends to co-occur with success in the course. Instructors are happy to chat about the course material, statistics in general, careers in statistics, and whatever other statistics or data science topics are on your mind!\n\n\nDon’t come to class if you’re sick!\nMaintaining your health and that of the Berkeley community is of primary importance to course staff, so if you are feeling ill or have been exposed to illness, whether it’s COVID-19 or something else, please do not come to class. All of the materials used in class will be posted to the course website. You’re encouraged to reach out to fellow students to discuss the class materials or stop by group tutoring or office hours to chat with a tutor or the instructor.\n\n\n\nMaterials\nThe primary materials for the course are the lecture notes, which will be posted to the course website in advance of class. We’ll teach you everything you need to know!\nThe following textbooks are useful supplementary texts but there is no need to purchase them:\n\nIntroduction to Modern Statistics by Çetinkaya-Rundel and Hardin (freely available online)\nStatistics, Freedman, Pisani, and Purves\nData Visualization: A Practical Introduction, Healy (freely available online)\nHands-on Programming with R, Grolemund (freely available online)\nR for Data Science, Wickham and Grolemund (freely available online)\n\n\nRStudio\nThe software that we’ll be using for our data analysis is the free and open-source language called R that we’ll be interacting with via software called RStudio. As a Berkeley student, you have your own version of RStudio waiting you for at: http://stat20.datahub.berkeley.edu. Most students taking Stat 20 have no experience programming; we’ll teach you everything you need to know!\n\n\n\nCourse communication\n\nbCourses\nWe don’t use bCourses for much. It is primarily used to disseminate announcements for the entire class, such as final exam information.\n\n\nDiscussion forum\nThe official discussion forum for the class will be hosted on Ed. Ed is a forum to ask and answer questions with your fellow students and course staff. It’s an indispensable resource for learning from your peers and seeking help from tutors and instructors.\nIf you have a question for staff, create a new post and mark it as “private” and it will go only to course staff. This is the best option to contact us if you have a personal concern. If your question does not include personal information and can be answered by other students, make sure it is public.\nIn a course this large, the instructors have a difficult time responding to individual emails, so please use the class forum or visit office hours if you wish to contact us!\n\n\nCourse website\nAll of the assignments will be posted here to the course website. This also holds the course notes, slides, and links to Gradescope, Ed, and RStudio.\n\n\n\nAssignments, Exams, and Grading\n\nTurning-in assignments\nYou will be turning in your assignments on a platform called Gradescope. This is also the platform where your assignments will be graded, so you can return there to get feedback on your work. You are welcome to file a regrade request if you notice that we made an error in applying the rubric to your work.\n\n\nLabs\nLabs are long-form assignments designed to apply the concepts from the lecture notes in the cause of doing an analysis of real data. This will involve both writing code and communicating your thoughts and findings in English. We’ll be working through some problems from the labs in class, but you may have to complete them on your own outside of class time. Some labs will be turned in individually; some will be turned in as groups.\nLabs are to be submitted as PDF files. These PDFs will be generated by rendering Quarto Documents (.qmd files) to HTML and then exporting the HTML into a PDF. Don’t worry if you’re not familiar with the Quarto Document as we will teach you about it!\nWe will be assessing most questions on labs for correctness but for others we will be giving credit based on completion.\n\n\nWorksheets\nDuring class, we will give you a second engagement with the day’s material in the form of a worksheet. These worksheets will run like traditional homework problems and drill the concepts in the reading notes rather than asking you to apply the concepts with a data set, like the lab does. These are graded credit / no credit, where full credit is given if you earnestly engage with the assignments.\n\n\nReading Questions\nReading questions serve to check your understanding and engagement while going through the lecture notes prior to class. There will be a handful of questions per lecture note. These questions be a mix of multiple choice, short answer, and coding questions. You can answer them directly on Gradescope. The reading questions will be due 11:59 pm on the day before class.\n\n\n\nQuizzes\nQuizzes reinforce the most important concepts from the lecture notes and provide you the opportunity to work through misunderstandings of concepts with peers and the instructor.\nThere is both an individual and group component to the quiz.\nThe individual component will last ~25 minutes. You are allowed one, A4, one-sided handwritten sheet of notes with your name in the upper right-hand corner. The group component will take place immediately after the individual component has been completed and will last ~15 minutes. Your final (composite) quiz grade will be the average of your group and individual quiz scores.\n\n\nExam\nThe final exam will be held in person during finals week. The time and date is Wednesday December 18th, 7 - 10 pm.\n\n\nGrading\nYour final grade in the course will be computed as follows:\n\nLabs 35%\nReading Questions: 3%\nQuizzes 25%\nWorksheets 7%\nFinal 30%\n\nThe grades will not be curved (&gt; 90% is some kind of A, etc.).\nIn order to provide flexibility around emergencies that might arise for you throughout the semester we will drop everyone’s lowest quiz grade before calculating your quiz average at the end of the semester. We will also drop your two lowest Reading Question scores; there are so many of those that it is understandable if you miss one or two.\n\n\n\nPolicies\n\nAccomodations for students with disabilities\nStat 20 is a course that is designed to allow all students to succeed. If you have letters of accommodations from the Disabled Students’ Program, please share them with your instructor as soon as possible, and we will work out the necessary arrangements.\n\n\nLate Work\nIf you don’t get your Labs or Worksheets in by the deadline, don’t fret. Fill out the extension request form to request an extension of 1-3 days. We will be approving all requests for extensions that are three days or fewer past the assignment deadline. For longer extensions, such as serious illness, speak to your instructor.\n\n\n\nCollaboration policy\nYou are encouraged to collaborate with your fellow students on worksheets and labs, but the work you turn in should reflect your own understanding and all of your collaborators must be cited. The individual component of quizzes, reading questions, and exams must reflect only your work.\nResearchers don’t use one another’s research without permission; scholars and students always use proper citations in papers; professors may not circulate or publish student papers without the writer’s permission; and students may not circulate or post non-public materials (quizzes, exams, rubrics-any private class materials) from their class without the written permission of the instructor.\nThe general rule: you must not submit assignments that reflect the work of others unless they are a cited collaborator.\nThe following examples of collaboration are allowed and in fact encouraged!\n\nDiscussing how to solve a problem with a classmate.\nShowing your code to a classmate along with an error message or confusing output.\nPosting snippets of your code to the discussion forum when seeking help.\nHelping other students solve questions on the discussion with conceptual pointers or snippets of code that doesn’t whole hog give away the answer.\nGoogling the text of an error message.\nCopying small snippets of code from answers on Stack Overflow.\n\nThe following examples are not allowed:\n\nLeaving a representation of your assignment (the text, a screenshot) where students (current and future) can access it. Examples of this include websites like course hero, on a group text chain, over discord/slack, or in a file passed on to future students.\nAccessing and submitting solutions to assignments from other students distributed as above. This includes copying written answers from other students and slightly modifying the language to differentiate it.\nGoogling for complete problem solutions.\nWorking on the reading questions or individual quizzes in collaboration with other people or resources. These assignments must reflect individual work.\nSubmitting work on an quiz or final that reflects consultation with outside resources or other people. These assessments must reflect individual work.\n\nIf you have questions about the boundaries of the policy, please ask. We’re always happy to clarify.\n\nViolations of the collaboration policy\nThe integrity of our course depends on our ability to ensure that students do not violate the collaboration policy. We take this responsibility seriously and forward cases of academic misconduct to the Center for Student Conduct.\nStudents determined to have violated the academic misconduct policy by the Center for Student Conduct will receive a grade penalty in the course and a sanction from the university which is generally: (i) First violation: Non-Reportable Warning and educational intervention, (ii) Second violation: Suspension/Disciplinary Probation and educational interventions, (iii) Third violation: Dismissal.\nAnd again, if you have questions about the boundaries of the collaboration policy, please ask!\n\n\n\nFrequently Asked Questions\n\nWhat should I do if I’m on the waitlist?\nAttend both lecture and section (remember, we are teaching it as one two hour class), and submit all assignments on time. Visit your instructor on the first day of class so you can be added to the course Ed and Gradescope.\nAre class sessions recorded?\nNo. Class sessions feature a mix of group problem solving, activities, and discussion and don’t lend themselves to recording. The course notes are the main reference source for the course. Any materials used during the class session will be posted to the course website.\nIs attendance required?\nNo, but it is difficult to succeed in this course if you are not regularly attending class. Class sessions are designed to be an effective and efficient format to make progress on important assignments. Plus, it’s a great way to meet your fellow students and learn from one another. This class is very unique in that regard.\nIf you can’t attend due to a religious observance, athletic competition, or something similarly important, don’t worry. Just reach out to us via a private Ed post, and we can let you know what to keep tabs on during the time you’re away.\nAre time conflicts allowed?\n\nStat 20 does not allow students to enroll with time conflicts.\n\nWhat if I join the class late?\nIf you join the class within the first two weeks, read the syllabus and lecture notes, take a look at Gradescope to get a sense of any assignments that may have already passed, and visit office hours to check that you’re up to date with things. The first two weeks of material are very important so you must be able to make up assignments.\nAfter two weeks into the semester, you’ll have too much material that you’ll need to make up, so you will have to wait to a subsequent semester to take Stat 20.\n\n\n\nCampus Resources\nIf you ever need someone to talk to about anything that you’re going through, please feel to reach out to the instructors. For some topics, the tutors might be an even better resource because they are students just like you. Tutors can also tell you what being an Academic Student Employee (ASE) is like.\nWith regards to reports of sexual misconduct/violence/assault, you may speak with us as well, but know that we will need to report our discussion to the Title IX officer. This is detailed below.\n\nAs UC employees, the instructors (and tutors) are “Responsible Employees” and are therefore required to report incidents of sexual violence, sexual harassment, or other conduct prohibited by University policy to the Title IX officer. We cannot keep reports of sexual harassment or sexual violence confidential, but the Title IX officer will consider requests for confidentiality. Note that there are confidential resources available to you through UCB’s PATH to Care Center, which serves survivors of sexual violence and sexual harassment; call their 24/7 Care Line at 510-643-2005.\n\nBelow are some campus resources that may be helpful for you:\n\nBerkeley Supportal- great place to start\nDisabled Students’ Program\nUniversity Health Services\nUCB Path to Care\nStudent Learning Center\nBerkeley International Office\nOmbuds Office for Students and Postdoctoral Appointees\nGender Equity Resource Center\nCenter for Educational Justice & Community Engagement\nUHS Counseling and Psychological Services (CAPS)\nCampus Academic Accommodations Hub\nASUC Student Advocate’s Office\nBasic Needs Center\nASUC Mental Health Resources Guide"
  },
  {
    "objectID": "docs/website.html",
    "href": "docs/website.html",
    "title": "Configuring this Website",
    "section": "",
    "text": "One repo to rule them all.\n\n\n\nOrganization: files should be organized in a way that prioritizes thinking of it as a curriculum (instead of a website or a series of assignments). (subpoint: modularity)\nReproducibility:\nDocumentation:\nAutomation: automate as many non-human tasks as possible."
  },
  {
    "objectID": "docs/website.html#design",
    "href": "docs/website.html#design",
    "title": "Configuring this Website",
    "section": "",
    "text": "One repo to rule them all.\n\n\n\nOrganization: files should be organized in a way that prioritizes thinking of it as a curriculum (instead of a website or a series of assignments). (subpoint: modularity)\nReproducibility:\nDocumentation:\nAutomation: automate as many non-human tasks as possible."
  },
  {
    "objectID": "docs/website.html#contributing",
    "href": "docs/website.html#contributing",
    "title": "Configuring this Website",
    "section": "Contributing",
    "text": "Contributing\n\nConfiguring your machine\n\nOn your machine, a new RStudio project from version control, linked directly to the repo at https://github.com/stat20/stat20.\nBe sure you’ve configured git on your machine (allowing you to make commits) and stored a Personal Access Token (PAT) (allowing your machine to push commits to your repo on GitHub).\n\n\n\nWorkflow\n\nIn RStudio on main, pull any new changes.\nCreate a new branch named with what you’re adding, prepended with your name (e.g. andrew-update-lab-6).\nEdit the files you wish to work on. As you go, the easiest way to see how your changes look is to run quarto preview --profile staff-site at the terminal. That will do a minimal render of the website to show you the document that you’re working on and will re-render that document every time you save. You can also run quarto preview if you want to see the student-facing site (with no staff guide).\nCommit your changes to your new branch and push them to GitHub.\nGo to your GitHub and make a pull request from your new branch into stat20/stat20, main branch. Once the PR is made, it will kick-off a test rendering of both the student site and the staff site (the staff site will take &gt; 10 min to fully render). Once they’re done, you can go to https://stat20-pr.netlify.app/ and https://stat20staff-pr.netlify.app/ to see how they look. Note: this action will kickoff anew for each commit that you add to the PR, so it can be good to make the PR when you have just one commit on the branch, then check back as you push more commits to see how it looks.\nOnce the PR is merged into main, it will kick-off an action that will render and publish the staff site to https://stat20staff.netlify.app/. https://stat20.org/ doesn’t get rendered and published when main is changed, but instead of a pre-programmed schedule. After merging the branch, that branch can be deleted.\n\n\n\nAdding a page\n\nCreate a new qmd file\nAdd your content like normal\n\n\n\nCourse Settings"
  },
  {
    "objectID": "docs/assignments.html",
    "href": "docs/assignments.html",
    "title": "Adding and Removing Assignments",
    "section": "",
    "text": "Assignments are hosted on the Assignments page and include a list of Labs and a list of Problem Sets. These lists build automatically if the assignment files follow a particular naming scheme. Below we discuss how to add assignments to the list. They can be removed by renaming the files or removing them entirely from the repository.\nFor further reading on how these lists are made, see the Quarto documentation on document listings."
  },
  {
    "objectID": "docs/assignments.html#problem-sets",
    "href": "docs/assignments.html#problem-sets",
    "title": "Adding and Removing Assignments",
    "section": "Problem Sets",
    "text": "Problem Sets\nProblem sets are sets of drill-style problems that provide practice with the concepts and skills of a particular day’s lesson. They are stored within the subdirectory containing all of the materials for that day.\n\nPDF handouts\n\nCreate a file called ps.qmd alongside the notes for a given day’s materials. Your directory should look like this:\nintro-to-probability\n├── notes.qmd\n├── ps.qmd\nAt least two YAML options should be specified in the front-matter, title and the custom handout format:\n---\ntitle: Calculating Chances\nformat: stat20handout-pdf\n---\nUpon rendering the site, this assignment should appear on the assignments page. The format of the assignment list is controlled by the assignments template, which will automatically assign numbers to the problem sets based on their order in the directory.\n\nThe pdf notes use the stat20handout custom pdf format. See Custom Formats for more information on its use.\n\n\nQmd handouts\n\nJust like with pdfs, create a file called ps.qmd alongside the notes for a given day’s materials. Your directory should look like this:\nintro-to-probability\n├── notes.qmd\n├── ps.qmd\nAdd the following to the front-matter of ps.qmd.\n---\ntitle: Simulation\nformat:\n  html:\n    code-tools: \n      source: true\n      toggle: false\nsidebar: false\n---\nThe title should have the name of topic, usually the same as the title of the notes. This name will be used in creating the PS name in the listing. The remaining yaml options will provide a link at the top right of the problem set webpage that, when clicked, will produce a pop-up of the source of the qmd file. Students can copy and paste this into a blank qmd file in RStudio (and can remove the extra yaml options).\n\nIf you have multiple problem set files on a single day, you can differentiate them by adding a single letter or digit following ps and hyphen. ps.qmd, ps-2.qmd, and ps-b.qmd should all work. See the source for the assignment page for the rule that determines which files show up in the listing."
  },
  {
    "objectID": "docs/assignments.html#labs",
    "href": "docs/assignments.html#labs",
    "title": "Adding and Removing Assignments",
    "section": "Labs",
    "text": "Labs\n\n\n\n\n\n\nWarning\n\n\n\nUnder Construction"
  }
]